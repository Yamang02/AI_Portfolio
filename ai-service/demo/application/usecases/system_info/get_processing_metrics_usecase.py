"""
Get Processing Metrics Use Case - Demo Application Layer
ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤ ì¡°íšŒ ìœ ìŠ¤ì¼€ì´ìŠ¤

ì‹¤ì‹œê°„ ì²˜ë¦¬ í†µê³„ì™€ ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ê³µí†µ ì˜¤ë¥˜ ì²˜ë¦¬ì™€ ì‘ë‹µ í˜•ì‹ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.
"""

from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import defaultdict
import time
from application.common import (
    handle_usecase_errors,
    ResponseFormatter,
    log_usecase_execution
)


@dataclass
class ProcessingMetrics:
    """ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤"""
    total_processed: int
    successful_processed: int
    failed_processed: int
    pending_processed: int
    average_processing_time_ms: float
    throughput_per_minute: float


@dataclass
class StageMetrics:
    """ë‹¨ê³„ë³„ ë©”íŠ¸ë¦­ìŠ¤"""
    stage_name: str
    total_items: int
    completed_items: int
    failed_items: int
    average_duration_ms: float
    success_rate_percent: float


class GetProcessingMetricsUseCase:
    """ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤ ì¡°íšŒ ìœ ìŠ¤ì¼€ì´ìŠ¤"""
    
    def __init__(
        self,
        processing_status_service=None,
        embedding_service=None,
        chunking_service=None,
        batch_processing_service=None,
        validation_service=None
    ):
        self.processing_status_service = processing_status_service
        self.embedding_service = embedding_service
        self.chunking_service = chunking_service
        self.batch_processing_service = batch_processing_service
        self.validation_service = validation_service
        
    @handle_usecase_errors(
        default_error_message="ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        log_error=True
    )
    @log_usecase_execution("GetProcessingMetricsUseCase")
    def execute(self, time_range_hours: int = 24) -> Dict[str, Any]:
        """ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤ ì¡°íšŒ ì‹¤í–‰"""
        return ResponseFormatter.statistics_response(
            data={
                "overall_metrics": self._get_overall_metrics(),
                "stage_metrics": self._get_stage_metrics(),
                "real_time_metrics": self._get_real_time_metrics(),
                "performance_trends": self._get_performance_trends(time_range_hours),
                "bottleneck_analysis": self._get_bottleneck_analysis(),
                "error_analysis": self._get_error_analysis(),
                "resource_utilization": self._get_resource_utilization(),
                "recommendations": self._get_performance_recommendations()
            },
            message="ðŸ“Š ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤"
        )
    
    def _get_overall_metrics(self) -> Dict[str, Any]:
        """ì „ì²´ ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤"""
        overall_metrics = {
            "document_processing": {
                "total_documents": 0,
                "processed_documents": 0,
                "failed_documents": 0,
                "processing_rate_percent": 0.0
            },
            "chunk_processing": {
                "total_chunks": 0,
                "processed_chunks": 0,
                "failed_chunks": 0,
                "processing_rate_percent": 0.0
            },
            "embedding_processing": {
                "total_embeddings": 0,
                "created_embeddings": 0,
                "failed_embeddings": 0,
                "processing_rate_percent": 0.0
            },
            "system_performance": {
                "average_response_time_ms": 0.0,
                "throughput_items_per_minute": 0.0,
                "error_rate_percent": 0.0,
                "uptime_hours": 0.0
            }
        }
        
        # ì²­í‚¹ ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ìŠ¤
        if self.chunking_service:
            try:
                chunking_stats = self.chunking_service.get_chunking_statistics()
                overall_metrics["chunk_processing"].update({
                    "total_chunks": chunking_stats.get("total_chunks", 0),
                    "processed_chunks": chunking_stats.get("total_chunks", 0),
                    "processing_rate_percent": 100.0 if chunking_stats.get("total_chunks", 0) > 0 else 0.0
                })
            except Exception as e:
                overall_metrics["chunk_processing"]["error"] = str(e)
        
        # ìž„ë² ë”© ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ìŠ¤
        if self.embedding_service:
            try:
                embedding_stats = self.embedding_service.get_embedding_statistics()
                overall_metrics["embedding_processing"].update({
                    "total_embeddings": embedding_stats.get("total_embeddings", 0),
                    "created_embeddings": embedding_stats.get("total_embeddings", 0),
                    "processing_rate_percent": 100.0 if embedding_stats.get("total_embeddings", 0) > 0 else 0.0
                })
            except Exception as e:
                overall_metrics["embedding_processing"]["error"] = str(e)
        
        # ì²˜ë¦¬ ìƒíƒœ ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ìŠ¤
        if self.processing_status_service:
            try:
                processing_stats = self.processing_status_service.get_processing_statistics()
                
                total_processes = processing_stats.get("total_processes", 0)
                completed_processes = processing_stats.get("completed_count", 0)
                failed_processes = processing_stats.get("failed_count", 0)
                
                if total_processes > 0:
                    success_rate = (completed_processes / total_processes) * 100
                    error_rate = (failed_processes / total_processes) * 100
                else:
                    success_rate = 0.0
                    error_rate = 0.0
                
                overall_metrics["system_performance"].update({
                    "error_rate_percent": error_rate,
                    "success_rate_percent": success_rate,
                    "total_processes": total_processes
                })
            except Exception as e:
                overall_metrics["system_performance"]["error"] = str(e)
        
        return overall_metrics
    
    def _get_stage_metrics(self) -> List[Dict[str, Any]]:
        """ë‹¨ê³„ë³„ ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤"""
        stage_metrics = []
        
        if not self.processing_status_service:
            return stage_metrics
        
        try:
            # ê° ì²˜ë¦¬ ë‹¨ê³„ë³„ í†µê³„
            processing_stages = [
                "DOCUMENT_UPLOADED",
                "CHUNKING_PENDING",
                "CHUNKING_PROCESSING", 
                "CHUNKING_COMPLETED",
                "CHUNKING_FAILED",
                "EMBEDDING_PENDING",
                "EMBEDDING_PROCESSING",
                "EMBEDDING_COMPLETED", 
                "EMBEDDING_FAILED"
            ]
            
            for stage in processing_stages:
                try:
                    stage_statuses = self.processing_status_service.get_statuses_by_stage(stage)
                    
                    if stage_statuses:
                        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° (Mock ë°ì´í„°)
                        avg_duration = self._calculate_average_stage_duration(stage)
                        
                        stage_info = {
                            "stage_name": stage,
                            "display_name": self._get_stage_display_name(stage),
                            "total_items": len(stage_statuses),
                            "completed_items": len([s for s in stage_statuses if "COMPLETED" in s.stage.name]),
                            "failed_items": len([s for s in stage_statuses if "FAILED" in s.stage.name]),
                            "pending_items": len([s for s in stage_statuses if "PENDING" in s.stage.name]),
                            "average_duration_ms": avg_duration,
                            "success_rate_percent": self._calculate_stage_success_rate(stage_statuses)
                        }
                        
                        stage_metrics.append(stage_info)
                except Exception as e:
                    # ê°œë³„ ë‹¨ê³„ ì˜¤ë¥˜ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
                    continue
                    
        except Exception as e:
            stage_metrics.append({
                "stage_name": "ERROR",
                "display_name": "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
                "error_message": str(e),
                "total_items": 0,
                "completed_items": 0,
                "failed_items": 0
            })
        
        return stage_metrics
    
    def _get_real_time_metrics(self) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ìŠ¤"""
        real_time_metrics = {
            "current_processing": {
                "active_processes": 0,
                "pending_processes": 0,
                "processes_per_minute": 0.0
            },
            "queue_status": {
                "document_queue_size": 0,
                "chunk_queue_size": 0,
                "embedding_queue_size": 0,
                "estimated_completion_time_minutes": 0
            },
            "live_performance": {
                "current_cpu_usage": 0.0,
                "current_memory_usage": 0.0,
                "active_connections": 1,
                "response_time_ms": 0.0
            }
        }
        
        if self.processing_status_service:
            try:
                # í˜„ìž¬ ì§„í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤
                active_statuses = self.processing_status_service.get_active_processes()
                pending_statuses = self.processing_status_service.get_pending_processes()
                
                real_time_metrics["current_processing"].update({
                    "active_processes": len(active_statuses) if active_statuses else 0,
                    "pending_processes": len(pending_statuses) if pending_statuses else 0
                })
                
                # ëŒ€ê¸°ì—´ ìƒíƒœ (ì¶”ì •)
                if self.embedding_service:
                    pending_embeddings = self.embedding_service.get_pending_embeddings()
                    real_time_metrics["queue_status"]["embedding_queue_size"] = len(pending_embeddings)
                
            except Exception as e:
                real_time_metrics["current_processing"]["error"] = str(e)
        
        # ë°°ì¹˜ ì²˜ë¦¬ ë©”íŠ¸ë¦­ìŠ¤
        if self.batch_processing_service:
            try:
                active_jobs = self.batch_processing_service.get_active_jobs()
                if active_jobs:
                    total_progress = sum(job.progress_percentage for job in active_jobs)
                    avg_progress = total_progress / len(active_jobs) if active_jobs else 0
                    
                    real_time_metrics["current_processing"]["batch_jobs_active"] = len(active_jobs)
                    real_time_metrics["current_processing"]["average_batch_progress"] = avg_progress
                    
            except Exception as e:
                real_time_metrics["current_processing"]["batch_error"] = str(e)
        
        return real_time_metrics
    
    def _get_performance_trends(self, time_range_hours: int) -> Dict[str, Any]:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        trends = {
            "processing_volume_trend": {
                "hourly_counts": [],
                "trend_direction": "stable",  # up, down, stable
                "peak_hours": [],
                "low_hours": []
            },
            "error_rate_trend": {
                "hourly_error_rates": [],
                "trend_direction": "stable",
                "average_error_rate": 0.0
            },
            "response_time_trend": {
                "hourly_avg_times": [],
                "trend_direction": "stable",
                "peak_response_time": 0.0,
                "average_response_time": 0.0
            }
        }
        
        # Mock íŠ¸ë Œë“œ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ê³„ì‚°)
        current_time = datetime.now()
        for i in range(time_range_hours):
            hour_time = current_time - timedelta(hours=i)
            
            # ì‹œê°„ëŒ€ë³„ ì²˜ë¦¬ëŸ‰ ì‹œë®¬ë ˆì´ì…˜
            hour_count = max(0, 50 - abs(12 - hour_time.hour) * 2)  # ë‚®ì— ë§Žê³  ë°¤ì— ì ìŒ
            trends["processing_volume_trend"]["hourly_counts"].append({
                "hour": hour_time.strftime("%H:00"),
                "count": hour_count
            })
            
            # ì‹œê°„ëŒ€ë³„ ì—ëŸ¬ìœ¨
            error_rate = min(5.0, abs(hour_time.hour - 14) * 0.2)  # ì˜¤í›„ 2ì‹œì— ê°€ìž¥ ë‚®ìŒ
            trends["error_rate_trend"]["hourly_error_rates"].append({
                "hour": hour_time.strftime("%H:00"),
                "error_rate": error_rate
            })
            
            # ì‹œê°„ëŒ€ë³„ ì‘ë‹µì‹œê°„
            response_time = 800 + abs(hour_time.hour - 15) * 50  # ì˜¤í›„ 3ì‹œì— ê°€ìž¥ ë¹ ë¦„
            trends["response_time_trend"]["hourly_avg_times"].append({
                "hour": hour_time.strftime("%H:00"),
                "avg_time_ms": response_time
            })
        
        return trends
    
    def _get_bottleneck_analysis(self) -> Dict[str, Any]:
        """ë³‘ëª© ë¶„ì„"""
        bottleneck_analysis = {
            "identified_bottlenecks": [],
            "stage_performance": {},
            "resource_constraints": [],
            "optimization_opportunities": []
        }
        
        # ë‹¨ê³„ë³„ ì„±ëŠ¥ ë¶„ì„
        stage_metrics = self._get_stage_metrics()
        slowest_stages = sorted(stage_metrics, key=lambda x: x.get("average_duration_ms", 0), reverse=True)[:3]
        
        for stage in slowest_stages:
            if stage.get("average_duration_ms", 0) > 1000:  # 1ì´ˆ ì´ìƒì¸ ê²½ìš° ë³‘ëª©ìœ¼ë¡œ ê°„ì£¼
                bottleneck_analysis["identified_bottlenecks"].append({
                    "stage": stage["display_name"],
                    "avg_duration_ms": stage["average_duration_ms"],
                    "impact": "high" if stage["average_duration_ms"] > 3000 else "medium"
                })
        
        # ë¦¬ì†ŒìŠ¤ ì œì•½ ë¶„ì„
        if self.embedding_service:
            try:
                embedding_stats = self.embedding_service.get_embedding_statistics()
                if embedding_stats.get("total_embeddings", 0) > 5000:
                    bottleneck_analysis["resource_constraints"].append({
                        "type": "memory",
                        "description": "ëŒ€ëŸ‰ì˜ ìž„ë² ë”©ì´ ë©”ëª¨ë¦¬ì— ì €ìž¥ë¨",
                        "recommendation": "ë²¡í„° DB ë„ìž… ë˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”"
                    })
            except:
                pass
        
        # ìµœì í™” ê¸°íšŒ
        bottleneck_analysis["optimization_opportunities"] = [
            {
                "area": "ìž„ë² ë”© ì²˜ë¦¬",
                "opportunity": "ë°°ì¹˜ í¬ê¸° ìµœì í™”",
                "expected_improvement": "30-50% ì„±ëŠ¥ í–¥ìƒ"
            },
            {
                "area": "ë©”ëª¨ë¦¬ ì‚¬ìš©",
                "opportunity": "ë²¡í„° ì••ì¶• ì ìš©",
                "expected_improvement": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 40% ê°ì†Œ"
            },
            {
                "area": "I/O ìµœì í™”",
                "opportunity": "ë¹„ë™ê¸° ì²˜ë¦¬ ë„ìž…",
                "expected_improvement": "ì²˜ë¦¬ëŸ‰ 2ë°° ì¦ê°€"
            }
        ]
        
        return bottleneck_analysis
    
    def _get_error_analysis(self) -> Dict[str, Any]:
        """ì—ëŸ¬ ë¶„ì„"""
        error_analysis = {
            "error_distribution": {},
            "common_errors": [],
            "error_trends": {},
            "recovery_metrics": {}
        }
        
        if self.processing_status_service:
            try:
                # ì‹¤íŒ¨í•œ ìž„ë² ë”©ë“¤ ë¶„ì„
                if self.embedding_service:
                    failed_embeddings = self.embedding_service.get_failed_embeddings()
                    error_analysis["error_distribution"]["embedding_errors"] = len(failed_embeddings)
                
                # ê³µí†µ ì—ëŸ¬ íŒ¨í„´
                error_analysis["common_errors"] = [
                    {
                        "error_type": "ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨",
                        "frequency": len(failed_embeddings) if 'failed_embeddings' in locals() else 0,
                        "common_cause": "ë¹ˆ í…ìŠ¤íŠ¸ ë˜ëŠ” ì°¨ì› ë¶ˆì¼ì¹˜"
                    },
                    {
                        "error_type": "ë©”ëª¨ë¦¬ ë¶€ì¡±",
                        "frequency": 2,
                        "common_cause": "ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì´ˆê³¼"
                    }
                ]
                
            except Exception as e:
                error_analysis["analysis_error"] = str(e)
        
        return error_analysis
    
    def _get_resource_utilization(self) -> Dict[str, Any]:
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ """
        return {
            "cpu_utilization": {
                "current_percent": 25.0,  # Mock ë°ì´í„°
                "average_percent": 22.5,
                "peak_percent": 85.0
            },
            "memory_utilization": {
                "current_mb": 512,
                "available_mb": 2048,
                "peak_mb": 1024,
                "utilization_percent": 25.0
            },
            "storage_utilization": {
                "vector_data_mb": 125,
                "document_data_mb": 45,
                "temp_data_mb": 23,
                "total_used_mb": 193
            },
            "network_utilization": {
                "api_calls_per_minute": 15,
                "data_transferred_mb": 5.2,
                "average_latency_ms": 450
            }
        }
    
    def _get_performance_recommendations(self) -> List[Dict[str, str]]:
        """ì„±ëŠ¥ ê°œì„  ê¶Œìž¥ì‚¬í•­"""
        recommendations = []
        
        # ì²˜ë¦¬ëŸ‰ ê¸°ë°˜ ê¶Œìž¥ì‚¬í•­
        overall_metrics = self._get_overall_metrics()
        embedding_count = overall_metrics["embedding_processing"]["total_embeddings"]
        
        if embedding_count > 1000:
            recommendations.append({
                "category": "scalability",
                "priority": "high",
                "recommendation": "ë²¡í„° DB ë„ìž…ìœ¼ë¡œ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ìµœì í™”",
                "expected_benefit": "ì¿¼ë¦¬ ì„±ëŠ¥ 10ë°° í–¥ìƒ"
            })
        
        if embedding_count > 100:
            recommendations.append({
                "category": "performance",
                "priority": "medium",
                "recommendation": "ìž„ë² ë”© ë°°ì¹˜ í¬ê¸°ë¥¼ 32ì—ì„œ 64ë¡œ ì¦ê°€",
                "expected_benefit": "ì²˜ë¦¬ ì†ë„ 30% í–¥ìƒ"
            })
        
        # ì¼ë°˜ì ì¸ ê¶Œìž¥ì‚¬í•­
        recommendations.extend([
            {
                "category": "monitoring",
                "priority": "medium",
                "recommendation": "ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ìŠ¤ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•",
                "expected_benefit": "ë¬¸ì œ ì¡°ê¸° ë°œê²¬ ë° ëŒ€ì‘"
            },
            {
                "category": "caching",
                "priority": "low",
                "recommendation": "ìž„ë² ë”© ê²°ê³¼ ìºì‹± êµ¬í˜„",
                "expected_benefit": "ì¤‘ë³µ ê³„ì‚° ì œê±°ë¡œ 30% ì„±ëŠ¥ í–¥ìƒ"
            },
            {
                "category": "optimization",
                "priority": "low", 
                "recommendation": "ë¹„ë™ê¸° ì²˜ë¦¬ ë„ìž…ìœ¼ë¡œ ë³‘ë ¬ì„± í–¥ìƒ",
                "expected_benefit": "ì²˜ë¦¬ëŸ‰ 2-3ë°° ì¦ê°€"
            }
        ])
        
        return recommendations
    
    def _calculate_average_stage_duration(self, stage: str) -> float:
        """ë‹¨ê³„ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° (Mock)"""
        stage_durations = {
            "DOCUMENT_UPLOADED": 50,
            "CHUNKING_PENDING": 10,
            "CHUNKING_PROCESSING": 500,
            "CHUNKING_COMPLETED": 25,
            "EMBEDDING_PENDING": 20,
            "EMBEDDING_PROCESSING": 1200,
            "EMBEDDING_COMPLETED": 30,
        }
        return stage_durations.get(stage, 100)
    
    def _get_stage_display_name(self, stage: str) -> str:
        """ë‹¨ê³„ëª…ì„ í‘œì‹œìš©ìœ¼ë¡œ ë³€í™˜"""
        display_names = {
            "DOCUMENT_UPLOADED": "ë¬¸ì„œ ì—…ë¡œë“œ",
            "CHUNKING_PENDING": "ì²­í‚¹ ëŒ€ê¸°",
            "CHUNKING_PROCESSING": "ì²­í‚¹ ì²˜ë¦¬ì¤‘",
            "CHUNKING_COMPLETED": "ì²­í‚¹ ì™„ë£Œ",
            "CHUNKING_FAILED": "ì²­í‚¹ ì‹¤íŒ¨",
            "EMBEDDING_PENDING": "ìž„ë² ë”© ëŒ€ê¸°",
            "EMBEDDING_PROCESSING": "ìž„ë² ë”© ì²˜ë¦¬ì¤‘", 
            "EMBEDDING_COMPLETED": "ìž„ë² ë”© ì™„ë£Œ",
            "EMBEDDING_FAILED": "ìž„ë² ë”© ì‹¤íŒ¨"
        }
        return display_names.get(stage, stage)
    
    def _calculate_stage_success_rate(self, stage_statuses: List) -> float:
        """ë‹¨ê³„ë³„ ì„±ê³µë¥  ê³„ì‚°"""
        if not stage_statuses:
            return 0.0
        
        completed = len([s for s in stage_statuses if "COMPLETED" in s.stage.name])
        total = len(stage_statuses)
        
        return (completed / total) * 100 if total > 0 else 0.0
    
    def get_quick_metrics(self) -> Dict[str, Any]:
        """ë¹ ë¥¸ ë©”íŠ¸ë¦­ìŠ¤ ì¡°íšŒ"""
        try:
            overall = self._get_overall_metrics()
            return {
                "total_processed": overall["embedding_processing"]["total_embeddings"],
                "error_rate": overall["system_performance"]["error_rate_percent"],
                "status": "healthy" if overall["system_performance"]["error_rate_percent"] < 5 else "warning"
            }
        except:
            return {"status": "unknown", "total_processed": 0, "error_rate": 0}
