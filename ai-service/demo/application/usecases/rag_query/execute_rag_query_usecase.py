"""
Execute RAG Query Use Case
RAG Query ì‹¤í–‰ ìœ ìŠ¤ì¼€ì´ìŠ¤

ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ë¬¸ì„œ ê²€ìƒ‰ í›„ AI ë‹µë³€ì„ ìƒì„±í•˜ëŠ” Use Caseì…ë‹ˆë‹¤.
ê³µí†µ ì˜¤ë¥˜ ì²˜ë¦¬ì™€ ì‘ë‹µ í˜•ì‹ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.
"""

import logging
from typing import Dict, Any, Tuple, List
from domain.services.retrieval_service import RetrievalService
from domain.services.generation_service import GenerationService
from domain.services.document_management_service import DocumentService
from domain.services.query_template_service import QueryTemplateService
from domain.entities.query import Query
from application.common import (
    handle_usecase_errors,
    validate_required_fields,
    ResponseFormatter,
    log_usecase_execution,
    validate_string_not_empty
)

logger = logging.getLogger(__name__)


class ExecuteRAGQueryUseCase:
    """RAG Query ì‹¤í–‰ ìœ ìŠ¤ì¼€ì´ìŠ¤"""
    
    def __init__(
        self,
        retrieval_service: RetrievalService,
        generation_service: GenerationService,
        document_service: DocumentService,
        query_template_service: QueryTemplateService = None
    ):
        self.retrieval_service = retrieval_service
        self.generation_service = generation_service
        self.document_service = document_service
        self.query_template_service = query_template_service or QueryTemplateService()
        logger.info("âœ… ExecuteRAGQueryUseCase initialized")
    
    @handle_usecase_errors(
        default_error_message="RAG Query ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        log_error=True
    )
    @validate_required_fields(
        question=validate_string_not_empty
    )
    @log_usecase_execution("ExecuteRAGQueryUseCase")
    def execute(
        self,
        question: str,
        max_sources: int = 3,
        similarity_threshold: float = 0.4
    ) -> Dict[str, Any]:
        """RAG Query ì‹¤í–‰"""
        # Query ì—”í‹°í‹° ìƒì„±
        query = Query(
            text=question,
            query_type="RAG_QUESTION",
            max_results=max_sources,
            similarity_threshold=similarity_threshold
        )
        
        # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        search_results = self.retrieval_service.search_similar_chunks(
            query=query,
            top_k=max_sources,
            similarity_threshold=similarity_threshold
        )
        
        if not search_results:
            return ResponseFormatter.success(
                data={
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•œ í›„ ì„ë² ë”©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    "sources": "ğŸ“­ ë²¡í„°ìŠ¤í† ì–´ì— ì²­í¬ê°€ ì—†ê±°ë‚˜ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "query_id": str(query.query_id),
                    "search_results_count": 0,
                    "used_sources_count": 0
                },
                message="ğŸ¤– RAG Queryê°€ ì‹¤í–‰ë˜ì—ˆì§€ë§Œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
        
        # RAG ì‘ë‹µ ìƒì„±
        rag_response = self.generation_service.generate_rag_response(
            query=query,
            search_results=search_results,
            max_sources=max_sources
        )
        
        # ì¶œì²˜ ì •ë³´ í¬ë§·íŒ…
        sources_text = self._format_sources(search_results[:max_sources])
        
        return ResponseFormatter.success(
            data={
                "answer": rag_response.answer,
                "sources": sources_text,
                "query_id": str(query.query_id),
                "response_id": str(rag_response.rag_response_id),
                "confidence_score": rag_response.confidence_score,
                "processing_time_ms": rag_response.processing_time_ms,
                "search_results_count": len(search_results),
                "used_sources_count": len(search_results[:max_sources])
            },
            message="ğŸ¤– RAG Queryê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤"
        )
    
    def _format_sources(self, search_results) -> str:
        """ì¶œì²˜ ì •ë³´ í¬ë§·íŒ…"""
        if not search_results:
            return "ğŸ“­ ì‚¬ìš©ëœ ì¶œì²˜ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        sources_parts = ["ğŸ“š **ì°¸ì¡°ëœ ì²­í¬ë“¤:**\n"]
        
        for i, result in enumerate(search_results):
            chunk = result.chunk
            similarity = result.similarity_score
            relevance = result.get_relevance_level()
            
            # ì²­í¬ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 150ì)
            content_preview = chunk.content[:150] + "..." if len(chunk.content) > 150 else chunk.content
            
            source_info = f"""
**ì²­í¬ {i+1}** (ìœ ì‚¬ë„: {similarity:.3f}, ê´€ë ¨ì„±: {relevance})
- **ì†Œì† ë¬¸ì„œ ID**: {str(chunk.document_id)[:8]}...
- **ì²­í¬ ID**: {str(chunk.chunk_id)[:8]}...
- **ì²­í¬ ì¸ë±ìŠ¤**: {chunk.chunk_index}
- **ì²­í¬ í¬ê¸°**: {len(chunk.content)} ê¸€ì
- **ì²­í¬ ë‚´ìš©**: {content_preview}
---"""
            sources_parts.append(source_info)
        
        return "\n".join(sources_parts)
    
    @handle_usecase_errors(
        default_error_message="ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        log_error=True
    )
    @log_usecase_execution("ExecuteRAGQueryUseCase")
    def get_sample_queries_for_loaded_documents(self) -> List[Dict[str, Any]]:
        """ë¡œë“œëœ ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„±"""
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸: ê¸°ë³¸ ìƒ˜í”Œ ì¿¼ë¦¬ ë°˜í™˜ (ë¬¸ì„œ ë¡œë“œ ìƒíƒœ ë¬´ê´€)
        sample_queries = [
            {
                "query": "AI í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ì˜ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "expected_type": "PROJECT",
                "confidence": 0.95,
                "reasoning": "í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ  ìŠ¤íƒì„ ë¬»ëŠ” ì§ˆë¬¸",
                "source_document": "AI Portfolio Project"
            },
            {
                "query": "í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜ë¥¼ ì„ íƒí•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "expected_type": "EXPERIENCE",
                "confidence": 0.91,
                "reasoning": "ì•„í‚¤í…ì²˜ ì„ íƒ ê²½í—˜ì„ ë¬»ëŠ” ì§ˆë¬¸",
                "source_document": "Architecture Q&A"
            },
            {
                "query": "RAG ì‹œìŠ¤í…œì—ì„œ ë²¡í„° ê²€ìƒ‰ì€ ì–´ë–»ê²Œ êµ¬í˜„í–ˆë‚˜ìš”?",
                "expected_type": "TECHNICAL_SKILL",
                "confidence": 0.89,
                "reasoning": "êµ¬ì²´ì  ê¸°ìˆ  êµ¬í˜„ì„ ë¬»ëŠ” ì§ˆë¬¸",
                "source_document": "RAG System Q&A"
            },
            {
                "query": "ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë°°ìš´ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "expected_type": "EXPERIENCE", 
                "confidence": 0.88,
                "reasoning": "í”„ë¡œì íŠ¸ ê²½í—˜ê³¼ í•™ìŠµì„ ë¬»ëŠ” ì§ˆë¬¸",
                "source_document": "Learning Experience"
            }
        ]
        
        return ResponseFormatter.list_response(
            data=sample_queries,
            count=len(sample_queries),
            message="ğŸ“ ìƒ˜í”Œ ì¿¼ë¦¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤"
        )
