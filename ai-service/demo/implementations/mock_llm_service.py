"""
Mock LLM Service for Demo environments.
"""
from typing import Dict, Any

class MockLlmService:
    """A mock LLM service that returns a templated response without calling a real LLM."""
    async def generate_response(self, query: str, context: str) -> str:
        """Generates a mock RAG response."""
        context_length = len(context)
        context_preview = context[:200] + "..." if context_length > 200 else context

        return f"""[DEMO RESPONSE]

Query: "{query}"

Based on the {context_length} characters of context found, here is a mock response:

-- Context Preview --
{context_preview}
---------------------

This response was generated by the MockLlmService. 
In a production environment, a real language model (like Gemini) would be used to generate a more intelligent and relevant answer based on the provided context.
"""

    def get_model_info(self) -> Dict[str, Any]:
        return {
            "model_name": "mock-llm-service",
            "is_mock": True
        }
