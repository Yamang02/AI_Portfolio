"""
Query & Vector Search Tab Adapter
Query & Vector Search íƒ­ ì–´ëŒ‘í„°

RAG ì‹œìŠ¤í…œì˜ Queryì™€ Vector Search ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” íƒ­ ì–´ëŒ‘í„°ì…ë‹ˆë‹¤.
Queryì™€ Vector Search ê¸°ëŠ¥ì˜ UIë§Œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""

import gradio as gr
import logging
from typing import List
from application.usecases.execute_rag_query_usecase import ExecuteRAGQueryUseCase
from application.usecases.execute_vector_search_usecase import ExecuteVectorSearchUseCase
from application.usecases.get_vector_store_info_usecase import GetVectorStoreInfoUseCase

logger = logging.getLogger(__name__)


class QueryVectorSearchTabAdapter:
    """Query & Vector Search íƒ­ ì–´ëŒ‘í„° - Queryì™€ Vector Search UIë§Œ ë‹´ë‹¹"""
    
    def __init__(self, service_factory):
        self.service_factory = service_factory
        
        # UseCaseë“¤ì„ ì§ì ‘ ìƒì„± (ì„œë¹„ìŠ¤ íŒ©í† ë¦¬ì—ì„œ í•„ìš”í•œ ì„œë¹„ìŠ¤ë“¤ì„ ì£¼ì…)
        self.execute_rag_query_usecase = ExecuteRAGQueryUseCase(
            retrieval_service=service_factory.get_retrieval_service(),
            generation_service=service_factory.get_generation_service(),
            document_service=service_factory.get_document_service()
        )
        
        self.execute_vector_search_usecase = ExecuteVectorSearchUseCase(
            retrieval_service=service_factory.get_retrieval_service()
        )
        
        self.get_vector_store_info_usecase = GetVectorStoreInfoUseCase(
            embedding_service=service_factory.get_embedding_service(),
            chunking_service=service_factory.get_chunking_service()
        )
        
        logger.info("âœ… Query & Vector Search Tab Adapter initialized with Use Cases")
    
    def create_tab(self) -> gr.Tab:
        """Query & Vector Search íƒ­ ìƒì„±"""
        with gr.Tab("ğŸ” Query/VectorSearch", id=4) as tab:
            gr.Markdown("## ğŸ” Query & Vector Search")
            gr.Markdown("RAG ì‹œìŠ¤í…œì˜ Query ê¸°ëŠ¥ê³¼ Vector Search ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤")
            
            # ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ì˜ì—­ (ì„œë¸Œíƒ­ë“¤ ìƒë‹¨)
            with gr.Row():
                with gr.Column(scale=1):
                    refresh_vectorstore_btn = gr.Button("ğŸ”„ VectorStore ì •ë³´ ìƒˆë¡œê³ ì¹¨", variant="secondary", size="sm")
                with gr.Column(scale=4):
                    vectorstore_info = gr.Textbox(
                        label="ğŸ“Š VectorStore ìƒíƒœ",
                        value="ğŸ”„ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                        lines=3,
                        interactive=False
                    )
            
            # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            refresh_vectorstore_btn.click(
                fn=self._get_vectorstore_info,
                outputs=[vectorstore_info]
            )
            
            # íƒ­ ë‚´ ì„œë¸Œíƒ­ êµ¬ì„±
            with gr.Tabs() as sub_tabs:
                # Query íƒ­
                with gr.Tab("ğŸ’¬ Query") as query_tab:
                    gr.Markdown("### ğŸ’¬ RAG Query")
                    gr.Markdown("""
                    RAG ì‹œìŠ¤í…œì„ í†µí•´ ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
                    
                    **ğŸ§  ì§€ëŠ¥í˜• ì¿¼ë¦¬ ë¶„ë¥˜ ì‹œìŠ¤í…œ**: ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ì™¸ë¶€ LLMì„ í†µí•´ ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ 
                    ìµœì í™”ëœ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. Demo í™˜ê²½ì—ì„œëŠ” Mock LLMì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    
                    **ë¶„ë¥˜ íƒ€ì…**: PROJECT, EXPERIENCE, TECHNICAL_SKILL, GENERAL
                    """)
                    
                    with gr.Row():
                        # ì™¼ìª½: ì§ˆë¬¸ ì…ë ¥
                        with gr.Column(scale=1):
                            # ìƒ˜í”Œ ì¿¼ë¦¬ ì„ íƒ
                            with gr.Row():
                                load_samples_btn = gr.Button("ğŸ“‹ ë¡œë“œëœ ë¬¸ì„œ ê¸°ë°˜ ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„±", size="sm")
                            
                            sample_query_dropdown = gr.Dropdown(
                                label="ğŸ¯ ìƒ˜í”Œ ì§ˆì˜ ì„ íƒ (ì§€ëŠ¥í˜• ì¿¼ë¦¬ ë¶„ë¥˜ ë°ëª¨)",
                                choices=self._get_initial_sample_queries(),
                                value=None,
                                interactive=True
                            )
                            
                            question_input = gr.Textbox(
                                label="ì§ˆë¬¸",
                                placeholder="ì˜ˆ: í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                                lines=4
                            )
                            max_sources = gr.Slider(
                                label="ì‚¬ìš©í•  ìµœëŒ€ ì¶œì²˜ ìˆ˜",
                                minimum=1,
                                maximum=5,
                                value=3,
                                step=1
                            )
                            query_btn = gr.Button("ğŸ’¬ Query ì‹¤í–‰", variant="primary")
                        
                        # ì˜¤ë¥¸ìª½: AI ë‹µë³€
                        with gr.Column(scale=2):
                            answer_output = gr.Textbox(
                                label="AI ë‹µë³€",
                                lines=15,
                                interactive=False
                            )
                    
                    # ì¶œì²˜ ë¬¸ì„œ
                    with gr.Row():
                        sources_output = gr.Textbox(
                            label="ì°¸ì¡°ëœ ì¶œì²˜ ë¬¸ì„œ",
                            lines=8,
                            interactive=False
                        )
                
                # Vector Search íƒ­
                with gr.Tab("ğŸ” Vector Search") as vector_search_tab:
                    gr.Markdown("### ğŸ” Vector Search")
                    gr.Markdown("ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.")
                    
                    with gr.Row():
                        # ì™¼ìª½: ê²€ìƒ‰ ì…ë ¥
                        with gr.Column(scale=1):
                            search_input = gr.Textbox(
                                label="ê²€ìƒ‰ ì¿¼ë¦¬",
                                placeholder="ì˜ˆ: í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜, ë„ë©”ì¸ ì£¼ë„ ì„¤ê³„",
                                lines=3
                            )
                            top_k = gr.Slider(
                                label="ìƒìœ„ Kê°œ ê²°ê³¼",
                                minimum=1,
                                maximum=10,
                                value=5,
                                step=1
                            )
                            similarity_threshold = gr.Slider(
                                label="ìœ ì‚¬ë„ ì„ê³„ê°’",
                                minimum=0.0,
                                maximum=1.0,
                                value=0.05,
                                step=0.01
                            )
                            search_btn = gr.Button("ğŸ” Vector Search ì‹¤í–‰", variant="secondary")
                        
                        # ì˜¤ë¥¸ìª½: ê²€ìƒ‰ ê²°ê³¼
                        with gr.Column(scale=2):
                            search_results = gr.Textbox(
                                label="ê²€ìƒ‰ ê²°ê³¼",
                                lines=20,
                                interactive=False
                            )
            
            # Event handlers
            load_samples_btn.click(
                fn=self._load_sample_queries_from_documents,
                outputs=[sample_query_dropdown]
            )
            
            sample_query_dropdown.change(
                fn=self._on_sample_query_selected,
                inputs=[sample_query_dropdown],
                outputs=[question_input]
            )
            
            query_btn.click(
                fn=self._execute_query,
                inputs=[question_input, max_sources],
                outputs=[answer_output, sources_output]
            )
            
            search_btn.click(
                fn=self._execute_vector_search,
                inputs=[search_input, top_k, similarity_threshold],
                outputs=[search_results]
            )
        
        return tab
    
    def _execute_query(self, question: str, max_sources: int) -> tuple:
        """RAG Query ì‹¤í–‰ (UI ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬)"""
        try:
            # UseCase ì‹¤í–‰
            result = self.execute_rag_query_usecase.execute(
                question=question,
                max_sources=max_sources,
                similarity_threshold=0.1
            )
            
            if result["success"]:
                return result["answer"], result["sources"]
            else:
                return result["answer"], result.get("sources", "ì˜¤ë¥˜ë¡œ ì¸í•´ ì¶œì²˜ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"Error in _execute_query: {e}")
            return f"âŒ Query ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "ğŸ“­ ì¶œì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    
    def _execute_vector_search(self, search_query: str, top_k: int, similarity_threshold: float) -> str:
        """Vector Search ì‹¤í–‰ (UI ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬)"""
        try:
            # UseCase ì‹¤í–‰
            result = self.execute_vector_search_usecase.execute(
                search_query=search_query,
                top_k=top_k,
                similarity_threshold=similarity_threshold
            )
            
            return result["results"]
                
        except Exception as e:
            logger.error(f"Error in _execute_vector_search: {e}")
            return f"âŒ Vector Search ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _get_vectorstore_info(self) -> str:
        """ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ì¡°íšŒ (UI ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬)"""
        try:
            # UseCase ì‹¤í–‰
            result = self.get_vector_store_info_usecase.execute()
            
            if result["success"]:
                info = result["vector_store_info"]
                
                # ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ í¬ë§·íŒ… (ì²­í¬ ì¤‘ì‹¬)
                formatted_info = f"""ğŸ“Š **VectorStore ìƒíƒœ ì •ë³´** (ì²­í¬ ê¸°ë°˜)

**ğŸª ê¸°ë³¸ ì •ë³´:**
- ì €ì¥ì†Œ ì´ë¦„: {info['store_basic_info']['store_name']}
- ì €ì¥ì†Œ íƒ€ì…: {info['store_basic_info']['store_type']}
- ì´ˆê¸°í™” ìƒíƒœ: {info['store_basic_info']['initialization_status']}
- ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜: {info['store_basic_info']['search_algorithm']}

**ğŸ¤– ì„ë² ë”© ëª¨ë¸ ì •ë³´:**
- ëª¨ë¸ ì´ë¦„: {info['embedding_model_info']['model_name']}
- ë²¡í„° ì°¨ì›: {info['embedding_model_info']['vector_dimension']}ì°¨ì›
- ëª¨ë¸ íƒ€ì…: {info['embedding_model_info']['model_type']}

**ğŸ“¦ ì²­í¬ ê¸°ë°˜ ë°ì´í„° í†µê³„:**
- ì´ ë¬¸ì„œ ìˆ˜: {info['stored_data_statistics']['total_documents']}ê°œ
- ì´ ì²­í¬ ìˆ˜: {info['stored_data_statistics']['total_chunks']}ê°œ (ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ë¨)
- ì´ ë²¡í„° ìˆ˜: {info['stored_data_statistics']['total_vectors']}ê°œ (ì²­í¬ë³„ ì„ë² ë”©)
- í‰ê·  ì²­í¬ ê¸¸ì´: {info['stored_data_statistics']['average_document_length']:.1f}ê¸€ì
- ì €ì¥ì†Œ í¬ê¸°: {info['stored_data_statistics']['store_size_mb']:.2f}MB

**âš¡ ì„±ëŠ¥ ì •ë³´:**
- í‰ê·  ì„ë² ë”© ìƒì„± ì‹œê°„: {info['performance_info']['average_embedding_time_ms']:.1f}ms
- ì´ ì²˜ë¦¬ ì‹œê°„: {info['performance_info']['total_processing_time_ms']:.1f}ms
- ì„±ê³µë¥ : {info['performance_info']['success_rate']:.1f}%
- ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {info['performance_info']['last_updated']}

**ğŸ” ê²€ìƒ‰ ê°€ëŠ¥ ìƒíƒœ:**
- ë²¡í„° ê²€ìƒ‰ ê°€ëŠ¥: {'âœ… ê°€ëŠ¥' if info['stored_data_statistics']['total_vectors'] > 0 else 'âŒ ë¶ˆê°€ëŠ¥ (ì²­í¬ ì—†ìŒ)'}
- RAG Query ê°€ëŠ¥: {'âœ… ê°€ëŠ¥' if info['stored_data_statistics']['total_vectors'] > 0 else 'âŒ ë¶ˆê°€ëŠ¥ (ì²­í¬ ì—†ìŒ)'}"""
                
                return formatted_info
            else:
                return f"âŒ ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                
        except Exception as e:
            logger.error(f"Error in _get_vectorstore_info: {e}")
            return f"âŒ ë²¡í„°ìŠ¤í† ì–´ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _load_sample_queries_from_documents(self) -> gr.Dropdown:
        """ë¡œë“œëœ ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒ˜í”Œ ì¿¼ë¦¬ ë¡œë“œ"""
        try:
            # UseCaseë¥¼ í†µí•´ ìƒ˜í”Œ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°
            sample_queries = self.execute_rag_query_usecase.get_sample_queries_for_loaded_documents()
            
            if not sample_queries:
                choices = ["ğŸ“­ ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € Document íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”."]
                return gr.Dropdown(choices=choices)
            
            # ì„ íƒ ì˜µì…˜ ìƒì„±
            choices = []
            for query in sample_queries:
                query_type = query.get('expected_type', 'GENERAL')
                confidence = query.get('confidence', 0.0)
                text = query.get('query', '')
                source_doc = query.get('source_document', '')
                choice_text = f"[{query_type}] {text} (ì‹ ë¢°ë„: {confidence:.2f}) - {source_doc}"
                choices.append(choice_text)
            
            # í˜„ì¬ ìƒ˜í”Œ ì¿¼ë¦¬ ì €ì¥ (ì„ íƒ ì‹œ ì‚¬ìš©)
            self._current_sample_queries = sample_queries
            
            logger.info(f"âœ… {len(sample_queries)}ê°œì˜ ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„±ë¨")
            return gr.Dropdown(choices=choices)
            
        except Exception as e:
            logger.error(f"Error loading sample queries from documents: {e}")
            error_choices = [f"âŒ ìƒ˜í”Œ ì¿¼ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"]
            return gr.Dropdown(choices=error_choices)
    
    def _on_sample_query_selected(self, selected_choice: str) -> str:
        """ìƒ˜í”Œ ì¿¼ë¦¬ ì„ íƒ ì‹œ ì²˜ë¦¬"""
        if not selected_choice or not hasattr(self, '_current_sample_queries'):
            return ""
        
        if selected_choice.startswith("ğŸ“­") or selected_choice.startswith("âŒ"):
            return ""
        
        try:
            # ì„ íƒëœ í•­ëª©ì—ì„œ ì‹¤ì œ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for query in self._current_sample_queries:
                query_type = query.get('expected_type', 'GENERAL')
                confidence = query.get('confidence', 0.0)
                text = query.get('query', '')
                source_doc = query.get('source_document', '')
                choice_text = f"[{query_type}] {text} (ì‹ ë¢°ë„: {confidence:.2f}) - {source_doc}"
                
                if choice_text == selected_choice:
                    return text
            
            return ""
        except Exception as e:
            logger.error(f"Error processing selected sample query: {e}")
            return ""
    
    def _get_initial_sample_queries(self) -> List[str]:
        """íƒ­ ë¡œë“œ ì‹œ ì´ˆê¸° ìƒ˜í”Œ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # UseCaseë¥¼ í†µí•´ ìƒ˜í”Œ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°
            sample_queries = self.execute_rag_query_usecase.get_sample_queries_for_loaded_documents()
            
            if not sample_queries:
                return ["ğŸ“‹ ìœ„ì˜ 'ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„±' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¡œë“œëœ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ë¥¼ í™•ì¸í•˜ì„¸ìš”"]
            
            # ì„ íƒ ì˜µì…˜ ìƒì„± (ìµœëŒ€ 5ê°œë§Œ)
            choices = []
            for query in sample_queries[:5]:  # ì´ˆê¸°ì—ëŠ” 5ê°œë§Œ í‘œì‹œ
                query_type = query.get('expected_type', 'GENERAL')
                confidence = query.get('confidence', 0.0)
                text = query.get('query', '')
                source_doc = query.get('source_document', '')
                choice_text = f"[{query_type}] {text} (ì‹ ë¢°ë„: {confidence:.2f}) - {source_doc}"
                choices.append(choice_text)
            
            # í˜„ì¬ ìƒ˜í”Œ ì¿¼ë¦¬ ì €ì¥ (ì„ íƒ ì‹œ ì‚¬ìš©)
            self._current_sample_queries = sample_queries
            
            logger.info(f"âœ… ì´ˆê¸° ìƒ˜í”Œ ì¿¼ë¦¬ {len(choices)}ê°œ ë¡œë“œë¨")
            return choices
            
        except Exception as e:
            logger.error(f"Error loading initial sample queries: {e}")
            return ["ğŸ“‹ ìƒ˜í”Œ ì¿¼ë¦¬ë¥¼ ë¡œë“œí•˜ë ¤ë©´ ìœ„ì˜ 'ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„±' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"]
