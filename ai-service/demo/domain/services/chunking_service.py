"""
Chunking Service - Demo Domain Layer
ë°ëª¨ ë„ë©”ì¸ ì²­í‚¹ ì„œë¹„ìŠ¤

ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ë„ë©”ì¸ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
coreì˜ chunking ì„¤ì •ì„ í™œìš©í•©ë‹ˆë‹¤.
"""

import logging
import re
from typing import List, Dict, Any, Optional
from ..entities.document import Document
from ..entities.chunk import Chunk, ChunkId
from core.shared.value_objects.document_entities import DocumentId
from core.shared.config.chunking.chunking_config_manager import ChunkingConfigManager

logger = logging.getLogger(__name__)


class ChunkingService:
    """ì²­í‚¹ ë„ë©”ì¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self, processing_status_service=None):
        self.chunks: Dict[str, Chunk] = {}
        self.config_manager = ChunkingConfigManager()
        self.processing_status_service = processing_status_service
        logger.info("âœ… Chunking Service initialized with config manager")
    
    def chunk_document(
        self,
        document: Document,
        chunking_strategy: Optional[str] = None,
        custom_chunk_size: Optional[int] = None,
        custom_chunk_overlap: Optional[int] = None
    ) -> List[Chunk]:
        """ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• """
        try:
            # ë¬¸ì„œ ìœ í˜• ìë™ ê°ì§€
            if not chunking_strategy:
                chunking_strategy = self._detect_document_type(document)
            
            # ì„¤ì •ì—ì„œ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
            strategy_config = self.config_manager.get_strategy_config(chunking_strategy)
            params = strategy_config.get("parameters", {})
            
            # ì „ëµë³„ ê¸°ë³¸ê°’ ìš°ì„  ì‚¬ìš©, ìˆ˜ë™ ì„¤ì •ì€ ì˜¤ë²„ë¼ì´ë“œë¡œ ì‚¬ìš©
            chunk_size = params.get("chunk_size", 500)
            chunk_overlap = params.get("chunk_overlap", 75)
            
            # ìˆ˜ë™ ì„¤ì •ì´ ì œê³µëœ ê²½ìš°ì—ë§Œ ì˜¤ë²„ë¼ì´ë“œ
            if custom_chunk_size is not None:
                chunk_size = custom_chunk_size
                logger.info(f"ğŸ”§ ìˆ˜ë™ ì²­í¬ í¬ê¸° ì˜¤ë²„ë¼ì´ë“œ: {chunk_size}")
            if custom_chunk_overlap is not None:
                chunk_overlap = custom_chunk_overlap
                logger.info(f"ğŸ”§ ìˆ˜ë™ ì²­í¬ ê²¹ì¹¨ ì˜¤ë²„ë¼ì´ë“œ: {chunk_overlap}")
            
            preserve_structure = params.get("preserve_structure", True)
            
            logger.info(f"ğŸ“‹ ì²­í‚¹ ì „ëµ: {chunking_strategy} (í¬ê¸°: {chunk_size}, ê²¹ì¹¨: {chunk_overlap})")
            
            # ì „ëµë³„ ì²­í‚¹ ì‹¤í–‰
            if chunking_strategy == "PROJECT":
                chunks = self._chunk_project_document(document, chunk_size, chunk_overlap, strategy_config)
            elif chunking_strategy == "QA":
                chunks = self._chunk_qa_document(document, chunk_size, chunk_overlap, strategy_config)
            else:
                chunks = self._chunk_text_document(document, chunk_size, chunk_overlap, preserve_structure)
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥ ë° ì²˜ë¦¬ ìƒíƒœ ìƒì„±
            for chunk in chunks:
                self.chunks[str(chunk.chunk_id)] = chunk
                
                # ProcessingStatus ìë™ ìƒì„±
                if self.processing_status_service:
                    self.processing_status_service.create_status(chunk)
            
            logger.info(f"âœ… ë¬¸ì„œ ì²­í‚¹ ì™„ë£Œ: {document.source} â†’ {len(chunks)}ê°œ ì²­í¬ ({chunking_strategy} ì „ëµ)")
            return chunks
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì²­í‚¹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def chunk_documents(
        self,
        documents: List[Document],
        chunking_strategy: Optional[str] = None,
        custom_chunk_size: Optional[int] = None,
        custom_chunk_overlap: Optional[int] = None
    ) -> List[Chunk]:
        """ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• """
        all_chunks = []
        
        for document in documents:
            chunks = self.chunk_document(
                document, 
                chunking_strategy, 
                custom_chunk_size, 
                custom_chunk_overlap
            )
            all_chunks.extend(chunks)
        
        logger.info(f"ğŸ“Š ì´ {len(all_chunks)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ")
        return all_chunks
    
    def get_chunks_by_document(self, document_id: str) -> List[Chunk]:
        """ë¬¸ì„œë³„ ì²­í¬ ì¡°íšŒ"""
        return [
            chunk for chunk in self.chunks.values()
            if str(chunk.document_id) == document_id
        ]
    
    def get_chunk_by_id(self, chunk_id: str) -> Optional[Chunk]:
        """ì²­í¬ IDë¡œ ì²­í¬ ì¡°íšŒ"""
        return self.chunks.get(chunk_id)
    
    def get_all_chunks(self) -> List[Chunk]:
        """ëª¨ë“  ì²­í¬ ì¡°íšŒ"""
        return list(self.chunks.values())
    
    def get_chunks_count(self) -> int:
        """ì €ì¥ëœ ì²­í¬ ìˆ˜ ë°˜í™˜"""
        return len(self.chunks)
    
    def clear_chunks(self) -> None:
        """ëª¨ë“  ì²­í¬ ì‚­ì œ"""
        self.chunks.clear()
        logger.info("ğŸ—‘ï¸ ëª¨ë“  ì²­í¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def delete_chunks_by_document(self, document_id: str) -> int:
        """íŠ¹ì • ë¬¸ì„œì˜ ì²­í¬ë“¤ ì‚­ì œ"""
        deleted_count = 0
        chunks_to_delete = []
        
        for chunk_id, chunk in self.chunks.items():
            if str(chunk.document_id) == document_id:
                chunks_to_delete.append(chunk_id)
        
        for chunk_id in chunks_to_delete:
            del self.chunks[chunk_id]
            deleted_count += 1
        
        logger.info(f"ğŸ—‘ï¸ ë¬¸ì„œ {document_id}ì˜ {deleted_count}ê°œ ì²­í¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤")
        return deleted_count
    
    def get_chunking_statistics(self) -> Dict[str, Any]:
        """ì²­í‚¹ í†µê³„ ë°˜í™˜"""
        total_chunks = len(self.chunks)
        if total_chunks == 0:
            return {
                "total_chunks": 0,
                "total_characters": 0,
                "average_chars_per_chunk": 0,
                "document_chunk_counts": {},
                "chunk_size_distribution": {},
                "strategy_distribution": {}
            }
        
        total_chars = sum(len(chunk.content) for chunk in self.chunks.values())
        
        # ë¬¸ì„œë³„ ì²­í¬ ìˆ˜ ë° ì „ëµë³„ ë¶„í¬
        doc_chunk_counts = {}
        chunk_sizes = []
        strategy_counts = {}
        
        for chunk in self.chunks.values():
            doc_id = str(chunk.document_id)
            if doc_id not in doc_chunk_counts:
                doc_chunk_counts[doc_id] = 0
            doc_chunk_counts[doc_id] += 1
            chunk_sizes.append(len(chunk.content))
            
            # ì „ëµë³„ ë¶„í¬ (chunk_sizeë¡œ ì¶”ì •)
            if chunk.chunk_size <= 500:
                strategy = "TEXT"
            elif chunk.chunk_size <= 600:
                strategy = "PROJECT"
            else:
                strategy = "QA"
            
            if strategy not in strategy_counts:
                strategy_counts[strategy] = 0
            strategy_counts[strategy] += 1
        
        # ì²­í¬ í¬ê¸° ë¶„í¬
        size_distribution = {}
        for size in chunk_sizes:
            size_range = f"{(size // 100) * 100}-{(size // 100) * 100 + 99}"
            if size_range not in size_distribution:
                size_distribution[size_range] = 0
            size_distribution[size_range] += 1
        
        return {
            "total_chunks": total_chunks,
            "total_characters": total_chars,
            "average_chars_per_chunk": total_chars / total_chunks,
            "min_chunk_size": min(chunk_sizes),
            "max_chunk_size": max(chunk_sizes),
            "document_chunk_counts": doc_chunk_counts,
            "chunk_size_distribution": size_distribution,
            "strategy_distribution": strategy_counts
        }
    
    def get_available_strategies(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì²­í‚¹ ì „ëµ ëª©ë¡ ë°˜í™˜"""
        return self.config_manager.get_available_strategies()
    
    def _detect_document_type(self, document: Document) -> str:
        """ë¬¸ì„œ ìœ í˜• ìë™ ê°ì§€"""
        # ë¨¼ì € Document ë©”íƒ€ë°ì´í„°ì—ì„œ document_type í™•ì¸
        if document.metadata and document.metadata.document_type:
            doc_type = document.metadata.document_type.value
            logger.info(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°ì—ì„œ ë¬¸ì„œ ìœ í˜• ê°ì§€: {doc_type}")
            return doc_type
        
        # ë©”íƒ€ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‚´ìš© ê¸°ë°˜ ê°ì§€
        detection_config = self.config_manager.get_detection_config()
        content = document.content.lower()
        source = document.source.lower()
        
        # íŒŒì¼ ê²½ë¡œ/ì´ë¦„ ê¸°ë°˜ ê°ì§€
        path_patterns = detection_config.get("path_patterns", {})
        for doc_type, patterns in path_patterns.items():
            for pattern in patterns:
                if re.search(pattern, source):
                    logger.info(f"ğŸ“‹ ê²½ë¡œ íŒ¨í„´ìœ¼ë¡œ {doc_type} ê°ì§€: {pattern}")
                    return doc_type
        
        # ë‚´ìš© ê¸°ë°˜ ê°ì§€
        content_patterns = detection_config.get("content_patterns", {})
        for doc_type, config in content_patterns.items():
            patterns = config.get("patterns", [])
            min_matches = config.get("min_matches", 1)
            matches = 0
            
            for pattern in patterns:
                if re.search(pattern, content):
                    matches += 1
            
            if matches >= min_matches:
                logger.info(f"ğŸ“‹ ë‚´ìš© íŒ¨í„´ìœ¼ë¡œ {doc_type} ê°ì§€: {matches}ê°œ ë§¤ì¹­")
                return doc_type
        
        # ê¸°ë³¸ê°’
        logger.info("ğŸ“‹ ê¸°ë³¸ TEXT ì „ëµ ì‚¬ìš©")
        return "TEXT"
    
    def _chunk_project_document(
        self,
        document: Document,
        chunk_size: int,
        chunk_overlap: int,
        strategy_config: Dict[str, Any]
    ) -> List[Chunk]:
        """í”„ë¡œì íŠ¸ ë¬¸ì„œ íŠ¹í™” ì²­í‚¹"""
        content = document.content
        chunks = []
        chunk_index = 0
        
        # ì„¹ì…˜ ìš°ì„ ìˆœìœ„ ê°€ì ¸ì˜¤ê¸°
        section_priorities = strategy_config.get("section_priorities", {})
        
        # ì„¹ì…˜ë³„ ë¶„í• 
        sections = self._split_into_sections(content)
        
        for section_name, section_content in sections:
            priority = section_priorities.get(section_name, 999)
            
            # ì„¹ì…˜ë³„ íŠ¹ë³„ ì²˜ë¦¬
            if section_name == "Timeline" and "timeline_section" in strategy_config.get("special_processing", {}):
                timeline_chunks = self._chunk_timeline_section(section_content, document.document_id, chunk_index, chunk_size, chunk_overlap)
                chunks.extend(timeline_chunks)
                chunk_index += len(timeline_chunks)
            else:
                # ì¼ë°˜ ì„¹ì…˜ ì²­í‚¹
                section_chunks = self._chunk_by_sentences(section_content, document.document_id, chunk_index, chunk_size, chunk_overlap)
                chunks.extend(section_chunks)
                chunk_index += len(section_chunks)
        
        return chunks
    
    def _chunk_qa_document(
        self,
        document: Document,
        chunk_size: int,
        chunk_overlap: int,
        strategy_config: Dict[str, Any]
    ) -> List[Chunk]:
        """Q&A ë¬¸ì„œ íŠ¹í™” ì²­í‚¹"""
        content = document.content
        chunks = []
        chunk_index = 0
        
        # Q&A íŒ¨í„´ ì²˜ë¦¬
        processing_patterns = strategy_config.get("processing_patterns", {})
        qa_patterns = processing_patterns.get("qa_patterns", [])
        
        if qa_patterns:
            # íŒ¨í„´ ê¸°ë°˜ Q&A ì¶”ì¶œ
            qa_pairs = self._extract_qa_pairs(content, qa_patterns)
            
            for qa_pair in qa_pairs:
                if len(qa_pair) <= chunk_size:
                    # Q&A ìŒì´ ì²­í¬ í¬ê¸°ë³´ë‹¤ ì‘ìœ¼ë©´ í•˜ë‚˜ì˜ ì²­í¬ë¡œ
                    chunk = self._create_chunk(
                        content=qa_pair,
                        document_id=document.document_id,
                        chunk_index=chunk_index,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap
                    )
                    chunks.append(chunk)
                    chunk_index += 1
                else:
                    # í° Q&AëŠ” ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
                    section_chunks = self._chunk_by_sentences(qa_pair, document.document_id, chunk_index, chunk_size, chunk_overlap)
                    chunks.extend(section_chunks)
                    chunk_index += len(section_chunks)
        else:
            # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ë¬¸ì¥ ë‹¨ìœ„ ì²­í‚¹
            chunks = self._chunk_by_sentences(content, document.document_id, chunk_index, chunk_size, chunk_overlap)
        
        return chunks
    
    def _chunk_text_document(
        self,
        document: Document,
        chunk_size: int,
        chunk_overlap: int,
        preserve_structure: bool
    ) -> List[Chunk]:
        """ì¼ë°˜ í…ìŠ¤íŠ¸ ë¬¸ì„œ ì²­í‚¹"""
        content = document.content
        
        if preserve_structure:
            # êµ¬ì¡° ë³´ì¡´ ì²­í‚¹ (ë‹¨ë½ ìš°ì„ , ë¬¸ì¥ ë‹¨ìœ„)
            return self._chunk_by_paragraphs(content, document.document_id, 0, chunk_size, chunk_overlap)
        else:
            # ë‹¨ìˆœ ë¬¸ì¥ ë‹¨ìœ„ ì²­í‚¹
            return self._chunk_by_sentences(content, document.document_id, 0, chunk_size, chunk_overlap)
    
    def _split_into_sections(self, content: str) -> List[tuple[str, str]]:
        """ë¬¸ì„œë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„í• """
        sections = []
        lines = content.split('\n')
        current_section = ""
        current_section_name = "ê¸°ë³¸"
        
        for line in lines:
            # ì„¹ì…˜ í—¤ë” ê°ì§€ (## ë˜ëŠ” ###)
            if line.startswith('## '):
                if current_section.strip():
                    sections.append((current_section_name, current_section.strip()))
                current_section_name = line[3:].strip()
                current_section = line + '\n'
            elif line.startswith('### '):
                if current_section.strip():
                    sections.append((current_section_name, current_section.strip()))
                current_section_name = line[4:].strip()
                current_section = line + '\n'
            else:
                current_section += line + '\n'
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
        if current_section.strip():
            sections.append((current_section_name, current_section.strip()))
        
        return sections
    
    def _extract_qa_pairs(self, content: str, patterns: List[str]) -> List[str]:
        """Q&A ìŒ ì¶”ì¶œ"""
        qa_pairs = []
        
        for pattern in patterns:
            matches = re.finditer(pattern, content, re.DOTALL)
            for match in matches:
                qa_pair = match.group(0)
                qa_pairs.append(qa_pair)
        
        return qa_pairs
    
    def _chunk_timeline_section(
        self,
        timeline_content: str,
        document_id: DocumentId,
        chunk_index: int,
        chunk_size: int,
        chunk_overlap: int
    ) -> List[Chunk]:
        """Timeline ì„¹ì…˜ íŠ¹í™” ì²­í‚¹"""
        chunks = []
        lines = timeline_content.split('\n')
        current_chunk = ""
        
        for line in lines:
            # ì—°ë„/ë‚ ì§œ íŒ¨í„´ ê°ì§€
            if re.match(r'^\d{4}', line) or re.match(r'^\*\s*\d{4}', line):
                if current_chunk.strip():
                    chunk = self._create_chunk(
                        content=current_chunk.strip(),
                        document_id=document_id,
                        chunk_index=chunk_index,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap
                    )
                    chunks.append(chunk)
                    chunk_index += 1
                    current_chunk = ""
            
            current_chunk += line + '\n'
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
        if current_chunk.strip():
            chunk = self._create_chunk(
                content=current_chunk.strip(),
                document_id=document_id,
                chunk_index=chunk_index,
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap
            )
            chunks.append(chunk)
        
        return chunks
    
    def _chunk_by_sentences(
        self,
        content: str,
        document_id: DocumentId,
        chunk_index: int,
        chunk_size: int,
        chunk_overlap: int
    ) -> List[Chunk]:
        """ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì²­í‚¹"""
        sentences = self._split_into_sentences(content)
        chunks = []
        current_chunk = ""
        current_index = chunk_index
        
        for sentence in sentences:
            if len(current_chunk + sentence) <= chunk_size:
                current_chunk += sentence
            else:
                if current_chunk.strip():
                    chunk = self._create_chunk(
                        content=current_chunk.strip(),
                        document_id=document_id,
                        chunk_index=current_index,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap
                    )
                    chunks.append(chunk)
                    current_index += 1
                
                current_chunk = sentence
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
        if current_chunk.strip():
            chunk = self._create_chunk(
                content=current_chunk.strip(),
                document_id=document_id,
                chunk_index=current_index,
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap
            )
            chunks.append(chunk)
        
        return chunks
    
    def _chunk_by_paragraphs(
        self,
        content: str,
        document_id: DocumentId,
        chunk_index: int,
        chunk_size: int,
        chunk_overlap: int
    ) -> List[Chunk]:
        """ë‹¨ë½ ë‹¨ìœ„ë¡œ ì²­í‚¹"""
        paragraphs = content.split('\n\n')
        chunks = []
        current_chunk = ""
        current_index = chunk_index
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
                
            if len(current_chunk + paragraph) <= chunk_size:
                current_chunk += paragraph + "\n\n"
            else:
                if current_chunk.strip():
                    chunk = self._create_chunk(
                        content=current_chunk.strip(),
                        document_id=document_id,
                        chunk_index=current_index,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap
                    )
                    chunks.append(chunk)
                    current_index += 1
                
                current_chunk = paragraph + "\n\n"
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
        if current_chunk.strip():
            chunk = self._create_chunk(
                content=current_chunk.strip(),
                document_id=document_id,
                chunk_index=current_index,
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap
            )
            chunks.append(chunk)
        
        return chunks
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• """
        # ë” ì •êµí•œ ë¬¸ì¥ ë¶„í•  (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€, ë‹¨ ì•½ì–´ëŠ” ì œì™¸)
        sentences = re.split(r'(?<=[.!?])\s+', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def _create_chunk(
        self,
        content: str,
        document_id: DocumentId,
        chunk_index: int,
        chunk_size: int,
        chunk_overlap: int
    ) -> Chunk:
        """ì²­í¬ ìƒì„±"""
        return Chunk(
            content=content,
            document_id=document_id,
            chunk_index=chunk_index,
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
