"""
Embedding Service - Demo Domain Layer
ë°ëª¨ ë„ë©”ì¸ ì„ë² ë”© ì„œë¹„ìŠ¤

ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë„ë©”ì¸ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
"""

import logging
from typing import List, Dict, Any
import numpy as np
from ..entities.chunk import Chunk
from ..entities.embedding import Embedding, EmbeddingId
from ..entities.vector_store import VectorStore

logger = logging.getLogger(__name__)


class EmbeddingService:
    """ì„ë² ë”© ë„ë©”ì¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.embeddings: Dict[str, Embedding] = {}
        self.vector_store = VectorStore()
        logger.info("âœ… Embedding Service initialized")
    
    def create_embedding(self, chunk: Chunk) -> Embedding:
        """ì²­í¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            # Mock ì„ë² ë”© ìƒì„± (ì‹¤ì œë¡œëŠ” sentence-transformers ëª¨ë¸ ì‚¬ìš©)
            vector = self._generate_mock_embedding(chunk.content)
            
            embedding = Embedding(
                chunk_id=chunk.chunk_id,
                vector=vector,
                model_name=self.vector_store.model_name,
                dimension=self.vector_store.dimension
            )
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            self.embeddings[str(embedding.embedding_id)] = embedding
            
            # ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
            self.vector_store.add_embedding(embedding)
            
            logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: ì²­í¬ {chunk.chunk_id} â†’ {len(vector)}ì°¨ì›")
            return embedding
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def create_embeddings(self, chunks: List[Chunk]) -> List[Embedding]:
        """ì—¬ëŸ¬ ì²­í¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        embeddings = []
        
        for chunk in chunks:
            embedding = self.create_embedding(chunk)
            embeddings.append(embedding)
        
        logger.info(f"ğŸ“Š ì´ {len(embeddings)}ê°œì˜ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
        return embeddings
    
    def get_embedding(self, embedding_id: str) -> Embedding:
        """ì„ë² ë”© ì¡°íšŒ"""
        return self.embeddings.get(embedding_id)
    
    def get_embeddings_count(self) -> int:
        """ì €ì¥ëœ ì„ë² ë”© ìˆ˜ ë°˜í™˜"""
        return len(self.embeddings)
    
    def get_vector_store_statistics(self) -> Dict[str, Any]:
        """ë²¡í„°ìŠ¤í† ì–´ í†µê³„ ë°˜í™˜"""
        return self.vector_store.get_statistics()
    
    def calculate_similarity(self, embedding1: Embedding, embedding2: Embedding) -> float:
        """ë‘ ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            vec1 = np.array(embedding1.vector)
            vec2 = np.array(embedding2.vector)
            
            # ì •ê·œí™”
            vec1_norm = vec1 / np.linalg.norm(vec1)
            vec2_norm = vec2 / np.linalg.norm(vec2)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = np.dot(vec1_norm, vec2_norm)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def _generate_mock_embedding(self, text: str) -> List[float]:
        """Mock ì„ë² ë”© ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” sentence-transformers ì‚¬ìš©)"""
        # í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°„ë‹¨í•œ ë²¡í„° ìƒì„±
        import hashlib
        
        # í…ìŠ¤íŠ¸ë¥¼ í•´ì‹œí•˜ì—¬ ì¼ê´€ëœ ë²¡í„° ìƒì„±
        hash_obj = hashlib.md5(text.encode())
        hash_hex = hash_obj.hexdigest()
        
        # 384ì°¨ì› ë²¡í„° ìƒì„± (sentence-transformers/all-MiniLM-L6-v2ì™€ ë™ì¼)
        vector = []
        for i in range(384):
            # í•´ì‹œê°’ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²°ì •ì  ëœë¤ ë²¡í„° ìƒì„±
            seed = int(hash_hex[i % 32], 16) + i
            np.random.seed(seed)
            vector.append(float(np.random.normal(0, 1)))
        
        return vector
