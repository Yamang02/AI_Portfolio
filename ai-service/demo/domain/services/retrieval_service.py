"""
Retrieval Service - Demo Domain Layer
ë°ëª¨ ë„ë©”ì¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤

ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ì„ ë‹´ë‹¹í•˜ëŠ” ë„ë©”ì¸ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
"""

import logging
from typing import List, Dict, Any, Optional
from ..entities.query import Query, QueryId
from ..entities.chunk import Chunk
from ..entities.embedding import Embedding
from ..entities.search_result import SearchResult, SearchResultId
from ..entities.vector_store import VectorStore

logger = logging.getLogger(__name__)


class RetrievalService:
    """ê²€ìƒ‰ ë„ë©”ì¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.search_results: Dict[str, SearchResult] = {}
        logger.info("âœ… Retrieval Service initialized")
    
    def search_similar_chunks(
        self,
        query: Query,
        top_k: int = None,
        similarity_threshold: float = None
    ) -> List[SearchResult]:
        """ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰"""
        try:
            # Queryì—ì„œ ê¸°ë³¸ê°’ ì‚¬ìš© ë˜ëŠ” íŒŒë¼ë¯¸í„° ìš°ì„ 
            final_top_k = top_k if top_k is not None else query.max_results
            final_threshold = similarity_threshold if similarity_threshold is not None else query.similarity_threshold
            
            # VectorStoreì—ì„œ ì„ë² ë”© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            embeddings = self.vector_store.embeddings
            logger.info(f"ğŸ” ë²¡í„°ìŠ¤í† ì–´ ìƒíƒœ í™•ì¸: ì„ë² ë”© ìˆ˜ = {len(embeddings)}")
            if not embeddings:
                logger.warning("ë²¡í„°ìŠ¤í† ì–´ì— ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (Mock)
            query_embedding = self._create_query_embedding(query.text)
            
            # ëª¨ë“  ì„ë² ë”©ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = []
            logger.info(f"ğŸ” ìœ ì‚¬ë„ ê³„ì‚° ì‹œì‘: {len(embeddings)}ê°œ ì„ë² ë”©ê³¼ ë¹„êµ")
            for i, embedding in enumerate(embeddings):
                # ì„ë² ë”©ì—ì„œ ì²­í¬ ì •ë³´ ì¶”ì¶œ (ë©”íƒ€ë°ì´í„° í™œìš©)
                chunk = self._create_chunk_from_embedding_metadata(embedding)
                similarity = self._calculate_cosine_similarity(query_embedding, embedding.vector)
                similarities.append((chunk, embedding, similarity))
                if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ë¡œê·¸ ì¶œë ¥
                    logger.info(f"ğŸ” ì„ë² ë”© {i+1}: ìœ ì‚¬ë„ = {similarity:.4f}, ì²­í¬ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° = {chunk.content[:50]}...")
            
            # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            similarities.sort(key=lambda x: x[2], reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ í•„í„°ë§
            results = []
            logger.info(f"ğŸ” í•„í„°ë§ ì‹œì‘: ì„ê³„ê°’ = {final_threshold}, ìƒìœ„ Kê°œ = {final_top_k}")
            for rank, (chunk, embedding, similarity) in enumerate(similarities[:final_top_k]):
                logger.info(f"ğŸ” ê²°ê³¼ {rank+1}: ìœ ì‚¬ë„ = {similarity:.4f}, ì„ê³„ê°’ í†µê³¼ = {'âœ…' if similarity >= final_threshold else 'âŒ'}")
                if similarity >= final_threshold:
                    search_result = SearchResult(
                        query_id=query.query_id,
                        chunk=chunk,
                        embedding=embedding,
                        similarity_score=similarity,
                        rank=rank + 1
                    )
                    results.append(search_result)
                    
                    # ë©”ëª¨ë¦¬ì— ì €ì¥
                    self.search_results[str(search_result.search_result_id)] = search_result
            
            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: '{query.text}' â†’ {len(results)}ê°œ ê²°ê³¼ (ì „ì²´ {len(similarities)}ê°œ ì¤‘)")
            return results
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def get_search_history(self, query_id: str) -> List[SearchResult]:
        """ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        return [
            result for result in self.search_results.values()
            if str(result.query_id) == query_id
        ]
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ í†µê³„ ë°˜í™˜"""
        total_searches = len(set(str(result.query_id) for result in self.search_results.values()))
        total_results = len(self.search_results)
        
        # í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜
        if total_results > 0:
            avg_similarity = sum(result.similarity_score for result in self.search_results.values()) / total_results
        else:
            avg_similarity = 0.0
        
        return {
            "total_searches": total_searches,
            "total_results": total_results,
            "average_similarity_score": avg_similarity,
            "vector_store_embeddings": self.vector_store.get_embeddings_count()
        }
    
    def _create_query_embedding(self, query_text: str) -> List[float]:
        """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        # Mock ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ì‹¤ì œë¡œëŠ” sentence-transformers ì‚¬ìš©)
        import hashlib
        import numpy as np
        
        hash_obj = hashlib.md5(query_text.encode())
        hash_hex = hash_obj.hexdigest()
        
        vector = []
        for i in range(384):
            seed = int(hash_hex[i % 32], 16) + i
            np.random.seed(seed)
            vector.append(float(np.random.normal(0, 1)))
        
        return vector
    
    def _calculate_cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            import numpy as np
            
            v1 = np.array(vec1)
            v2 = np.array(vec2)
            
            # ì •ê·œí™”
            v1_norm = v1 / np.linalg.norm(v1)
            v2_norm = v2 / np.linalg.norm(v2)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            similarity = np.dot(v1_norm, v2_norm)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def _create_chunk_from_embedding_metadata(self, embedding: Embedding) -> Chunk:
        """ì„ë² ë”© ë©”íƒ€ë°ì´í„°ì—ì„œ ì²­í¬ ê°ì²´ ìƒì„±"""
        try:
            from ..entities.chunk import Chunk, ChunkId
            from ..entities.document import DocumentId
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ (document_id ê¸°ë°˜)
            metadata = embedding.metadata or {}
            chunk_text = metadata.get("chunk_text_preview", "")
            document_id_str = metadata.get("document_id", "unknown")
            
            # ì²­í¬ ê°ì²´ ìƒì„± (document_id ê¸°ë°˜)
            chunk = Chunk(
                content=chunk_text,
                document_id=DocumentId(document_id_str),
                chunk_id=ChunkId(),
                chunk_index=metadata.get("chunk_index", 0),
                chunk_size=metadata.get("chunk_size", len(chunk_text)),
                chunk_overlap=metadata.get("chunk_overlap", 0)
            )
            
            return chunk
            
        except Exception as e:
            logger.error(f"ì²­í¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ê¸°ë³¸ ì²­í¬ ë°˜í™˜ (document_id ê¸°ë°˜)
            from ..entities.chunk import Chunk, ChunkId
            from ..entities.document import DocumentId
            return Chunk(
                content="Content not available",
                document_id=DocumentId("unknown"),
                chunk_id=ChunkId()
            )
