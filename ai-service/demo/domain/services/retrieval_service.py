"""
Retrieval Service - Demo Domain Layer
ë°ëª¨ ë„ë©”ì¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤

ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ì„ ë‹´ë‹¹í•˜ëŠ” ë„ë©”ì¸ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
"""

import logging
import uuid
from typing import List, Dict, Any, Optional
from ..entities.query import Query, QueryId
from ..entities.chunk import Chunk
from ..entities.embedding import Embedding
from ..entities.search_result import SearchResult, SearchResultId
from ..entities.vector_store import VectorStore
from ..ports.outbound.embedding_model_port import EmbeddingModelPort

logger = logging.getLogger(__name__)


class RetrievalService:
    """ê²€ìƒ‰ ë„ë©”ì¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self, vector_store: VectorStore, embedding_model: EmbeddingModelPort):
        self.vector_store = vector_store
        self.embedding_model = embedding_model
        self.search_results: Dict[str, SearchResult] = {}
        
        # ConfigManagerë¥¼ í†µí•œ ê²€ìƒ‰ í’ˆì§ˆ ì„¤ì • ë¡œë“œ
        try:
            from config.demo_config_manager import get_demo_config_manager
            config_manager = get_demo_config_manager()
            self.search_config = config_manager.get_search_quality_config()
            logger.info("âœ… Retrieval Service initialized with embedding model and ConfigManager")
        except Exception as e:
            logger.error(f"âŒ ConfigManager ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise RuntimeError("ê²€ìƒ‰ í’ˆì§ˆ ì„¤ì •ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ConfigManagerë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ì„ë² ë”© ëª¨ë¸ ì •ë³´ ë¡œê¹…
        model_info = self.embedding_model.get_model_info()
        logger.info(f"ğŸ¤– ì‚¬ìš© ì¤‘ì¸ ì„ë² ë”© ëª¨ë¸: {model_info['model_name']} ({model_info['model_type']})")
        logger.info(f"ğŸ“ ë²¡í„° ì°¨ì›: {model_info['dimension']}ì°¨ì›")
    
    def search_similar_chunks(
        self,
        query: Query,
        top_k: int = None,
        similarity_threshold: float = None
    ) -> List[SearchResult]:
        """ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰"""
        try:
            # Queryì—ì„œ ê¸°ë³¸ê°’ ì‚¬ìš© ë˜ëŠ” íŒŒë¼ë¯¸í„° ìš°ì„ 
            final_top_k = top_k if top_k is not None else query.max_results
            final_threshold = similarity_threshold if similarity_threshold is not None else query.similarity_threshold
            
            # VectorStoreì—ì„œ ì„ë² ë”© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            embeddings = self.vector_store.embeddings
            if not embeddings:
                logger.warning("ë²¡í„°ìŠ¤í† ì–´ì— ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©)
            query_embedding = self.embedding_model.encode_single(query.text)
            
            # ëª¨ë“  ì„ë² ë”©ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ì§§ì€ ì²­í¬ í˜ë„í‹° ì ìš©)
            similarities = []
            for embedding in embeddings:
                # ì„ë² ë”©ì—ì„œ ì²­í¬ ì •ë³´ ì¶”ì¶œ (ë©”íƒ€ë°ì´í„° í™œìš©)
                chunk = self._create_chunk_from_embedding_metadata(embedding)
                
                # ConfigManager ê¸°ë°˜ ì§§ì€ ì²­í¬ í•„í„°ë§
                min_length = self.search_config["min_chunk_length"]
                if len(chunk.content.strip()) <= min_length:
                    logger.debug(f"ì§§ì€ ì²­í¬ ì œì™¸: '{chunk.content}' ({len(chunk.content)}ê¸€ì)")
                    continue
                
                similarity = self._calculate_cosine_similarity(query_embedding.tolist(), embedding.vector)
                
                # ConfigManager ê¸°ë°˜ ì§§ì€ ì²­í¬ í˜ë„í‹° ì ìš©
                short_threshold = self.search_config["short_chunk_threshold"]
                short_penalty = self.search_config["short_chunk_penalty"]
                
                if len(chunk.content.strip()) <= short_threshold:
                    similarity *= short_penalty
                    logger.debug(f"ì§§ì€ ì²­í¬ í˜ë„í‹° ì ìš©: '{chunk.content[:20]}...' (ì›ë˜: {similarity/short_penalty:.3f} â†’ ì ìš© í›„: {similarity:.3f})")
                
                similarities.append((chunk, embedding, similarity))
            
            # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            similarities.sort(key=lambda x: x[2], reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ í•„í„°ë§ (ì¤‘ë³µ ì œê±° í¬í•¨)
            results = []
            seen_chunk_ids = set()
            
            for rank, (chunk, embedding, similarity) in enumerate(similarities[:final_top_k]):
                if similarity >= final_threshold:
                    # ì¤‘ë³µ ì²­í¬ ID ê²€ì¦
                    chunk_id_str = str(chunk.chunk_id)
                    if chunk_id_str in seen_chunk_ids:
                        logger.warning(f"ì¤‘ë³µ ì²­í¬ ID ë°œê²¬: {chunk_id_str} (ìˆœìœ„ {rank + 1})")
                        continue
                    
                    seen_chunk_ids.add(chunk_id_str)
                    
                    search_result = SearchResult(
                        query_id=query.query_id,
                        chunk=chunk,
                        embedding=embedding,
                        similarity_score=similarity,
                        rank=len(results) + 1  # ì‹¤ì œ ë°˜í™˜ ìˆœìœ„ë¡œ ì¬ì¡°ì •
                    )
                    results.append(search_result)
                    
                    # ë©”ëª¨ë¦¬ì— ì €ì¥
                    self.search_results[str(search_result.search_result_id)] = search_result
            
            # ê²€ìƒ‰ ê²°ê³¼ ë””ë²„ê¹… ì •ë³´
            logger.info(f"ğŸ” ê²€ìƒ‰ ë””ë²„ê¹… - ì¿¼ë¦¬: '{query.text}'")
            logger.info(f"ğŸ“Š ì „ì²´ ì„ë² ë”© ìˆ˜: {len(embeddings)}")
            logger.info(f"ğŸ¯ ì„ê³„ê°’ ì´ìƒ ê²°ê³¼: {len(results)}ê°œ")
            
            if results:
                logger.info("ğŸ“‹ ìƒìœ„ 5ê°œ ê²°ê³¼:")
                for i, result in enumerate(results[:5]):
                    chunk_preview = result.chunk.content[:50].replace('\n', ' ')
                    logger.info(f"  {i+1}. ìœ ì‚¬ë„: {result.similarity_score:.4f} | ì²­í¬: '{chunk_preview}...'")
            
            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: '{query.text}' â†’ {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def get_search_history(self, query_id: str) -> List[SearchResult]:
        """ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        return [
            result for result in self.search_results.values()
            if str(result.query_id) == query_id
        ]
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ í†µê³„ ë°˜í™˜"""
        total_searches = len(set(str(result.query_id) for result in self.search_results.values()))
        total_results = len(self.search_results)
        
        # í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜
        if total_results > 0:
            avg_similarity = sum(result.similarity_score for result in self.search_results.values()) / total_results
        else:
            avg_similarity = 0.0
        
        return {
            "total_searches": total_searches,
            "total_results": total_results,
            "average_similarity_score": avg_similarity,
            "vector_store_embeddings": self.vector_store.get_embeddings_count()
        }
    
    
    def _calculate_cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            import numpy as np
            
            v1 = np.array(vec1)
            v2 = np.array(vec2)
            
            # ì •ê·œí™”
            v1_norm = v1 / np.linalg.norm(v1)
            v2_norm = v2 / np.linalg.norm(v2)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            similarity = np.dot(v1_norm, v2_norm)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def _create_chunk_from_embedding_metadata(self, embedding: Embedding) -> Chunk:
        """ì„ë² ë”© ë©”íƒ€ë°ì´í„°ì—ì„œ ì²­í¬ ê°ì²´ ìƒì„± (ì›ë³¸ ì²­í¬ ID ìœ ì§€)"""
        try:
            from ..entities.chunk import Chunk
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ
            metadata = embedding.metadata or {}
            chunk_text = metadata.get("chunk_text_preview", "")
            document_id_str = metadata.get("document_id", "unknown")
            
            # ì›ë³¸ ì²­í¬ ID ì‚¬ìš© (ì„ë² ë”©ì˜ chunk_id)
            chunk = Chunk(
                content=chunk_text,
                document_id=document_id_str,
                chunk_id=embedding.chunk_id,  # ì›ë³¸ ì²­í¬ ID ì‚¬ìš©
                chunk_index=metadata.get("chunk_index", 0),
                chunk_size=metadata.get("chunk_size", len(chunk_text)),
                chunk_overlap=metadata.get("chunk_overlap", 0)
            )
            
            return chunk
            
        except Exception as e:
            logger.error(f"ì²­í¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ê¸°ë³¸ ì²­í¬ ë°˜í™˜
            from ..entities.chunk import Chunk
            return Chunk(
                content="Content not available",
                document_id="unknown",
                chunk_id=embedding.chunk_id if hasattr(embedding, 'chunk_id') else str(uuid.uuid4())
            )
