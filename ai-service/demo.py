"""
HuggingFace Spaces Demo Entry Point
Hexagonal Architecture RAG Demo for AI Portfolio
"""

import asyncio
import gradio as gr
import logging
from typing import List, Tuple, Dict, Any

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import hexagonal architecture components
from src.application.services.rag_service import RAGService
from src.adapters.outbound.llm.mock_llm_adapter import MockLLMAdapter
from src.adapters.outbound.databases.vector.memory_vector_adapter import MemoryVectorAdapter


class RAGDemoInterface:
    """RAG ë°ëª¨ë¥¼ ìœ„í•œ Gradio ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        # Initialize hexagonal architecture components
        self.llm_adapter = MockLLMAdapter()
        self.vector_adapter = MemoryVectorAdapter()
        self.rag_service = RAGService(
            vector_store=self.vector_adapter,
            llm_port=self.llm_adapter
        )
        self.initialized = False
        logger.info("âœ… Hexagonal RAG Demo initialized")

    async def initialize(self):
        """ë¹„ë™ê¸° ì´ˆê¸°í™” (ì„ë² ë”© ëª¨ë¸ ë¡œë“œ)"""
        if self.initialized:
            return
            
        try:
            logger.info("ğŸ”„ Initializing LLM and Vector adapters...")
            await self.llm_adapter.initialize()
            await self.vector_adapter.initialize()
            self.initialized = True
            logger.info("âœ… All adapters initialized successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize adapters: {e}")
            raise
    
    async def add_document(self, content: str, source: str = "manual_input") -> str:
        """ì§€ì‹ ë² ì´ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€"""
        if not content.strip():
            return "âŒ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"
        
        try:
            result = await self.rag_service.add_document_from_text(
                content=content.strip(),
                source=source,
                metadata={"timestamp": "demo"}
            )
            
            if result.get("success"):
                return f"âœ… ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! ë¬¸ì„œ ID: {result.get('document_id', 'N/A')}"
            else:
                return f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    async def add_document_with_analysis(self, content: str, source: str = "manual_input") -> Tuple[str, str, str]:
        """ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ì¶”ê°€"""
        if not content.strip():
            return "âŒ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", "", ""
        
        try:
            result = await self.rag_service.add_document_with_analysis(
                content=content.strip(),
                source=source,
                metadata={"timestamp": "demo"}
            )
            
            if not result.get("success"):
                return f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}", "", ""
            
            # ê¸°ë³¸ ê²°ê³¼
            basic_result = f"âœ… ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!\në¬¸ì„œ ID: {result.get('document_id', 'N/A')}\nì¶œì²˜: {result.get('source', 'N/A')}"
            
            # ì²˜ë¦¬ ê³¼ì • ë¶„ì„
            processing_steps = result.get("processing_steps", {})
            vector_result = result.get("vector_result", {})
            
            processing_info = f"â±ï¸ **ì²˜ë¦¬ ë¶„ì„:**\n"
            processing_info += f"â€¢ ëª¨ë¸ ìƒì„±: {processing_steps.get('model_creation', 0):.3f}s\n"
            processing_info += f"â€¢ ë²¡í„° ì²˜ë¦¬: {processing_steps.get('vector_processing', 0):.3f}s\n"
            processing_info += f"â€¢ ì´ ì‹œê°„: {processing_steps.get('total_time', 0):.3f}s\n\n"
            
            # ë²¡í„° ì²˜ë¦¬ ê²°ê³¼
            if vector_result.get("success"):
                vector_info = f"ğŸ”¢ **ë²¡í„° ë¶„ì„:**\n"
                vector_info += f"â€¢ ìƒì„±ëœ ì²­í¬: {vector_result.get('chunks_created', 0)}\n"
                vector_info += f"â€¢ ë²¡í„° ì°¨ì›: {vector_result.get('vector_dimensions', 0)}\n"
                vector_info += f"â€¢ ì´ ë¬¸ì„œ ìˆ˜: {vector_result.get('total_documents', 0)}\n"
                vector_info += f"â€¢ ì´ ì²­í¬ ìˆ˜: {vector_result.get('total_chunks', 0)}\n\n"
                
                # ì²­í¬ ìƒì„¸ ì •ë³´
                chunk_details = vector_result.get("chunk_details", [])
                if chunk_details:
                    vector_info += "ğŸ“„ **ì²­í¬ ìƒì„¸ ì •ë³´:**\n"
                    for i, chunk in enumerate(chunk_details, 1):
                        vector_info += f"â€¢ ì²­í¬ {i}: {chunk['length']} chars - {chunk['content_preview']}\n"
            else:
                vector_info = "âŒ ë²¡í„° ì²˜ë¦¬ ì‹¤íŒ¨"
            
            return basic_result, processing_info, vector_info
                
        except Exception as e:
            logger.error(f"ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", "", ""
    
    async def search_documents(self, query: str, top_k: int = 3) -> str:
        """ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰"""
        if not query.strip():
            return "âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”"
        
        try:
            result = await self.rag_service.search_documents(
                query=query.strip(),
                top_k=top_k,
                similarity_threshold=0.1
            )
            
            if not result.get("success"):
                return f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"
            
            documents = result.get("results", [])
            if not documents:
                return "ğŸ“­ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
            output = f"ğŸ” {len(documents)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            for i, doc in enumerate(documents, 1):
                output += f"**{i}. ì ìˆ˜: {doc.get('similarity_score', 0):.3f}**\n"
                output += f"{doc.get('content', 'ë‚´ìš© ì—†ìŒ')[:200]}...\n\n"
            
            return output
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    async def search_documents_with_analysis(self, query: str, top_k: int = 3) -> Tuple[str, str, str]:
        """ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ê²€ìƒ‰"""
        if not query.strip():
            return "âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", "", ""
        
        try:
            result = await self.rag_service.search_documents_with_analysis(
                query=query.strip(),
                top_k=top_k,
                similarity_threshold=0.1
            )
            
            if not result.get("success"):
                return f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}", "", ""
            
            # ê²€ìƒ‰ ê²°ê³¼
            documents = result.get("results", [])
            if not documents:
                return "ğŸ“­ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "", ""
            
            search_results = f"ğŸ” {len(documents)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            for i, doc in enumerate(documents, 1):
                search_results += f"**{i}. ì ìˆ˜: {doc.get('similarity_score', 0):.3f}**\n"
                search_results += f"{doc.get('content', 'ë‚´ìš© ì—†ìŒ')[:200]}...\n\n"
            
            # ì²˜ë¦¬ ê³¼ì • ë¶„ì„
            detailed_analysis = result.get("detailed_analysis", {})
            processing_steps = detailed_analysis.get("processing_steps", {})
            vector_info = detailed_analysis.get("vector_info", {})
            
            processing_info = f"â±ï¸ **ì²˜ë¦¬ ë¶„ì„:**\n"
            processing_info += f"â€¢ ì „ì²˜ë¦¬: {processing_steps.get('preprocessing', 0):.3f}s\n"
            processing_info += f"â€¢ ë²¡í„°í™”: {processing_steps.get('vectorization', 0):.3f}s\n"
            processing_info += f"â€¢ ìœ ì‚¬ë„ ê³„ì‚°: {processing_steps.get('similarity_calculation', 0):.3f}s\n"
            processing_info += f"â€¢ ì •ë ¬: {processing_steps.get('sorting', 0):.3f}s\n"
            processing_info += f"â€¢ ê²°ê³¼ ìƒì„±: {processing_steps.get('result_creation', 0):.3f}s\n"
            processing_info += f"â€¢ ì´ ì‹œê°„: {processing_steps.get('total_time', 0):.3f}s\n\n"
            
            # ë²¡í„° ì •ë³´
            vector_analysis = f"ğŸ”¢ **ë²¡í„° ë¶„ì„:**\n"
            vector_analysis += f"â€¢ ë²¡í„° ì°¨ì›: {vector_info.get('dimensions', 0)}\n"
            vector_analysis += f"â€¢ ì´ ì²­í¬ ìˆ˜: {vector_info.get('total_chunks', 0)}\n"
            vector_analysis += f"â€¢ ì²˜ë¦¬ëœ ì²­í¬: {vector_info.get('processed_chunks', 0)}\n"
            vector_analysis += f"â€¢ ìœ ì‚¬ë„ ì„ê³„ê°’: {vector_info.get('threshold_applied', 0)}\n\n"
            
            # ìœ ì‚¬ë„ ë¶„í¬
            similarity_dist = detailed_analysis.get("similarity_distribution", {})
            vector_analysis += f"ğŸ“Š **ìœ ì‚¬ë„ ë¶„í¬:**\n"
            vector_analysis += f"â€¢ ì •í™•íˆ ì¼ì¹˜: {similarity_dist.get('exact_matches', 0)}\n"
            vector_analysis += f"â€¢ ìœ ì‚¬ë„ ì¼ì¹˜: {similarity_dist.get('similarity_matches', 0)}\n"
            vector_analysis += f"â€¢ ë¬¸ë§¥ìƒ ì¼ì¹˜: {similarity_dist.get('contextual_matches', 0)}\n"
            
            return search_results, processing_info, vector_analysis
                
        except Exception as e:
            logger.error(f"ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", "", ""
    
    async def generate_answer(self, question: str, max_results: int = 3) -> Tuple[str, str]:
        """ì¶œì²˜ì™€ í•¨ê»˜ RAG ë‹µë³€ ìƒì„±"""
        if not question.strip():
            return "âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", ""
        
        try:
            result = await self.rag_service.generate_rag_answer(
                question=question.strip(),
                context_hint=None,
                metadata={"timestamp": "demo"}
            )
            
            # Format answer
            answer = f"ğŸ¤– **ë‹µë³€:**\n{result.answer}\n\n"
            answer += f"â±ï¸ **ì²˜ë¦¬ ì‹œê°„:** {result.processing_time_ms:.0f}ms\n"
            answer += f"ğŸ¯ **ì‹ ë¢°ë„:** {result.confidence:.2f}"
            
            # Format sources
            if result.sources:
                sources = "ğŸ“š **ì‚¬ìš©ëœ ì¶œì²˜:**\n\n"
                for i, source in enumerate(result.sources, 1):
                    sources += f"**{i}. ìœ ì‚¬ë„: {source.similarity_score:.3f}**\n"
                    sources += f"{source.chunk.content[:300]}...\n\n"
            else:
                sources = "ğŸ“­ ì¶œì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
            return answer, sources
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", ""
    
    async def clear_knowledge_base(self) -> str:
        """ì§€ì‹ ë² ì´ìŠ¤ì˜ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ"""
        try:
            result = await self.rag_service.clear_storage()
            if result.get("success"):
                return "âœ… ì§€ì‹ ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
            else:
                return f"âŒ ì‚­ì œ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {str(e)}"
    
    async def get_status(self) -> str:
        """ì‹œìŠ¤í…œ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°"""
        try:
            status = await self.rag_service.get_status()
            
            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ì–´ëŒ‘í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            llm_info = await self.llm_adapter.get_info()
            vector_info = await self.vector_adapter.get_info()
            
            return f"""
ğŸ“Š **ì‹œìŠ¤í…œ ìƒíƒœ**

**ğŸ“„ ë¬¸ì„œ ê´€ë¦¬:**
â€¢ ì €ì¥ëœ ë¬¸ì„œ: {status.get('document_count', 0)}ê°œ
â€¢ ë²¡í„° ì„ë² ë”©: {status.get('vector_count', 0)}ê°œ

**ğŸ¤– LLM ì„œë¹„ìŠ¤:**
â€¢ ëª¨ë¸: {llm_info.get('model_name', 'MockLLM')}
â€¢ ìƒíƒœ: {'âœ… ì¤€ë¹„ë¨' if status.get('llm_available') else 'âŒ ì‚¬ìš© ë¶ˆê°€'}
â€¢ íƒ€ì…: {llm_info.get('type', 'Mock')}

**ğŸ” ë²¡í„° ìŠ¤í† ì–´:**
â€¢ ìŠ¤í† ì–´: {vector_info.get('store_name', 'MemoryVector')}
â€¢ ìƒíƒœ: {'âœ… ì¤€ë¹„ë¨' if status.get('vector_store_available') else 'âŒ ì‚¬ìš© ë¶ˆê°€'}
â€¢ ì„ë² ë”© ëª¨ë¸: {vector_info.get('embedding_model', 'all-MiniLM-L6-v2')}
â€¢ ì°¨ì›: {vector_info.get('dimensions', 384)}
            """
        except Exception as e:
            return f"âŒ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}"

    async def view_all_documents(self) -> str:
        """ë°ëª¨: ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œ ë³´ê¸°"""
        try:
            documents = await self.vector_adapter.get_all_documents()
            
            if not documents:
                return "ğŸ“­ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
            
            output = f"ğŸ“š **ì €ì¥ëœ ë¬¸ì„œ ({len(documents)}ê°œ)**\n\n"
            
            for i, doc in enumerate(documents, 1):
                output += f"**{i}. {doc['source']}** `{doc['id'][:8]}...`\n"
                output += f"â€¢ **ê¸¸ì´**: {doc['content_length']} chars\n"
                output += f"â€¢ **ìƒì„±ì¼**: {doc['created_at'][:19] if doc['created_at'] else 'N/A'}\n"
                output += f"â€¢ **ë¯¸ë¦¬ë³´ê¸°**: {doc['content_preview']}\n\n"
                
            return output
            
        except Exception as e:
            logger.error(f"ì „ì²´ ë¬¸ì„œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    async def get_embedding_analysis(self) -> str:
        """ë°ëª¨: ì„ë² ë”© ë¶„ì„ ì •ë³´"""
        try:
            info = await self.vector_adapter.get_embedding_info()
            
            if not info.get("embeddings_available"):
                return "âŒ ì„ë² ë”©ì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
                
            output = f"""
ğŸ”¬ **ì„ë² ë”© ë¶„ì„**

**ëª¨ë¸**: {info['model_name']}
**ë¬¸ì„œ ìˆ˜**: {info['document_count']}
**ì„ë² ë”© ì°¨ì›**: {info['embedding_dimensions']}
**ì„ë² ë”© í˜•íƒœ**: {info['embedding_shape']}
**ìƒ˜í”Œ ë²¡í„° í¬ê¸°**: {info['sample_embedding_norm']:.4f}
            """
            
            return output
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"


def create_demo_interface() -> gr.Blocks:
    """Gradio ë°ëª¨ ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    demo_controller = RAGDemoInterface()
    
    with gr.Blocks(
        title="AI í¬íŠ¸í´ë¦¬ì˜¤ RAG ë°ëª¨",
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 1400px !important;
            margin: 0 auto !important;
        }
        .tab-nav {
            justify-content: center !important;
        }
        .contain {
            max-width: none !important;
            margin: 0 auto !important;
        }
        """
    ) as demo:
        
        gr.Markdown("""
        # ğŸš€ AI í¬íŠ¸í´ë¦¬ì˜¤ RAG ë°ëª¨
        
        ### ğŸ¯ ì‚¬ìš© ë°©ë²•:
        1. **ë¬¸ì„œ ì¶”ê°€**ë¥¼ í†µí•´ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”
        2. **ë¬¸ì„œ ë¶„ì„**ì„ í†µí•´ ìƒì„¸ ì²˜ë¦¬ ë‹¨ê³„ë¥¼ í™•ì¸í•˜ì„¸ìš”
        3. **ê²€ìƒ‰**ì„ í†µí•´ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ìœ¼ì„¸ìš”
        4. **ê²€ìƒ‰ ë¶„ì„**ì„ í†µí•´ ë²¡í„° ì²˜ë¦¬ ê³¼ì •ì„ ì´í•´í•˜ì„¸ìš”
        5. **ì§ˆë¬¸í•˜ê¸°**ë¥¼ í†µí•´ AI ìƒì„± ë‹µë³€ì„ ë°›ìœ¼ì„¸ìš”

        
        ### ğŸ”¬ ì£¼ìš” ê¸°ëŠ¥:
        - **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: ë²¡í„° ìœ ì‚¬ë„ + BM25 í‚¤ì›Œë“œ ê²€ìƒ‰
        - **ì‹¤ì‹œê°„ ë¶„ì„**: ì²˜ë¦¬ ë‹¨ê³„ë³„ ìƒì„¸ ë¶„ì„
        - **ë²¡í„° ì‹œê°í™”**: ì„ë² ë”© ë° ìœ ì‚¬ë„ ë¶„ì„
        - **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‘ë‹µ ì‹œê°„ ë° ì •í™•ë„ ì¸¡ì •
        """)
        
        with gr.Tab("ğŸ“„ ë¬¸ì„œ ê´€ë¦¬"):
            with gr.Row():
                with gr.Column():
                    doc_input = gr.Textbox(
                        label="ë¬¸ì„œ ë‚´ìš©",
                        placeholder="ì—¬ê¸°ì— ë¬¸ì„œ ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
                        lines=8
                    )
                    source_input = gr.Textbox(
                        label="ì¶œì²˜ ì´ë¦„ (ì„ íƒ ì‚¬í•­)",
                        placeholder="ì˜ˆ: research_paper.pdf",
                        value="manual_input"
                    )
                    add_btn = gr.Button("â• ë¬¸ì„œ ì¶”ê°€", variant="primary")
                
                with gr.Column():
                    add_output = gr.Textbox(
                        label="ìƒíƒœ",
                        lines=3,
                        interactive=False
                    )
                    
                    clear_btn = gr.Button("ğŸ—‘ï¸ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ", variant="secondary")
                    clear_output = gr.Textbox(
                        label="ìƒíƒœ ì´ˆê¸°í™”",
                        lines=2,
                        interactive=False
                    )

        with gr.Tab("ğŸ”¬ ë¬¸ì„œ ë¶„ì„"):
            with gr.Row():
                with gr.Column():
                    doc_input_analysis = gr.Textbox(
                        label="ë¶„ì„í•  ë¬¸ì„œ ë‚´ìš©",
                        placeholder="ìƒì„¸ ë¶„ì„ì„ ìœ„í•´ ì—¬ê¸°ì— ë¬¸ì„œ ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
                        lines=8
                    )
                    source_input_analysis = gr.Textbox(
                        label="ì¶œì²˜ ì´ë¦„ (ì„ íƒ ì‚¬í•­)",
                        placeholder="ì˜ˆ: research_paper.pdf",
                        value="manual_input"
                    )
                    add_analysis_btn = gr.Button("ğŸ”¬ ì¶”ê°€ ë° ë¶„ì„", variant="primary")
                
                with gr.Column():
                    basic_result = gr.Textbox(
                        label="ê¸°ë³¸ ê²°ê³¼",
                        lines=3,
                        interactive=False
                    )
                    processing_info = gr.Textbox(
                        label="ì²˜ë¦¬ ë¶„ì„",
                        lines=6,
                        interactive=False
                    )
                    vector_info = gr.Textbox(
                        label="ë²¡í„° ë¶„ì„",
                        lines=8,
                        interactive=False
                    )
        
        with gr.Tab("ğŸ” ë¬¸ì„œ ê²€ìƒ‰"):
            with gr.Row():
                with gr.Column():
                    search_input = gr.Textbox(
                        label="ê²€ìƒ‰ì–´",
                        placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                    )
                    top_k = gr.Slider(
                        label="ê²°ê³¼ ìˆ˜",
                        minimum=1,
                        maximum=10,
                        value=3,
                        step=1
                    )
                    search_btn = gr.Button("ğŸ” ê²€ìƒ‰", variant="primary")
                
                with gr.Column():
                    search_output = gr.Textbox(
                        label="ê²€ìƒ‰ ê²°ê³¼",
                        lines=12,
                        interactive=False
                    )

        with gr.Tab("ğŸ”¬ ê²€ìƒ‰ ë¶„ì„"):
            with gr.Row():
                with gr.Column():
                    search_input_analysis = gr.Textbox(
                        label="ë¶„ì„í•  ê²€ìƒ‰ì–´",
                        placeholder="ìƒì„¸ ë¶„ì„ì„ ìœ„í•´ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                    )
                    top_k_analysis = gr.Slider(
                        label="ê²°ê³¼ ìˆ˜",
                        minimum=1,
                        maximum=10,
                        value=3,
                        step=1
                    )
                    search_analysis_btn = gr.Button("ğŸ”¬ ê²€ìƒ‰ ë° ë¶„ì„", variant="primary")
                
                with gr.Column():
                    search_results_analysis = gr.Textbox(
                        label="ê²€ìƒ‰ ê²°ê³¼",
                        lines=8,
                        interactive=False
                    )
                    search_processing_info = gr.Textbox(
                        label="ì²˜ë¦¬ ë¶„ì„",
                        lines=8,
                        interactive=False
                    )
                    search_vector_info = gr.Textbox(
                        label="ë²¡í„° ë¶„ì„",
                        lines=8,
                        interactive=False
                    )
        
        with gr.Tab("ğŸ“š ë¬¸ì„œ ë³´ê¸°"):
            with gr.Row():
                with gr.Column():
                    view_docs_btn = gr.Button("ğŸ“š ì „ì²´ ë¬¸ì„œ ë³´ê¸°", variant="primary")
                    documents_output = gr.Textbox(
                        label="ì €ì¥ëœ ë¬¸ì„œ",
                        lines=15,
                        interactive=False,
                        max_lines=20
                    )
                
                with gr.Column():
                    embedding_analysis_btn = gr.Button("ğŸ”¬ ì„ë² ë”© ë¶„ì„", variant="secondary")
                    embedding_output = gr.Textbox(
                        label="ì„ë² ë”© ë¶„ì„",
                        lines=15,
                        interactive=False
                    )

        with gr.Tab("ğŸ¤– RAG Q&A"):
            with gr.Row():
                with gr.Column():
                    question_input = gr.Textbox(
                        label="ì§ˆë¬¸",
                        placeholder="ë¬¸ì„œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”..."
                    )
                    max_sources = gr.Slider(
                        label="ì‚¬ìš©í•  ìµœëŒ€ ì¶œì²˜ ìˆ˜",
                        minimum=1,
                        maximum=5,
                        value=3,
                        step=1
                    )
                    answer_btn = gr.Button("ğŸ’¬ ë‹µë³€ ìƒì„±", variant="primary")
                
                with gr.Column():
                    answer_output = gr.Textbox(
                        label="AI ë‹µë³€",
                        lines=8,
                        interactive=False
                    )
                    sources_output = gr.Textbox(
                        label="ì¶œì²˜ ë¬¸ì„œ",
                        lines=8,
                        interactive=False
                    )
        
        with gr.Tab("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ"):
            with gr.Row():
                with gr.Column():
                    status_btn = gr.Button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", variant="secondary")
                    status_output = gr.Textbox(
                        label="ì‹œìŠ¤í…œ ì •ë³´",
                        lines=10,
                        interactive=False
                    )
                
                with gr.Column():
                    gr.Markdown("""
                    ### ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ ì •ë³´
                    
                    **ì‚¬ìš© ì¤‘ì¸ ê¸°ìˆ :**
                    - **LLM**: MockLLM (ê°œë°œìš©)
                    - **ë²¡í„° ìŠ¤í† ì–´**: MemoryVector (í•˜ì´ë¸Œë¦¬ë“œ)
                    - **ì„ë² ë”©**: SentenceTransformers
                    - **ê²€ìƒ‰**: BM25 + ë²¡í„° ìœ ì‚¬ë„
                    
                    **ì„±ëŠ¥ íŠ¹ì§•:**
                    - âœ… ë¹ ë¥¸ ì‘ë‹µ ì†ë„
                    - âœ… ë©”ëª¨ë¦¬ ê¸°ë°˜ ì²˜ë¦¬
                    - âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì •í™•ë„
                    - âœ… ì‹¤ì‹œê°„ ë¶„ì„ ê¸°ëŠ¥
                    """)
        
        # Async wrapper functions for Gradio compatibility
        def sync_add_document(content, source):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.add_document(content, source)
            return asyncio.run(run())
        
        def sync_add_document_with_analysis(content, source):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.add_document_with_analysis(content, source)
            return asyncio.run(run())
        
        def sync_clear_knowledge_base():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.clear_knowledge_base()
            return asyncio.run(run())
        
        def sync_search_documents(query, top_k):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.search_documents(query, top_k)
            return asyncio.run(run())
        
        def sync_search_documents_with_analysis(query, top_k):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.search_documents_with_analysis(query, top_k)
            return asyncio.run(run())
        
        def sync_generate_answer(question, max_sources):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.generate_answer(question, max_sources)
            return asyncio.run(run())
        
        def sync_get_status():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_status()
            return asyncio.run(run())

        def sync_view_all_documents():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.view_all_documents()
            return asyncio.run(run())

        def sync_get_embedding_analysis():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_embedding_analysis()
            return asyncio.run(run())

        # Event handlers
        add_btn.click(
            fn=sync_add_document,
            inputs=[doc_input, source_input],
            outputs=add_output
        )
        
        add_analysis_btn.click(
            fn=sync_add_document_with_analysis,
            inputs=[doc_input_analysis, source_input_analysis],
            outputs=[basic_result, processing_info, vector_info]
        )
        
        clear_btn.click(
            fn=sync_clear_knowledge_base,
            outputs=clear_output
        )
        
        search_btn.click(
            fn=sync_search_documents,
            inputs=[search_input, top_k],
            outputs=search_output
        )
        
        search_analysis_btn.click(
            fn=sync_search_documents_with_analysis,
            inputs=[search_input_analysis, top_k_analysis],
            outputs=[search_results_analysis, search_processing_info, search_vector_info]
        )
        
        answer_btn.click(
            fn=sync_generate_answer,
            inputs=[question_input, max_sources],
            outputs=[answer_output, sources_output]
        )
        
        status_btn.click(
            fn=sync_get_status,
            outputs=status_output
        )

        view_docs_btn.click(
            fn=sync_view_all_documents,
            outputs=documents_output
        )

        embedding_analysis_btn.click(
            fn=sync_get_embedding_analysis,
            outputs=embedding_output
        )
        
        # Load initial status
        demo.load(
            fn=sync_get_status,
            outputs=status_output
        )
    
    return demo


if __name__ == "__main__":
    logger.info("ğŸš€ Starting Hexagonal RAG Demo...")
    
    try:
        demo = create_demo_interface()
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            show_error=True
        )
    except Exception as e:
        logger.error(f"âŒ Failed to start demo: {e}")
        raise
