"""
HuggingFace Spaces Demo Entry Point
Hexagonal Architecture RAG Demo for AI Portfolio
"""

import asyncio
import gradio as gr
import logging
from typing import List, Tuple, Dict, Any
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import hexagonal architecture components
from src.application.services.rag_hexagonal_service import RAGHexagonalService
from src.adapters.outbound.llm.mock_llm_adapter import MockLLMAdapter
from src.adapters.outbound.databases.vector.vector_adapter_factory import VectorAdapterFactory


# í”„ë¡œë•ì…˜ ì„¤ì • ê³µìœ ë¥¼ ìœ„í•œ import
try:
    from src.shared.config.config_manager import ConfigManager
    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False
    logger.warning("ConfigLoader not available, using fallback configuration")


class RAGDemoInterface:
    """RAG ë°ëª¨ë¥¼ ìœ„í•œ Gradio ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        # í”„ë¡œë•ì…˜ ì„¤ì • ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.config_manager = None
        if CONFIG_AVAILABLE:
            try:
                self.config_manager = ConfigManager()
                logger.info("âœ… Production config manager initialized")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to initialize config manager: {e}")
        
        # Initialize hexagonal architecture components
        self.llm_adapter = MockLLMAdapter()
        
        # ë²¡í„°ìŠ¤í† ì–´ íŒ©í† ë¦¬ (ë°ëª¨ í™˜ê²½ìš©)
        self.vector_adapter_factory = VectorAdapterFactory(environment="demo")
        
        
        
        # ë²¡í„° ì–´ëŒ‘í„° ìƒì„± (RAGService í˜¸í™˜ìš©)
        self.vector_adapter = self.vector_adapter_factory.create_vector_adapter()
        
        self.rag_service = RAGHexagonalService(
            vector_store=self.vector_adapter,  # Vector Adapter ì‚¬ìš©
            llm_port=self.llm_adapter,
            config_manager=self.config_manager  # í”„ë¡œë•ì…˜ ì„¤ì • ê³µìœ 
        )
        self.initialized = False
        self.sample_data_loaded = False
        logger.info("âœ… Hexagonal RAG Demo initialized with production config sharing")

    async def initialize(self):
        """ë¹„ë™ê¸° ì´ˆê¸°í™” (ì„ë² ë”© ëª¨ë¸ ë¡œë“œ)"""
        if self.initialized:
            return
            
        try:
            logger.info("ğŸ”„ Initializing LLM and Vector adapters...")
            await self.llm_adapter.initialize()
            
            self.initialized = True
            logger.info("âœ… All adapters initialized successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize adapters: {e}")
            raise

    def load_sample_data(self) -> str:
        """sampledata ë””ë ‰í† ë¦¬ì—ì„œ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ (ê²½ëŸ‰í™”)"""
        try:
            # sampledata ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
            sample_path = Path("sampledata")
            
            if not sample_path.exists():
                return "âŒ sampledata ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
            logger.info(f"ğŸ“š ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì‹œì‘: {sample_path}")
            sample_data = []
            
            # í•µì‹¬ ë¬¸ì„œë§Œ ì„ íƒ (ê²½ëŸ‰í™”)
            core_files = [
                ("ai-portfolio.md", "AI í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ ê°œìš”"),
                ("qa_architecture.md", "í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜ Q&A"),
                ("qa_ai-services.md", "RAG ì‹œìŠ¤í…œ Q&A")
            ]
            
            for filename, title in core_files:
                file_path = sample_path / filename
                logger.info(f"ğŸ” íŒŒì¼ í™•ì¸: {file_path} (ì¡´ì¬: {file_path.exists()})")
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # ë‚´ìš©ì„ ê°„ë‹¨í•˜ê²Œ ìš”ì•½ (ì²« 2000ìë§Œ)
                        if len(content) > 2000:
                            content = content[:2000] + "\n\n... (ë‚´ìš©ì´ ê¸¸ì–´ì„œ ì¼ë¶€ë§Œ í¬í•¨)"
                        sample_data.append({
                            "content": content,
                            "source": filename,
                            "title": title
                        })
                        logger.info(f"âœ… {title} ë¡œë“œ ì™„ë£Œ ({len(content)} chars)")
                else:
                    logger.warning(f"âš ï¸  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
            
            logger.info(f"ğŸ“Š ì´ {len(sample_data)}ê°œì˜ ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ë¨")
            
            if not sample_data:
                return "âŒ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
            # ë¹„ë™ê¸°ë¡œ ë°ì´í„° ì¶”ê°€
            async def add_all_samples():
                await self.initialize()
                results = []
                for data in sample_data:
                    try:
                        result = await self.rag_service.add_document_from_text(
                            content=data["content"],
                            source=data["source"],
                            metadata={"title": data["title"], "type": "sample_data"}
                        )
                        if result.get("success"):
                            results.append(f"âœ… {data['title']} ì¶”ê°€ ì™„ë£Œ")
                        else:
                            results.append(f"âŒ {data['title']} ì¶”ê°€ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    except Exception as e:
                        results.append(f"âŒ {data['title']} ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
                
                self.sample_data_loaded = True
                return "\n".join(results)
            
            return asyncio.run(add_all_samples())
            
        except Exception as e:
            logger.error(f"ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}"

    def get_sample_queries(self) -> List[str]:
        """ìƒ˜í”Œ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡ ë°˜í™˜ (ê²½ëŸ‰í™”)"""
        return [
            "í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜ëŠ” ì–´ë–»ê²Œ êµ¬í˜„ë˜ì—ˆë‚˜ìš”?",
            "RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ êµ¬ì„± ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "í”„ë¡œì íŠ¸ì˜ ì£¼ìš” ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ì–´ë–¤ ê¸°ìˆ  ìŠ¤íƒì„ ì‚¬ìš©í–ˆë‚˜ìš”?"
        ]
    
    async def add_document(self, content: str, source: str = "manual_input") -> str:
        """ì§€ì‹ ë² ì´ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€"""
        if not content.strip():
            return "âŒ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"
        
        try:
            result = await self.rag_service.add_document_from_text(
                content=content.strip(),
                source=source,
                metadata={"timestamp": "demo"}
            )
            
            if result.get("success"):
                return f"âœ… ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! ë¬¸ì„œ ID: {result.get('document_id', 'N/A')}"
            else:
                return f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    async def add_document_with_analysis(self, content: str, source: str = "manual_input") -> Tuple[str, str, str]:
        """ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ì¶”ê°€"""
        if not content.strip():
            return "âŒ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", "", ""
        
        try:
            result = await self.rag_service.add_document_with_analysis(
                content=content.strip(),
                source=source,
                metadata={"timestamp": "demo"}
            )
            
            if not result.get("success"):
                return f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}", "", ""
            
            # ê¸°ë³¸ ê²°ê³¼
            basic_result = f"âœ… ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!\në¬¸ì„œ ID: {result.get('document_id', 'N/A')}\nì¶œì²˜: {result.get('source', 'N/A')}"
            
            # ì²˜ë¦¬ ê³¼ì • ë¶„ì„
            processing_steps = result.get("processing_steps", {})
            vector_result = result.get("vector_result", {})
            
            processing_info = f"â±ï¸ **ì²˜ë¦¬ ë¶„ì„:**\n"
            processing_info += f"â€¢ ëª¨ë¸ ìƒì„±: {processing_steps.get('model_creation', 0):.3f}s\n"
            processing_info += f"â€¢ ë²¡í„° ì²˜ë¦¬: {processing_steps.get('vector_processing', 0):.3f}s\n"
            processing_info += f"â€¢ ì´ ì‹œê°„: {processing_steps.get('total_time', 0):.3f}s\n\n"
            
            # ë²¡í„° ì²˜ë¦¬ ê²°ê³¼
            if vector_result.get("success"):
                vector_info = f"ğŸ”¢ **ë²¡í„° ë¶„ì„:**\n"
                vector_info += f"â€¢ ìƒì„±ëœ ì²­í¬: {vector_result.get('chunks_created', 0)}\n"
                vector_info += f"â€¢ ë²¡í„° ì°¨ì›: {vector_result.get('vector_dimensions', 0)}\n"
                vector_info += f"â€¢ ì´ ë¬¸ì„œ ìˆ˜: {vector_result.get('total_documents', 0)}\n"
                vector_info += f"â€¢ ì´ ì²­í¬ ìˆ˜: {vector_result.get('total_chunks', 0)}\n\n"
                
                # ì²­í¬ ìƒì„¸ ì •ë³´
                chunk_details = vector_result.get("chunk_details", [])
                if chunk_details:
                    vector_info += "ğŸ“„ **ì²­í¬ ìƒì„¸ ì •ë³´:**\n"
                    for i, chunk in enumerate(chunk_details, 1):
                        vector_info += f"â€¢ ì²­í¬ {i}: {chunk['length']} chars - {chunk['content_preview']}\n"
            else:
                vector_info = "âŒ ë²¡í„° ì²˜ë¦¬ ì‹¤íŒ¨"
            
            return basic_result, processing_info, vector_info
                
        except Exception as e:
            logger.error(f"ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", "", ""
    
    async def search_documents(self, query: str, top_k: int = 3) -> str:
        """ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰"""
        if not query.strip():
            return "âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”"
        
        try:
            result = await self.rag_service.search_documents(
                query=query.strip(),
                top_k=top_k,
                similarity_threshold=0.1
            )
            
            if not result.get("success"):
                return f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"
            
            documents = result.get("results", [])
            if not documents:
                return "ğŸ“­ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
            output = f"ğŸ” {len(documents)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            for i, doc in enumerate(documents, 1):
                output += f"**{i}. ì ìˆ˜: {doc.get('similarity_score', 0):.3f}**\n"
                output += f"{doc.get('content', 'ë‚´ìš© ì—†ìŒ')[:200]}...\n\n"
            
            return output
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    async def demonstrate_retriever_process(self, query: str) -> Tuple[str, str, str]:
        """ë¦¬íŠ¸ë¦¬ë²„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì‹œì—°"""
        if not query.strip():
            return "âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", "", ""
        
        try:
            # 1ë‹¨ê³„: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            step1_info = "ğŸ”„ **1ë‹¨ê³„: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±**\n"
            step1_info += f"â€¢ ì¿¼ë¦¬: '{query}'\n"
            step1_info += f"â€¢ ëª¨ë¸: sentence-transformers/all-MiniLM-L6-v2\n"
            step1_info += f"â€¢ ë²¡í„° ì°¨ì›: 384\n"
            
            # 2ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰
            step2_info = "ğŸ” **2ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰**\n"
            step2_info += f"â€¢ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ + BM25\n"
            step2_info += f"â€¢ ê²€ìƒ‰ ë²”ìœ„: ì „ì²´ ë²¡í„° ìŠ¤í† ì–´\n"
            
            # ì‹¤ì œ ê²€ìƒ‰ ì‹¤í–‰
            result = await self.rag_service.search_documents_with_analysis(
                query=query.strip(),
                top_k=5,
                similarity_threshold=0.1
            )
            
            if not result.get("success"):
                return f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}", "", ""
            
            documents = result.get("results", [])
            detailed_analysis = result.get("detailed_analysis", {})
            processing_steps = detailed_analysis.get("processing_steps", {})
            
            # 3ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼
            step3_info = "ğŸ“Š **3ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼**\n"
            step3_info += f"â€¢ ì°¾ì€ ë¬¸ì„œ: {len(documents)}ê°œ\n"
            step3_info += f"â€¢ ì²˜ë¦¬ ì‹œê°„: {processing_steps.get('total_time', 0):.3f}s\n\n"
            
            for i, doc in enumerate(documents[:3], 1):
                step3_info += f"**{i}. ìœ ì‚¬ë„: {doc.get('similarity_score', 0):.3f}**\n"
                step3_info += f"{doc.get('content', '')[:150]}...\n\n"
            
            # ìƒì„¸ ë¶„ì„ ì •ë³´
            analysis_info = "ğŸ”¬ **ìƒì„¸ ë¶„ì„**\n"
            analysis_info += f"â€¢ ì „ì²˜ë¦¬: {processing_steps.get('preprocessing', 0):.3f}s\n"
            analysis_info += f"â€¢ ë²¡í„°í™”: {processing_steps.get('vectorization', 0):.3f}s\n"
            analysis_info += f"â€¢ ìœ ì‚¬ë„ ê³„ì‚°: {processing_steps.get('similarity_calculation', 0):.3f}s\n"
            analysis_info += f"â€¢ ì •ë ¬: {processing_steps.get('sorting', 0):.3f}s\n"
            
            vector_info = detailed_analysis.get("vector_info", {})
            analysis_info += f"â€¢ ë²¡í„° ì°¨ì›: {vector_info.get('dimensions', 384)}\n"
            analysis_info += f"â€¢ ì´ ì²­í¬ ìˆ˜: {vector_info.get('total_chunks', 0)}\n"
            analysis_info += f"â€¢ ì²˜ë¦¬ëœ ì²­í¬: {vector_info.get('processed_chunks', 0)}\n"
            
            return step1_info, step2_info + step3_info, analysis_info
                
        except Exception as e:
            logger.error(f"ë¦¬íŠ¸ë¦¬ë²„ ê³¼ì • ì‹œì—° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", "", ""

    async def search_documents_with_analysis(self, query: str, top_k: int = 3) -> Tuple[str, str, str]:
        """ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ê²€ìƒ‰"""
        if not query.strip():
            return "âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", "", ""
        
        try:
            result = await self.rag_service.search_documents_with_analysis(
                query=query.strip(),
                top_k=top_k,
                similarity_threshold=0.1
            )
            
            if not result.get("success"):
                return f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}", "", ""
            
            # ê²€ìƒ‰ ê²°ê³¼
            documents = result.get("results", [])
            if not documents:
                return "ğŸ“­ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "", ""
            
            search_results = f"ğŸ” {len(documents)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            for i, doc in enumerate(documents, 1):
                search_results += f"**{i}. ì ìˆ˜: {doc.get('similarity_score', 0):.3f}**\n"
                search_results += f"{doc.get('content', 'ë‚´ìš© ì—†ìŒ')[:200]}...\n\n"
            
            # ì²˜ë¦¬ ê³¼ì • ë¶„ì„
            detailed_analysis = result.get("detailed_analysis", {})
            processing_steps = detailed_analysis.get("processing_steps", {})
            vector_info = detailed_analysis.get("vector_info", {})
            
            processing_info = f"â±ï¸ **ì²˜ë¦¬ ë¶„ì„:**\n"
            processing_info += f"â€¢ ì „ì²˜ë¦¬: {processing_steps.get('preprocessing', 0):.3f}s\n"
            processing_info += f"â€¢ ë²¡í„°í™”: {processing_steps.get('vectorization', 0):.3f}s\n"
            processing_info += f"â€¢ ìœ ì‚¬ë„ ê³„ì‚°: {processing_steps.get('similarity_calculation', 0):.3f}s\n"
            processing_info += f"â€¢ ì •ë ¬: {processing_steps.get('sorting', 0):.3f}s\n"
            processing_info += f"â€¢ ê²°ê³¼ ìƒì„±: {processing_steps.get('result_creation', 0):.3f}s\n"
            processing_info += f"â€¢ ì´ ì‹œê°„: {processing_steps.get('total_time', 0):.3f}s\n\n"
            
            # ë²¡í„° ì •ë³´
            vector_analysis = f"ğŸ”¢ **ë²¡í„° ë¶„ì„:**\n"
            vector_analysis += f"â€¢ ë²¡í„° ì°¨ì›: {vector_info.get('dimensions', 0)}\n"
            vector_analysis += f"â€¢ ì´ ì²­í¬ ìˆ˜: {vector_info.get('total_chunks', 0)}\n"
            vector_analysis += f"â€¢ ì²˜ë¦¬ëœ ì²­í¬: {vector_info.get('processed_chunks', 0)}\n"
            vector_analysis += f"â€¢ ìœ ì‚¬ë„ ì„ê³„ê°’: {vector_info.get('threshold_applied', 0)}\n\n"
            
            # ìœ ì‚¬ë„ ë¶„í¬
            similarity_dist = detailed_analysis.get("similarity_distribution", {})
            vector_analysis += f"ğŸ“Š **ìœ ì‚¬ë„ ë¶„í¬:**\n"
            vector_analysis += f"â€¢ ì •í™•íˆ ì¼ì¹˜: {similarity_dist.get('exact_matches', 0)}\n"
            vector_analysis += f"â€¢ ìœ ì‚¬ë„ ì¼ì¹˜: {similarity_dist.get('similarity_matches', 0)}\n"
            vector_analysis += f"â€¢ ë¬¸ë§¥ìƒ ì¼ì¹˜: {similarity_dist.get('contextual_matches', 0)}\n"
            
            return search_results, processing_info, vector_analysis
                
        except Exception as e:
            logger.error(f"ìƒì„¸ ë¶„ì„ê³¼ í•¨ê»˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", "", ""
    
    async def generate_answer(self, question: str, max_results: int = 3) -> Tuple[str, str]:
        """ì¶œì²˜ì™€ í•¨ê»˜ RAG ë‹µë³€ ìƒì„±"""
        if not question.strip():
            return "âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", ""
        
        try:
            result = await self.rag_service.generate_rag_answer(
                question=question.strip(),
                context_hint=None,
                metadata={"timestamp": "demo"}
            )
            
            # Format answer
            answer = f"ğŸ¤– **ë‹µë³€:**\n{result.answer}\n\n"
            answer += f"â±ï¸ **ì²˜ë¦¬ ì‹œê°„:** {result.processing_time_ms:.0f}ms\n"
            answer += f"ğŸ¯ **ì‹ ë¢°ë„:** {result.confidence:.2f}"
            
            # Format sources
            if result.sources:
                sources = "ğŸ“š **ì‚¬ìš©ëœ ì¶œì²˜:**\n\n"
                for i, source in enumerate(result.sources, 1):
                    sources += f"**{i}. ìœ ì‚¬ë„: {source.similarity_score:.3f}**\n"
                    sources += f"{source.chunk.content[:300]}...\n\n"
            else:
                sources = "ğŸ“­ ì¶œì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
            return answer, sources
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", ""
    
    async def clear_knowledge_base(self) -> str:
        """ì§€ì‹ ë² ì´ìŠ¤ì˜ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ"""
        try:
            result = await self.rag_service.clear_storage()
            if result.get("success"):
                return "âœ… ì§€ì‹ ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
            else:
                return f"âŒ ì‚­ì œ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {str(e)}"
    
    async def get_status(self) -> str:
        """ì‹œìŠ¤í…œ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°"""
        try:
            status = await self.rag_service.get_status()
            
            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ì–´ëŒ‘í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            llm_info = await self.llm_adapter.get_info()
            vector_info = await self.vector_adapter.get_info()
            
            return f"""
ğŸ“Š **ì‹œìŠ¤í…œ ìƒíƒœ**

**ğŸ“„ ë¬¸ì„œ ê´€ë¦¬:**
â€¢ ì €ì¥ëœ ë¬¸ì„œ: {status.get('document_count', 0)}ê°œ
â€¢ ë²¡í„° ì„ë² ë”©: {status.get('vector_count', 0)}ê°œ

**ğŸ¤– LLM ì„œë¹„ìŠ¤:**
â€¢ ëª¨ë¸: {llm_info.get('model_name', 'MockLLM')}
â€¢ ìƒíƒœ: {'âœ… ì¤€ë¹„ë¨' if status.get('llm_available') else 'âŒ ì‚¬ìš© ë¶ˆê°€'}
â€¢ íƒ€ì…: {llm_info.get('type', 'Mock')}

**ğŸ” ë²¡í„° ìŠ¤í† ì–´:**
â€¢ ìŠ¤í† ì–´: {vector_info.get('store_name', 'MemoryVector')}
â€¢ ìƒíƒœ: {'âœ… ì¤€ë¹„ë¨' if status.get('vector_store_available') else 'âŒ ì‚¬ìš© ë¶ˆê°€'}
â€¢ í™˜ê²½: {self.vector_adapter_factory.environment}
â€¢ ì €ì¥ëœ ë²¡í„°: {vector_info.get('stored_vectors', 0)}ê°œ

**ğŸ”¤ ì„ë² ë”© ì„œë¹„ìŠ¤:**
â€¢ ëª¨ë¸: {vector_info.get('embedding_model', 'sentence-transformers/all-MiniLM-L6-v2')}
â€¢ ì°¨ì›: {vector_info.get('dimensions', 384)}
â€¢ ìƒíƒœ: {'âœ… ì¤€ë¹„ë¨' if vector_info.get('embedding_available', True) else 'âŒ ì‚¬ìš© ë¶ˆê°€'}
            """
        except Exception as e:
            return f"âŒ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}"

    async def view_all_documents(self) -> str:
        """ë°ëª¨: ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œ ë³´ê¸°"""
        try:
            documents = await self.vector_adapter.get_all_documents()
            
            if not documents:
                return "ğŸ“­ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
            
            output = f"ğŸ“š **ì €ì¥ëœ ë¬¸ì„œ ({len(documents)}ê°œ)**\n\n"
            
            for i, doc in enumerate(documents, 1):
                output += f"**{i}. {doc['source']}** `{doc['id'][:8]}...`\n"
                output += f"â€¢ **ê¸¸ì´**: {doc['content_length']} chars\n"
                output += f"â€¢ **ìƒì„±ì¼**: {doc['created_at'][:19] if doc['created_at'] else 'N/A'}\n"
                output += f"â€¢ **ë¯¸ë¦¬ë³´ê¸°**: {doc['content_preview']}\n\n"
                
            return output
            
        except Exception as e:
            logger.error(f"ì „ì²´ ë¬¸ì„œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    async def get_embedding_analysis(self) -> str:
        """ë°ëª¨: ì„ë² ë”© ë¶„ì„ ì •ë³´"""
        try:
            info = await self.vector_adapter.get_embedding_info()
            
            if not info.get("embeddings_available"):
                return "âŒ ì„ë² ë”©ì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
                
            output = f"""
ğŸ”¬ **ì„ë² ë”© ë¶„ì„**

**ëª¨ë¸**: {info['model_name']}
**ë¬¸ì„œ ìˆ˜**: {info['document_count']}
**ì„ë² ë”© ì°¨ì›**: {info['embedding_dimensions']}
**ì„ë² ë”© í˜•íƒœ**: {info['embedding_shape']}
**ìƒ˜í”Œ ë²¡í„° í¬ê¸°**: {info['sample_embedding_norm']:.4f}
            """
            
            return output
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    async def get_memory_info(self) -> str:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë° ìƒíƒœ ì •ë³´"""
        try:
            import psutil
            import gc
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰í„° ì •ë³´
            gc_stats = gc.get_stats()
            
            # í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì •ë³´
            process = psutil.Process()
            process_memory = process.memory_info()
            
            output = f"""
ğŸ’¾ **ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ìƒíƒœ**

**ì „ì²´ ë©”ëª¨ë¦¬:**
â€¢ ì´ ë©”ëª¨ë¦¬: {memory.total / (1024**3):.2f} GB
â€¢ ì‚¬ìš© ê°€ëŠ¥: {memory.available / (1024**3):.2f} GB
â€¢ ì‚¬ìš©ë¥ : {memory.percent:.1f}%
â€¢ ì‚¬ìš© ì¤‘: {memory.used / (1024**3):.2f} GB

**ìŠ¤ì™‘ ë©”ëª¨ë¦¬:**
â€¢ ì´ ìŠ¤ì™‘: {swap.total / (1024**3):.2f} GB
â€¢ ì‚¬ìš© ì¤‘: {swap.used / (1024**3):.2f} GB
â€¢ ì‚¬ìš©ë¥ : {swap.percent:.1f}%

**í˜„ì¬ í”„ë¡œì„¸ìŠ¤:**
â€¢ RSS (ë¬¼ë¦¬ ë©”ëª¨ë¦¬): {process_memory.rss / (1024**2):.2f} MB
â€¢ VMS (ê°€ìƒ ë©”ëª¨ë¦¬): {process_memory.vms / (1024**2):.2f} MB

**ê°€ë¹„ì§€ ì»¬ë ‰í„°:**
â€¢ ì„¸ëŒ€ 0: {gc_stats[0]['collections']}íšŒ ìˆ˜ì§‘
â€¢ ì„¸ëŒ€ 1: {gc_stats[1]['collections']}íšŒ ìˆ˜ì§‘
â€¢ ì„¸ëŒ€ 2: {gc_stats[2]['collections']}íšŒ ìˆ˜ì§‘
            """
            
            return output
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ë©”ëª¨ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}"

    async def get_chunk_analysis(self) -> str:
        """ì²­í¬ ë¶„ì„ ì •ë³´"""
        try:
            # ëª¨ë“  ë¬¸ì„œì˜ ì²­í¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            documents = await self.vector_adapter.get_all_documents()
            
            if not documents:
                return "ğŸ“­ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ì²­í¬ í†µê³„ ê³„ì‚°
            total_chunks = 0
            chunk_lengths = []
            chunk_sources = {}
            
            for doc in documents:
                chunks = await self.vector_adapter.get_document_chunks(doc['id'])
                total_chunks += len(chunks)
                
                for chunk in chunks:
                    chunk_lengths.append(len(chunk.get('content', '')))
                    source = chunk.get('source', 'unknown')
                    chunk_sources[source] = chunk_sources.get(source, 0) + 1
            
            if not chunk_lengths:
                return "ğŸ“­ ì²­í¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            avg_length = sum(chunk_lengths) / len(chunk_lengths)
            min_length = min(chunk_lengths)
            max_length = max(chunk_lengths)
            
            output = f"""
ğŸ“„ **ì²­í¬ ë¶„ì„**

**ê¸°ë³¸ í†µê³„:**
â€¢ ì´ ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ
â€¢ ì´ ì²­í¬ ìˆ˜: {total_chunks}ê°œ
â€¢ í‰ê·  ì²­í¬ ê¸¸ì´: {avg_length:.1f} ë¬¸ì
â€¢ ìµœì†Œ ì²­í¬ ê¸¸ì´: {min_length} ë¬¸ì
â€¢ ìµœëŒ€ ì²­í¬ ê¸¸ì´: {max_length} ë¬¸ì

**ì¶œì²˜ë³„ ì²­í¬ ë¶„í¬:**
"""
            
            for source, count in sorted(chunk_sources.items(), key=lambda x: x[1], reverse=True):
                output += f"â€¢ {source}: {count}ê°œ ì²­í¬\n"
            
            # ê¸¸ì´ ë¶„í¬ ë¶„ì„
            short_chunks = len([l for l in chunk_lengths if l < 100])
            medium_chunks = len([l for l in chunk_lengths if 100 <= l < 500])
            long_chunks = len([l for l in chunk_lengths if l >= 500])
            
            output += f"""
**ê¸¸ì´ ë¶„í¬:**
â€¢ ì§§ì€ ì²­í¬ (<100ì): {short_chunks}ê°œ ({short_chunks/total_chunks*100:.1f}%)
â€¢ ì¤‘ê°„ ì²­í¬ (100-500ì): {medium_chunks}ê°œ ({medium_chunks/total_chunks*100:.1f}%)
â€¢ ê¸´ ì²­í¬ (â‰¥500ì): {long_chunks}ê°œ ({long_chunks/total_chunks*100:.1f}%)
            """
            
            return output
            
        except Exception as e:
            logger.error(f"ì²­í¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì²­í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"

    async def get_vector_store_detailed_info(self) -> str:
        """ë²¡í„°ìŠ¤í† ì–´ ìƒì„¸ ì •ë³´"""
        try:
            # ê¸°ë³¸ ì •ë³´
            info = await self.vector_adapter.get_info()
            embedding_info = await self.vector_adapter.get_embedding_info()
            
            # ì €ì¥ëœ ë¬¸ì„œ ì •ë³´
            documents = await self.vector_adapter.get_all_documents()
            
            # ë²¡í„° í†µê³„
            total_vectors = 0
            vector_dimensions = 0
            if documents:
                total_vectors = sum(len(await self.vector_adapter.get_document_chunks(doc['id'])) for doc in documents)
                if documents:
                    sample_chunks = await self.vector_adapter.get_document_chunks(documents[0]['id'])
                    if sample_chunks:
                        vector_dimensions = len(sample_chunks[0].get('embedding', []))
            
            output = f"""
ğŸ” **ë²¡í„°ìŠ¤í† ì–´ ìƒì„¸ ì •ë³´**

**ìŠ¤í† ì–´ ì •ë³´:**
â€¢ ìŠ¤í† ì–´ ì´ë¦„: {info.get('store_name', 'Unknown')}
â€¢ ìŠ¤í† ì–´ íƒ€ì…: {info.get('store_type', 'Unknown')}
â€¢ ì´ˆê¸°í™” ìƒíƒœ: {'âœ… ì´ˆê¸°í™”ë¨' if info.get('initialized', False) else 'âŒ ì´ˆê¸°í™” ì•ˆë¨'}

**ì„ë² ë”© ëª¨ë¸:**
â€¢ ëª¨ë¸ëª…: {embedding_info.get('model_name', 'Unknown')}
â€¢ ì°¨ì›: {embedding_info.get('embedding_dimensions', 0)}
â€¢ ëª¨ë¸ í˜•íƒœ: {embedding_info.get('embedding_shape', 'Unknown')}
â€¢ ìƒ˜í”Œ ë²¡í„° í¬ê¸°: {embedding_info.get('sample_embedding_norm', 0):.4f}

**ì €ì¥ëœ ë°ì´í„°:**
â€¢ ì´ ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ
â€¢ ì´ ë²¡í„° ìˆ˜: {total_vectors}ê°œ
â€¢ í‰ê·  ë¬¸ì„œ ê¸¸ì´: {sum(len(doc.get('content', '')) for doc in documents) / len(documents) if documents else 0:.1f} ë¬¸ì

**ì„±ëŠ¥ ì •ë³´:**
â€¢ ì„ë² ë”© ìƒì„± ê°€ëŠ¥: {'âœ… ê°€ëŠ¥' if embedding_info.get('embeddings_available', False) else 'âŒ ë¶ˆê°€ëŠ¥'}
â€¢ ë²¡í„° ê²€ìƒ‰ ê°€ëŠ¥: {'âœ… ê°€ëŠ¥' if info.get('search_available', True) else 'âŒ ë¶ˆê°€ëŠ¥'}
â€¢ ë²¡í„° ì €ì¥ ê°€ëŠ¥: {'âœ… ê°€ëŠ¥' if info.get('storage_available', True) else 'âŒ ë¶ˆê°€ëŠ¥'}
            """
            
            return output
            
        except Exception as e:
            logger.error(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ë²¡í„°ìŠ¤í† ì–´ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}"

    async def get_memory_content(self) -> str:
        """ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ì‹¤ì œ ë‚´ìš© í™•ì¸"""
        try:
            # ë©”ëª¨ë¦¬ ì–´ëŒ‘í„°ì—ì„œ ì§ì ‘ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if hasattr(self.vector_adapter, 'get_memory_content'):
                content = await self.vector_adapter.get_memory_content()
                return content
            
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ë‚´ìš© (ë¬¸ì„œ ëª©ë¡)
            documents = await self.vector_adapter.get_all_documents()
            
            if not documents:
                return "ğŸ“­ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
            
            output = f"ğŸ’¾ **ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ë‚´ìš© ({len(documents)}ê°œ ë¬¸ì„œ)**\n\n"
            
            for i, doc in enumerate(documents, 1):
                output += f"**{i}. ë¬¸ì„œ ID: {doc['id']}**\n"
                output += f"â€¢ ì¶œì²˜: {doc['source']}\n"
                output += f"â€¢ ê¸¸ì´: {doc['content_length']} ë¬¸ì\n"
                output += f"â€¢ ìƒì„±ì¼: {doc['created_at'][:19] if doc['created_at'] else 'N/A'}\n"
                output += f"â€¢ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n{doc['content_preview'][:300]}...\n\n"
                
                # ì²­í¬ ì •ë³´ë„ í¬í•¨
                chunks = await self.vector_adapter.get_document_chunks(doc['id'])
                output += f"  ğŸ“„ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ\n"
                for j, chunk in enumerate(chunks[:3], 1):  # ì²˜ìŒ 3ê°œ ì²­í¬ë§Œ
                    output += f"    â€¢ ì²­í¬ {j}: {chunk.get('content', '')[:100]}...\n"
                output += "\n"
            
            return output
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ë©”ëª¨ë¦¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}"

    async def get_chunk_content(self) -> str:
        """ì²­í¬ì˜ ì‹¤ì œ ë‚´ìš© í™•ì¸"""
        try:
            documents = await self.vector_adapter.get_all_documents()
            
            if not documents:
                return "ğŸ“­ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
            
            output = f"ğŸ“„ **ì²­í¬ ë‚´ìš© í™•ì¸**\n\n"
            
            for i, doc in enumerate(documents, 1):
                chunks = await self.vector_adapter.get_document_chunks(doc['id'])
                
                output += f"**ë¬¸ì„œ {i}: {doc['source']}** (ID: {doc['id'][:8]}...)\n"
                output += f"ì´ {len(chunks)}ê°œ ì²­í¬\n\n"
                
                for j, chunk in enumerate(chunks, 1):
                    output += f"**ì²­í¬ {j}:**\n"
                    output += f"â€¢ ê¸¸ì´: {len(chunk.get('content', ''))} ë¬¸ì\n"
                    output += f"â€¢ ë‚´ìš©:\n{chunk.get('content', '')}\n\n"
                    
                    # ì²˜ìŒ 2ê°œ ë¬¸ì„œì˜ ì²˜ìŒ 3ê°œ ì²­í¬ë§Œ í‘œì‹œ
                    if i > 2 or j > 3:
                        break
                
                if i > 2:
                    output += "... (ë” ë§ì€ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤)\n"
                    break
                
                output += "---\n\n"
            
            return output
            
        except Exception as e:
            logger.error(f"ì²­í¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì²­í¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}"

    async def get_vector_store_content(self) -> str:
        """ë²¡í„°ìŠ¤í† ì–´ì˜ ì‹¤ì œ ë‚´ìš© í™•ì¸"""
        try:
            documents = await self.vector_adapter.get_all_documents()
            
            if not documents:
                return "ğŸ“­ ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
            
            output = f"ğŸ” **ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš© í™•ì¸**\n\n"
            
            for i, doc in enumerate(documents, 1):
                chunks = await self.vector_adapter.get_document_chunks(doc['id'])
                
                output += f"**ë¬¸ì„œ {i}: {doc['source']}**\n"
                output += f"â€¢ ë¬¸ì„œ ID: {doc['id']}\n"
                output += f"â€¢ ì „ì²´ ë‚´ìš© ê¸¸ì´: {doc['content_length']} ë¬¸ì\n"
                output += f"â€¢ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ\n"
                output += f"â€¢ ìƒì„±ì¼: {doc['created_at'][:19] if doc['created_at'] else 'N/A'}\n\n"
                
                # ë²¡í„° ì •ë³´ í¬í•¨
                if chunks:
                    sample_chunk = chunks[0]
                    embedding = sample_chunk.get('embedding', [])
                    output += f"**ë²¡í„° ì •ë³´:**\n"
                    output += f"â€¢ ë²¡í„° ì°¨ì›: {len(embedding)}\n"
                    output += f"â€¢ ìƒ˜í”Œ ë²¡í„° (ì²˜ìŒ 10ê°œ): {embedding[:10]}\n"
                    output += f"â€¢ ë²¡í„° í¬ê¸°: {len(embedding)} ì°¨ì›\n\n"
                
                # ì²­í¬ ìƒì„¸ ì •ë³´
                output += f"**ì²­í¬ ìƒì„¸ ì •ë³´:**\n"
                for j, chunk in enumerate(chunks, 1):
                    output += f"â€¢ ì²­í¬ {j}: {len(chunk.get('content', ''))} ë¬¸ì\n"
                    output += f"  ë‚´ìš©: {chunk.get('content', '')[:200]}...\n"
                    if j >= 3:  # ì²˜ìŒ 3ê°œ ì²­í¬ë§Œ
                        break
                
                output += "\n---\n\n"
                
                if i >= 3:  # ì²˜ìŒ 3ê°œ ë¬¸ì„œë§Œ
                    output += "... (ë” ë§ì€ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤)\n"
                    break
            
            return output
            
        except Exception as e:
            logger.error(f"ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}"

    async def demonstrate_complete_rag_pipeline(self, content: str, query: str) -> Tuple[str, str, str, str]:
        """ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸ ì‹œì—°: ë¬¸ì„œ ì¶”ê°€ë¶€í„° ê²€ìƒ‰ê¹Œì§€"""
        try:
            pipeline_log = []
            
            # === 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë”© ===
            pipeline_log.append("ğŸ”„ **1ë‹¨ê³„: ë¬¸ì„œ ë¡œë”©**")
            pipeline_log.append(f"â€¢ ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(content)} ë¬¸ì")
            pipeline_log.append(f"â€¢ ë¬¸ì„œ íƒ€ì…: í…ìŠ¤íŠ¸")
            pipeline_log.append(f"â€¢ ì²˜ë¦¬ ì‹œê°„: ì¦‰ì‹œ\n")
            
            # === 2ë‹¨ê³„: ë¬¸ì„œ ì €ì¥ ë° ë²¡í„°í™” ===
            pipeline_log.append("ğŸ”„ **2ë‹¨ê³„: ë¬¸ì„œ ì €ì¥ ë° ë²¡í„°í™”**")
            add_result = await self.rag_service.add_document_with_analysis(
                content=content.strip(),
                source="pipeline_demo",
                metadata={"demo": "complete_pipeline"}
            )
            
            if not add_result.get("success"):
                return "âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨", "", "", ""
            
            processing_steps = add_result.get("processing_steps", {})
            vector_result = add_result.get("vector_result", {})
            
            pipeline_log.append(f"â€¢ ì„ë² ë”© ëª¨ë¸: sentence-transformers/all-MiniLM-L6-v2")
            pipeline_log.append(f"â€¢ ë²¡í„° ì°¨ì›: {vector_result.get('vector_dimensions', 384)}")
            pipeline_log.append(f"â€¢ ìƒì„±ëœ ì²­í¬: {vector_result.get('chunks_created', 0)}ê°œ")
            pipeline_log.append(f"â€¢ ë²¡í„°í™” ì‹œê°„: {processing_steps.get('vector_processing', 0):.3f}s")
            pipeline_log.append(f"â€¢ BM25 ì¸ë±ì‹± ì™„ë£Œ\n")
            
            # === 3ë‹¨ê³„: ì¿¼ë¦¬ ì²˜ë¦¬ ===
            pipeline_log.append("ğŸ” **3ë‹¨ê³„: ì¿¼ë¦¬ ì²˜ë¦¬**")
            pipeline_log.append(f"â€¢ ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
            pipeline_log.append(f"â€¢ ì¿¼ë¦¬ ê¸¸ì´: {len(query)} ë¬¸ì")
            pipeline_log.append(f"â€¢ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜: í•˜ì´ë¸Œë¦¬ë“œ (Vector + BM25)\n")
            
            # === 4ë‹¨ê³„: ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰ ===
            search_result = await self.rag_service.search_documents_with_analysis(
                query=query.strip(),
                top_k=3,
                similarity_threshold=0.1
            )
            
            if not search_result.get("success"):
                return "\n".join(pipeline_log), "âŒ ê²€ìƒ‰ ì‹¤íŒ¨", "", ""
            
            documents = search_result.get("results", [])
            detailed_analysis = search_result.get("detailed_analysis", {})
            processing_steps_search = detailed_analysis.get("processing_steps", {})
            
            pipeline_log.append("ğŸ“Š **4ë‹¨ê³„: ê²€ìƒ‰ ì‹¤í–‰ ê²°ê³¼**")
            pipeline_log.append(f"â€¢ ì°¾ì€ ë¬¸ì„œ: {len(documents)}ê°œ")
            pipeline_log.append(f"â€¢ ê²€ìƒ‰ ì‹œê°„: {processing_steps_search.get('total_time', 0):.3f}s")
            pipeline_log.append(f"â€¢ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°: {processing_steps_search.get('similarity_calculation', 0):.3f}s")
            pipeline_log.append(f"â€¢ BM25 ì ìˆ˜ ê³„ì‚°: {processing_steps_search.get('preprocessing', 0):.3f}s")
            
            # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
            search_results = f"ğŸ” **ê²€ìƒ‰ ê²°ê³¼ ({len(documents)}ê°œ)**\n\n"
            for i, doc in enumerate(documents, 1):
                search_results += f"**{i}. ìœ ì‚¬ë„: {doc.get('similarity_score', 0):.3f}**\n"
                search_results += f"{doc.get('content', '')[:300]}...\n\n"
            
            # ë²¡í„° ë¶„ì„ ì •ë³´
            vector_info = detailed_analysis.get("vector_info", {})
            vector_analysis = f"ğŸ”¢ **ë²¡í„° ë¶„ì„**\n"
            vector_analysis += f"â€¢ ì²˜ë¦¬ëœ ì²­í¬: {vector_info.get('processed_chunks', 0)}ê°œ\n"
            vector_analysis += f"â€¢ ë²¡í„° ì°¨ì›: {vector_info.get('dimensions', 384)}\n"
            vector_analysis += f"â€¢ ìœ ì‚¬ë„ ì„ê³„ê°’: {vector_info.get('threshold_applied', 0.1)}\n\n"
            
            similarity_dist = detailed_analysis.get("similarity_distribution", {})
            vector_analysis += f"**ìœ ì‚¬ë„ ë¶„í¬:**\n"
            vector_analysis += f"â€¢ ê³ ìœ ì‚¬ë„ (>0.7): {similarity_dist.get('exact_matches', 0)}ê°œ\n"
            vector_analysis += f"â€¢ ì¤‘ìœ ì‚¬ë„ (0.3-0.7): {similarity_dist.get('similarity_matches', 0)}ê°œ\n"
            vector_analysis += f"â€¢ ì €ìœ ì‚¬ë„ (<0.3): {similarity_dist.get('contextual_matches', 0)}ê°œ\n"
            
            # === 5ë‹¨ê³„: RAG ë‹µë³€ ìƒì„± ===
            if documents:
                rag_result = await self.rag_service.generate_rag_answer(
                    question=query.strip(),
                    context_hint=None,
                    metadata={"demo": "complete_pipeline"}
                )
                
                pipeline_log.append(f"\nğŸ¤– **5ë‹¨ê³„: RAG ë‹µë³€ ìƒì„±**")
                pipeline_log.append(f"â€¢ LLM ëª¨ë¸: MockLLM (ë°ëª¨ìš©)")
                pipeline_log.append(f"â€¢ ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸: {len(rag_result.sources)}ê°œ ë¬¸ì„œ")
                pipeline_log.append(f"â€¢ ë‹µë³€ ìƒì„± ì‹œê°„: {rag_result.processing_time_ms:.0f}ms")
                pipeline_log.append(f"â€¢ ì‹ ë¢°ë„: {rag_result.confidence:.2f}")
                
                final_answer = f"ğŸ¤– **ìµœì¢… RAG ë‹µë³€**\n\n{rag_result.answer}\n\n"
                final_answer += f"**ë©”íƒ€ ì •ë³´:**\n"
                final_answer += f"â€¢ ì²˜ë¦¬ ì‹œê°„: {rag_result.processing_time_ms:.0f}ms\n"
                final_answer += f"â€¢ ì‹ ë¢°ë„: {rag_result.confidence:.2f}\n"
                final_answer += f"â€¢ ì‚¬ìš©ëœ ì†ŒìŠ¤: {len(rag_result.sources)}ê°œ"
            else:
                pipeline_log.append(f"\nâŒ **5ë‹¨ê³„: RAG ë‹µë³€ ìƒì„± ì‹¤íŒ¨**")
                pipeline_log.append("â€¢ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                final_answer = "âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return "\n".join(pipeline_log), search_results, vector_analysis, final_answer
            
        except Exception as e:
            logger.error(f"ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸ ì‹œì—° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}", "", "", ""


def create_demo_interface() -> gr.Blocks:
    """Gradio ë°ëª¨ ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    demo_controller = RAGDemoInterface()
    
    with gr.Blocks(
        title="AI í¬íŠ¸í´ë¦¬ì˜¤ RAG ë°ëª¨",
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 1800px !important;
            margin: 0 auto !important;
        }
        .tab-nav {
            justify-content: center !important;
        }
        .contain {
            max-width: none !important;
            margin: 0 auto !important;
        }
        .card {
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 16px;
            margin: 8px 0;
            background: #f8f9fa;
        }
        .feature-card {
            border: 1px solid #007bff;
            border-radius: 8px;
            padding: 12px;
            margin: 4px;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .usage-card {
            border: 1px solid #28a745;
            border-radius: 8px;
            padding: 12px;
            margin: 4px;
            background: linear-gradient(135deg, #f8fff9 0%, #e8f5e8 100%);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .status-card {
            border: 1px solid #17a2b8;
            border-radius: 8px;
            padding: 12px;
            margin: 4px;
            background: linear-gradient(135deg, #f8f9ff 0%, #e8f0ff 100%);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        """
    ) as demo:
        
        gr.Markdown("""
        # ğŸš€ AI í¬íŠ¸í´ë¦¬ì˜¤ RAG ë°ëª¨
        """)
        
        with gr.Row():
            # ì™¼ìª½: ì‚¬ìš© ë°©ë²• ì¹´ë“œ
            with gr.Column(scale=1):
                gr.Markdown("""
                <div class="usage-card" style="border: 1px solid #28a745; border-radius: 8px; padding: 12px; margin: 4px; background: linear-gradient(135deg, #f8fff9 0%, #e8f5e8 100%); box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <h3>ğŸ¯ ì‚¬ìš© ë°©ë²•</h3>
                    <ol style="margin: 8px 0; padding-left: 20px;">
                        <li><strong>ğŸ“š ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ</strong>ë¥¼ í†µí•´ AI í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”</li>
                        <li><strong>ğŸ“„ ë¬¸ì„œ ì¶”ê°€</strong>ë¥¼ í†µí•´ ì¶”ê°€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”</li>
                        <li><strong>ğŸ” ë¬¸ì„œ ê²€ìƒ‰</strong>ì„ í†µí•´ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ìœ¼ì„¸ìš” (ìƒ˜í”Œ ì¿¼ë¦¬ ì œê³µ)</li>
                        <li><strong>ğŸ¤– ì§ˆë¬¸í•˜ê¸°</strong>ë¥¼ í†µí•´ AI ìƒì„± ë‹µë³€ì„ ë°›ìœ¼ì„¸ìš”</li>
                        <li><strong>ğŸ”¬ ë¬¸ì„œ ë¶„ì„</strong>ì„ í†µí•´ ìƒì„¸ ì²˜ë¦¬ ë‹¨ê³„ë¥¼ í™•ì¸í•˜ì„¸ìš”</li>
                    </ol>
                </div>
                """)
            
            # ì˜¤ë¥¸ìª½: ì‹œìŠ¤í…œ ì •ë³´ ì¹´ë“œ (ë™ì  ì—…ë°ì´íŠ¸)
            with gr.Column(scale=1):
                system_status_html = gr.HTML(
                    value="""
                    <div class="status-card" style="border: 1px solid #17a2b8; border-radius: 8px; padding: 12px; margin: 4px; background: linear-gradient(135deg, #f8f9ff 0%, #e8f0ff 100%); box-shadow: 0 2px 4px rgba(0,0,0,0.1); min-width: 300px; width: 100%;">
                        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 8px;">
                            <h3 style="margin: 0;">ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´</h3>
                            <span style="font-size: 16px;" title="ìƒˆë¡œê³ ì¹¨">ğŸ”„</span>
                        </div>
                        <div style="font-size: 14px; line-height: 1.4;">
                            <div style="margin-bottom: 8px;">
                                <strong>ğŸ“„ ë¬¸ì„œ ê´€ë¦¬:</strong><br>
                                â€¢ ì €ì¥ëœ ë¬¸ì„œ: <strong>ë¡œë”© ì¤‘...</strong><br>
                                â€¢ ë²¡í„° ì„ë² ë”©: <strong>ë¡œë”© ì¤‘...</strong>
                            </div>
                            
                            <div style="margin-bottom: 8px;">
                                <strong>ğŸ¤– LLM ì„œë¹„ìŠ¤:</strong><br>
                                <strong>ë¡œë”© ì¤‘...</strong>
                            </div>
                            
                            <div style="margin-bottom: 8px;">
                                <strong>ğŸ” ë²¡í„° ìŠ¤í† ì–´:</strong><br>
                                <strong>ë¡œë”© ì¤‘...</strong>
                            </div>
                            
                            <div style="margin-bottom: 8px;">
                                <strong>ğŸ”¤ ì„ë² ë”© ì„œë¹„ìŠ¤:</strong><br>
                                <strong>ë¡œë”© ì¤‘...</strong>
                            </div>
                        </div>
                    </div>
                    """,
                    label="ì‹œìŠ¤í…œ ìƒíƒœ"
                )
                
                # ì‹œìŠ¤í…œ ìƒíƒœ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
                refresh_status_btn = gr.Button("ğŸ”„ ì‹œìŠ¤í…œ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", variant="secondary", size="sm")
        
        with gr.Tab("ğŸ“„ ë¬¸ì„œ ê´€ë¦¬"):
            with gr.Row():
                # ì™¼ìª½ ì—´: ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸš€ ë¹ ë¥¸ ì‹œì‘: ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ")
                    load_sample_btn = gr.Button("ğŸ“š AI í¬íŠ¸í´ë¦¬ì˜¤ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ", variant="primary", size="lg")
                    sample_status = gr.Textbox(
                        label="ìƒ˜í”Œ ë°ì´í„° ìƒíƒœ",
                        lines=8,
                        interactive=False,
                        placeholder="ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ë©´ AI í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ë¬¸ì„œê°€ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤..."
                    )
                
                # ì¤‘ì•™ ì—´: ìˆ˜ë™ ë¬¸ì„œ ì¶”ê°€
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“ ìˆ˜ë™ ë¬¸ì„œ ì¶”ê°€")
                    doc_input = gr.Textbox(
                        label="ë¬¸ì„œ ë‚´ìš©",
                        placeholder="ì—¬ê¸°ì— ë¬¸ì„œ ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
                        lines=8
                    )
                    source_input = gr.Textbox(
                        label="ì¶œì²˜ ì´ë¦„ (ì„ íƒ ì‚¬í•­)",
                        placeholder="ì˜ˆ: research_paper.pdf",
                        value="manual_input"
                    )
                    add_btn = gr.Button("â• ë¬¸ì„œ ì¶”ê°€", variant="primary")
                    add_output = gr.Textbox(
                        label="ìƒíƒœ",
                        lines=3,
                        interactive=False
                    )
                    clear_btn = gr.Button("ğŸ—‘ï¸ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ", variant="secondary")
                    clear_output = gr.Textbox(
                        label="ìƒíƒœ ì´ˆê¸°í™”",
                        lines=2,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ë¬¸ì„œ ë³´ê¸° (ì „ì²´ ë†’ì´)
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“š ì €ì¥ëœ ë¬¸ì„œ ë³´ê¸°")
                    view_docs_btn = gr.Button("ğŸ“š ì „ì²´ ë¬¸ì„œ ë³´ê¸°", variant="primary")
                    documents_output = gr.Textbox(
                        label="ì €ì¥ëœ ë¬¸ì„œ",
                        lines=25,
                        interactive=False,
                        max_lines=30
                    )

        with gr.Tab("ğŸ”¬ ë¬¸ì„œ ë¶„ì„"):
            with gr.Row():
                # ì™¼ìª½ ì—´: ë¬¸ì„œ ì…ë ¥
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“„ ë¶„ì„í•  ë¬¸ì„œ")
                    doc_input_analysis = gr.Textbox(
                        label="ë¶„ì„í•  ë¬¸ì„œ ë‚´ìš©",
                        placeholder="ìƒì„¸ ë¶„ì„ì„ ìœ„í•´ ì—¬ê¸°ì— ë¬¸ì„œ ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
                        lines=12
                    )
                    source_input_analysis = gr.Textbox(
                        label="ì¶œì²˜ ì´ë¦„ (ì„ íƒ ì‚¬í•­)",
                        placeholder="ì˜ˆ: research_paper.pdf",
                        value="manual_input"
                    )
                    add_analysis_btn = gr.Button("ğŸ”¬ ì¶”ê°€ ë° ë¶„ì„", variant="primary")
                
                # ì¤‘ì•™ ì—´: ê¸°ë³¸ ê²°ê³¼
                with gr.Column(scale=1):
                    gr.Markdown("### âœ… ê¸°ë³¸ ê²°ê³¼")
                    basic_result = gr.Textbox(
                        label="ê¸°ë³¸ ê²°ê³¼",
                        lines=6,
                        interactive=False
                    )
                    gr.Markdown("### â±ï¸ ì²˜ë¦¬ ë¶„ì„")
                    processing_info = gr.Textbox(
                        label="ì²˜ë¦¬ ë¶„ì„",
                        lines=8,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ë²¡í„° ë¶„ì„
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ”¢ ë²¡í„° ë¶„ì„")
                    vector_info = gr.Textbox(
                        label="ë²¡í„° ë¶„ì„",
                        lines=20,
                        interactive=False
                    )
        
        with gr.Tab("ğŸ”„ ë¦¬íŠ¸ë¦¬ë²„ ê³¼ì • ì‹œì—°"):
            with gr.Row():
                # ì™¼ìª½ ì—´: ì¿¼ë¦¬ ì…ë ¥
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ” ë¦¬íŠ¸ë¦¬ë²„ ê³¼ì • ì‹œì—°")
                    gr.Markdown("**ì‹¤ì œ ë¦¬íŠ¸ë¦¬ë²„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤:**")
                    gr.Markdown("â€¢ 1ë‹¨ê³„: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±")
                    gr.Markdown("â€¢ 2ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)")
                    gr.Markdown("â€¢ 3ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„")
                    
                    retriever_query = gr.Textbox(
                        label="ê²€ìƒ‰í•  ì¿¼ë¦¬",
                        placeholder="ì˜ˆ: í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                        lines=3
                    )
                    retriever_btn = gr.Button("ğŸ”„ ë¦¬íŠ¸ë¦¬ë²„ ê³¼ì • ì‹œì—°", variant="primary")
                
                # ì¤‘ì•™ ì—´: 1ë‹¨ê³„ + 2ë‹¨ê³„
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“Š ì²˜ë¦¬ ê³¼ì •")
                    step1_output = gr.Textbox(
                        label="1ë‹¨ê³„: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±",
                        lines=6,
                        interactive=False
                    )
                    step2_output = gr.Textbox(
                        label="2ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ + ê²°ê³¼",
                        lines=12,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ìƒì„¸ ë¶„ì„
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ”¬ ìƒì„¸ ë¶„ì„")
                    analysis_output = gr.Textbox(
                        label="ìƒì„¸ ë¶„ì„ ì •ë³´",
                        lines=20,
                        interactive=False
                    )

        with gr.Tab("ğŸ” ë¬¸ì„œ ê²€ìƒ‰"):
            with gr.Row():
                # ì™¼ìª½ ì—´: ê²€ìƒ‰ ì…ë ¥
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ’¡ ìƒ˜í”Œ ê²€ìƒ‰ ì¿¼ë¦¬")
                    sample_query_dropdown = gr.Dropdown(
                        choices=demo_controller.get_sample_queries(),
                        label="ë¯¸ë¦¬ ì •ì˜ëœ ì§ˆë¬¸ë“¤",
                        value="",
                        interactive=True
                    )
                    use_sample_btn = gr.Button("ğŸ” ì„ íƒí•œ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰", variant="secondary")
                    
                    gr.Markdown("---")
                    gr.Markdown("### ğŸ” ì§ì ‘ ê²€ìƒ‰")
                    search_input = gr.Textbox(
                        label="ê²€ìƒ‰ì–´",
                        placeholder="ì˜ˆ: í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜, RAG ì‹œìŠ¤í…œ, Docker ìµœì í™”, CI/CD íŒŒì´í”„ë¼ì¸, ì„±ëŠ¥ ìµœì í™”, ë¬¸ì œ í•´ê²°...",
                        lines=4
                    )
                    top_k = gr.Slider(
                        label="ê²°ê³¼ ìˆ˜",
                        minimum=1,
                        maximum=10,
                        value=3,
                        step=1
                    )
                    search_btn = gr.Button("ğŸ” ê²€ìƒ‰", variant="primary")
                
                # ì¤‘ì•™ ì—´: ê²€ìƒ‰ ê²°ê³¼
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼")
                    search_output = gr.Textbox(
                        label="ê²€ìƒ‰ ê²°ê³¼",
                        lines=20,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ì„ë² ë”© ë¶„ì„
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ”¬ ì„ë² ë”© ë¶„ì„")
                    embedding_analysis_btn = gr.Button("ğŸ”¬ ì„ë² ë”© ë¶„ì„", variant="secondary")
                    embedding_output = gr.Textbox(
                        label="ì„ë² ë”© ë¶„ì„",
                        lines=25,
                        interactive=False
                    )

        with gr.Tab("ğŸ”¬ ê²€ìƒ‰ ë¶„ì„"):
            with gr.Row():
                # ì™¼ìª½ ì—´: ê²€ìƒ‰ ì…ë ¥
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ” ë¶„ì„í•  ê²€ìƒ‰")
                    search_input_analysis = gr.Textbox(
                        label="ë¶„ì„í•  ê²€ìƒ‰ì–´",
                        placeholder="ìƒì„¸ ë¶„ì„ì„ ìœ„í•´ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                        lines=4
                    )
                    top_k_analysis = gr.Slider(
                        label="ê²°ê³¼ ìˆ˜",
                        minimum=1,
                        maximum=10,
                        value=3,
                        step=1
                    )
                    search_analysis_btn = gr.Button("ğŸ”¬ ê²€ìƒ‰ ë° ë¶„ì„", variant="primary")
                
                # ì¤‘ì•™ ì—´: ê²€ìƒ‰ ê²°ê³¼
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼")
                    search_results_analysis = gr.Textbox(
                        label="ê²€ìƒ‰ ê²°ê³¼",
                        lines=12,
                        interactive=False
                    )
                    gr.Markdown("### â±ï¸ ì²˜ë¦¬ ë¶„ì„")
                    search_processing_info = gr.Textbox(
                        label="ì²˜ë¦¬ ë¶„ì„",
                        lines=10,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ë²¡í„° ë¶„ì„
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ”¢ ë²¡í„° ë¶„ì„")
                    search_vector_info = gr.Textbox(
                        label="ë²¡í„° ë¶„ì„",
                        lines=20,
                        interactive=False
                    )
        
        with gr.Tab("ğŸ¤– RAG Q&A"):
            with gr.Row():
                # ì™¼ìª½ ì—´: ì§ˆë¬¸ ì…ë ¥
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")
                    question_input = gr.Textbox(
                        label="ì§ˆë¬¸",
                        placeholder="ì˜ˆ: í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”? RAG ì‹œìŠ¤í…œì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”? Docker ìµœì í™” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”...",
                        lines=6
                    )
                    max_sources = gr.Slider(
                        label="ì‚¬ìš©í•  ìµœëŒ€ ì¶œì²˜ ìˆ˜",
                        minimum=1,
                        maximum=5,
                        value=3,
                        step=1
                    )
                    answer_btn = gr.Button("ğŸ’¬ ë‹µë³€ ìƒì„±", variant="primary")
                
                # ì¤‘ì•™ ì—´: AI ë‹µë³€
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ¤– AI ë‹µë³€")
                    answer_output = gr.Textbox(
                        label="AI ë‹µë³€",
                        lines=20,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ì¶œì²˜ ë¬¸ì„œ
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“š ì¶œì²˜ ë¬¸ì„œ")
                    sources_output = gr.Textbox(
                        label="ì¶œì²˜ ë¬¸ì„œ",
                        lines=25,
                        interactive=False
                    )

        with gr.Tab("ğŸ”„ RAG íŒŒì´í”„ë¼ì¸"):
            with gr.Row():
                gr.Markdown("""
                ## ğŸ¯ ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸ ì‹œì—°
                **ë¬¸ì„œ ë¡œë”© â†’ ì²­í‚¹ â†’ ë²¡í„°í™” â†’ ì €ì¥ â†’ ê²€ìƒ‰ â†’ ë‹µë³€ìƒì„±**ì˜ ì „ì²´ ê³¼ì •ì„ í•œ ë²ˆì— ë³´ì—¬ì¤ë‹ˆë‹¤.
                """)
            
            with gr.Row():
                # ì™¼ìª½ ì—´: ì…ë ¥
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“ ì…ë ¥ ë°ì´í„°")
                    pipeline_document = gr.Textbox(
                        label="ë¶„ì„í•  ë¬¸ì„œ",
                        placeholder="RAG íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬í•  ë¬¸ì„œë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                        lines=10
                    )
                    pipeline_query = gr.Textbox(
                        label="ê²€ìƒ‰ ì¿¼ë¦¬",
                        placeholder="ë¬¸ì„œì—ì„œ ì°¾ê³ ì í•˜ëŠ” ë‚´ìš©ì„ ì§ˆë¬¸í•˜ì„¸ìš”...",
                        lines=3
                    )
                    pipeline_btn = gr.Button("ğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", variant="primary")
                
                # ì¤‘ì•™ ì—´: íŒŒì´í”„ë¼ì¸ ê³¼ì •
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ”„ ì²˜ë¦¬ ê³¼ì •")
                    pipeline_process = gr.Textbox(
                        label="íŒŒì´í”„ë¼ì¸ ë¡œê·¸",
                        lines=25,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ê²€ìƒ‰ ê²°ê³¼
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ” ê²€ìƒ‰ ê²°ê³¼")
                    pipeline_search_result = gr.Textbox(
                        label="ê²€ìƒ‰ëœ ë¬¸ì„œ",
                        lines=12,
                        interactive=False
                    )
                    gr.Markdown("### ğŸ”¢ ë²¡í„° ë¶„ì„")
                    pipeline_vector_analysis = gr.Textbox(
                        label="ë²¡í„° ë¶„ì„ ê²°ê³¼",
                        lines=10,
                        interactive=False
                    )
            
            with gr.Row():
                # í•˜ë‹¨: ìµœì¢… RAG ë‹µë³€
                with gr.Column():
                    gr.Markdown("### ğŸ¤– ìµœì¢… RAG ë‹µë³€")
                    pipeline_final_answer = gr.Textbox(
                        label="ìƒì„±ëœ ë‹µë³€",
                        lines=8,
                        interactive=False
                    )

        with gr.Tab("ğŸ“Š ë°ì´í„° í™•ì¸"):
            with gr.Row():
                # ì™¼ìª½ ì—´: ë©”ëª¨ë¦¬ ë‚´ìš© í™•ì¸
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ’¾ ë©”ëª¨ë¦¬ ë‚´ìš© í™•ì¸")
                    memory_content_btn = gr.Button("ğŸ’¾ ë©”ëª¨ë¦¬ ë‚´ìš© ë³´ê¸°", variant="primary")
                    memory_content_output = gr.Textbox(
                        label="ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ë‚´ìš©",
                        lines=20,
                        interactive=False
                    )
                
                # ì¤‘ì•™ ì—´: ì²­í¬ ë‚´ìš© í™•ì¸
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“„ ì²­í¬ ë‚´ìš© í™•ì¸")
                    chunk_content_btn = gr.Button("ğŸ“„ ì²­í¬ ë‚´ìš© ë³´ê¸°", variant="primary")
                    chunk_content_output = gr.Textbox(
                        label="ì²­í¬ ë‚´ìš©",
                        lines=20,
                        interactive=False
                    )
                
                # ì˜¤ë¥¸ìª½ ì—´: ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš© í™•ì¸
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ” ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš© í™•ì¸")
                    vector_content_btn = gr.Button("ğŸ” ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš© ë³´ê¸°", variant="primary")
                    vector_content_output = gr.Textbox(
                        label="ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš©",
                        lines=20,
                        interactive=False
                    )
        
        # Async wrapper functions for Gradio compatibility
        def sync_add_document(content, source):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.add_document(content, source)
            return asyncio.run(run())
        
        def sync_add_document_with_analysis(content, source):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.add_document_with_analysis(content, source)
            return asyncio.run(run())
        
        def sync_clear_knowledge_base():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.clear_knowledge_base()
            return asyncio.run(run())
        
        def sync_search_documents(query, top_k):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.search_documents(query, top_k)
            return asyncio.run(run())
        
        def sync_search_documents_with_analysis(query, top_k):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.search_documents_with_analysis(query, top_k)
            return asyncio.run(run())
        
        def sync_generate_answer(question, max_sources):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.generate_answer(question, max_sources)
            return asyncio.run(run())
        
        def sync_get_status():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_status()
            return asyncio.run(run())

        def sync_view_all_documents():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.view_all_documents()
            return asyncio.run(run())

        def sync_get_embedding_analysis():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_embedding_analysis()
            return asyncio.run(run())

        def sync_get_memory_info():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_memory_info()
            return asyncio.run(run())

        def sync_get_chunk_analysis():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_chunk_analysis()
            return asyncio.run(run())

        def sync_get_vector_store_detailed_info():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_vector_store_detailed_info()
            return asyncio.run(run())

        def sync_demonstrate_retriever_process(query):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.demonstrate_retriever_process(query)
            return asyncio.run(run())

        def sync_get_memory_content():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_memory_content()
            return asyncio.run(run())

        def sync_get_chunk_content():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_chunk_content()
            return asyncio.run(run())

        def sync_get_vector_store_content():
            async def run():
                await demo_controller.initialize()
                return await demo_controller.get_vector_store_content()
            return asyncio.run(run())
        
        def sync_demonstrate_complete_rag_pipeline(document, query):
            async def run():
                await demo_controller.initialize()
                return await demo_controller.demonstrate_complete_rag_pipeline(document, query)
            return asyncio.run(run())

        def format_system_status_html(status_text):
            """ì‹œìŠ¤í…œ ìƒíƒœ í…ìŠ¤íŠ¸ë¥¼ HTMLë¡œ í¬ë§·íŒ…"""
            if not status_text or "âŒ" in status_text:
                return """<div style="font-size: 14px; line-height: 1.4; color: #dc3545; min-width: 300px; width: 100%;">
                    <div style="margin-bottom: 8px;">
                        <strong>ğŸ“„ ë¬¸ì„œ ê´€ë¦¬:</strong><br>
                        â€¢ ì €ì¥ëœ ë¬¸ì„œ: <strong>âŒ ì˜¤ë¥˜</strong><br>
                        â€¢ ë²¡í„° ì„ë² ë”©: <strong>âŒ ì˜¤ë¥˜</strong>
                    </div>
                    
                    <div style="margin-bottom: 8px;">
                        <strong>ğŸ¤– LLM ì„œë¹„ìŠ¤:</strong><br>
                        <strong>âŒ ì¤€ë¹„ì•ˆë¨</strong>
                    </div>
                    
                    <div style="margin-bottom: 8px;">
                        <strong>ğŸ” ë²¡í„° ìŠ¤í† ì–´:</strong><br>
                        <strong>âŒ ì¤€ë¹„ì•ˆë¨</strong>
                    </div>
                    
                    <div style="margin-bottom: 8px;">
                        <strong>ğŸ”¤ ì„ë² ë”© ì„œë¹„ìŠ¤:</strong><br>
                        <strong>âŒ ì¤€ë¹„ì•ˆë¨</strong>
                    </div>
                </div>"""
            
            # ìƒíƒœ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ (ì‹¤ì œ ì¶œë ¥ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
            lines = status_text.split('\n')
            doc_count = "0"
            vector_count = "0"
            llm_model = "MockLLM"
            llm_type = "Mock"
            llm_status = "âŒ ì¤€ë¹„ì•ˆë¨"
            vector_store = "MemoryVector"
            stored_vectors = "0"
            vector_status = "âŒ ì¤€ë¹„ì•ˆë¨"
            embedding_model = "sentence-transformers/all-MiniLM-L6-v2"
            dimensions = "384"
            embedding_status = "âŒ ì¤€ë¹„ì•ˆë¨"
            
            # ì‹¤ì œ ì¶œë ¥ êµ¬ì¡°ì— ë§ê²Œ íŒŒì‹±
            for line in lines:
                line = line.strip()
                if "ì €ì¥ëœ ë¬¸ì„œ:" in line:
                    doc_count = line.split(":")[-1].strip().replace("ê°œ", "")
                elif "ë²¡í„° ì„ë² ë”©:" in line:
                    vector_count = line.split(":")[-1].strip().replace("ê°œ", "")
                elif "ìŠ¤í† ì–´:" in line:
                    vector_store = line.split(":")[-1].strip()
                elif "ì €ì¥ëœ ë²¡í„°:" in line:
                    stored_vectors = line.split(":")[-1].strip().replace("ê°œ", "")
                elif "ëª¨ë¸:" in line and "sentence-transformers" in line:
                    embedding_model = line.split(":")[-1].strip()
                elif "ì°¨ì›:" in line:
                    dimensions = line.split(":")[-1].strip()
                elif "ìƒíƒœ:" in line and "âœ…" in line:
                    # í˜„ì¬ ì„¹ì…˜ì„ ì¶”ì •í•˜ì—¬ ìƒíƒœ ì„¤ì •
                    if "LLM" in status_text and "MockLLM" in status_text:
                        llm_status = "âœ… ì¤€ë¹„ë¨"
                    if "MemoryVector" in line or "ìŠ¤í† ì–´" in line:
                        vector_status = "âœ… ì¤€ë¹„ë¨"
                    if "sentence-transformers" in line or "ì°¨ì›" in line:
                        embedding_status = "âœ… ì¤€ë¹„ë¨"
            
            # ê¸°ë³¸ê°’ ì„¤ì • (ì‹¤ì œ ìƒíƒœì—ì„œ ì •ë³´ê°€ ì—†ì„ ê²½ìš°)
            if "âœ… ì¤€ë¹„ë¨" in status_text:
                llm_status = "âœ… ì¤€ë¹„ë¨"
                vector_status = "âœ… ì¤€ë¹„ë¨"
                embedding_status = "âœ… ì¤€ë¹„ë¨"
            
            return f"""<div style="font-size: 14px; line-height: 1.4; min-width: 300px; width: 100%;">
                <div style="margin-bottom: 8px;">
                    <strong>ğŸ“„ ë¬¸ì„œ ê´€ë¦¬:</strong><br>
                    â€¢ ì €ì¥ëœ ë¬¸ì„œ: <strong>{doc_count}ê°œ</strong><br>
                    â€¢ ë²¡í„° ì„ë² ë”©: <strong>{vector_count}ê°œ</strong>
                </div>
                
                <div style="margin-bottom: 8px;">
                    <strong>ğŸ¤– LLM ì„œë¹„ìŠ¤:</strong><br>
                    <strong>{llm_model}({llm_type})</strong> - <strong>{llm_status}</strong>
                </div>
                
                <div style="margin-bottom: 8px;">
                    <strong>ğŸ” ë²¡í„° ìŠ¤í† ì–´:</strong><br>
                    <strong>{vector_store}</strong> - <strong>{stored_vectors}ê°œ ë²¡í„°</strong> - <strong>{vector_status}</strong>
                </div>
                
                <div style="margin-bottom: 8px;">
                    <strong>ğŸ”¤ ì„ë² ë”© ì„œë¹„ìŠ¤:</strong><br>
                    <strong>{embedding_model}</strong> - <strong>{dimensions}ì°¨ì›</strong> - <strong>{embedding_status}</strong>
                </div>
            </div>"""

        # Event handlers
        load_sample_btn.click(
            fn=lambda: demo_controller.load_sample_data(),
            outputs=sample_status
        )
        
        use_sample_btn.click(
            fn=lambda query: query if query else "ê²€ìƒ‰ì–´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”",
            inputs=sample_query_dropdown,
            outputs=search_input
        )
        
        add_btn.click(
            fn=sync_add_document,
            inputs=[doc_input, source_input],
            outputs=add_output
        )
        
        add_analysis_btn.click(
            fn=sync_add_document_with_analysis,
            inputs=[doc_input_analysis, source_input_analysis],
            outputs=[basic_result, processing_info, vector_info]
        )
        
        clear_btn.click(
            fn=sync_clear_knowledge_base,
            outputs=clear_output
        )
        
        search_btn.click(
            fn=sync_search_documents,
            inputs=[search_input, top_k],
            outputs=search_output
        )
        
        search_analysis_btn.click(
            fn=sync_search_documents_with_analysis,
            inputs=[search_input_analysis, top_k_analysis],
            outputs=[search_results_analysis, search_processing_info, search_vector_info]
        )
        
        retriever_btn.click(
            fn=sync_demonstrate_retriever_process,
            inputs=[retriever_query],
            outputs=[step1_output, step2_output, analysis_output]
        )

        answer_btn.click(
            fn=sync_generate_answer,
            inputs=[question_input, max_sources],
            outputs=[answer_output, sources_output]
        )

        view_docs_btn.click(
            fn=sync_view_all_documents,
            outputs=documents_output
        )

        # ì„ë² ë”© ë¶„ì„ ë²„íŠ¼ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        embedding_analysis_btn.click(
            fn=sync_get_embedding_analysis,
            outputs=embedding_output
        )

        # ì‹œìŠ¤í…œ ìƒíƒœ ìƒˆë¡œê³ ì¹¨ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        refresh_status_btn.click(
            fn=lambda: format_system_status_html(sync_get_status()),
            outputs=system_status_html
        )

        # ë°ì´í„° í™•ì¸ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        memory_content_btn.click(
            fn=sync_get_memory_content,
            outputs=memory_content_output
        )

        chunk_content_btn.click(
            fn=sync_get_chunk_content,
            outputs=chunk_content_output
        )

        vector_content_btn.click(
            fn=sync_get_vector_store_content,
            outputs=vector_content_output
        )

        # RAG íŒŒì´í”„ë¼ì¸ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        pipeline_btn.click(
            fn=sync_demonstrate_complete_rag_pipeline,
            inputs=[pipeline_document, pipeline_query],
            outputs=[pipeline_process, pipeline_search_result, pipeline_vector_analysis, pipeline_final_answer]
        )

        # í˜ì´ì§€ ë¡œë“œ ì‹œ ì´ˆê¸° ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸
        demo.load(
            fn=lambda: format_system_status_html(sync_get_status()),
            outputs=system_status_html
        )
    
    return demo


if __name__ == "__main__":
    logger.info("ğŸš€ Starting Hexagonal RAG Demo...")
    
    try:
        demo = create_demo_interface()
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            show_error=True
        )
    except Exception as e:
        logger.error(f"âŒ Failed to start demo: {e}")
        raise
