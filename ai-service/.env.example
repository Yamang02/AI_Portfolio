# ==============================================
# AI 서비스 환경변수 설정 예시
# ==============================================
# 사용법: 이 파일을 .env로 복사한 후 실제 값으로 변경하세요
# cp .env.example .env

# ==============================================
# API 키 설정
# ==============================================
# Google Gemini API 키 (필수)
# https://makersuite.google.com/app/apikey 에서 발급
GEMINI_API_KEY=your_gemini_api_key_here

# ==============================================
# LLM 모델 설정
# ==============================================
# 사용할 Gemini 모델명
GEMINI_MODEL=gemini-1.5-flash
# 대안: gemini-1.5-pro, gemini-1.0-pro

# LLM 생성 파라미터
LLM_TEMPERATURE=0.7
LLM_MAX_OUTPUT_TOKENS=2048
LLM_TOP_P=0.9
LLM_TOP_K=40

# ==============================================
# 벡터 데이터베이스 설정 (Qdrant)
# ==============================================
# Qdrant 서버 호스트
QDRANT_HOST=localhost
# Docker Compose 사용시: qdrant

# Qdrant 서버 포트
QDRANT_PORT=6333

# Qdrant Cloud 사용시 (선택사항)
# QDRANT_API_KEY=your_qdrant_cloud_api_key
# QDRANT_URL=https://your-cluster.qdrant.io

# ==============================================
# 임베딩 모델 설정
# ==============================================
# 사용할 임베딩 모델명
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# 대안: 
# - sentence-transformers/all-MiniLM-L6-v2 (영어 전용, 빠름)
# - sentence-transformers/all-mpnet-base-v2 (영어 전용, 고품질)

# 임베딩 모델 실행 디바이스
EMBEDDING_DEVICE=auto
# 옵션: auto, cpu, cuda

# 임베딩 배치 크기
EMBEDDING_BATCH_SIZE=32

# 최대 시퀀스 길이
EMBEDDING_MAX_SEQ_LENGTH=512

# ==============================================
# RAG 시스템 설정
# ==============================================
# 검색시 최대 결과 수
RAG_MAX_SEARCH_RESULTS=5

# 최소 유사도 점수 (0.0-1.0)
RAG_MIN_SIMILARITY_SCORE=0.7

# 최대 컨텍스트 길이 (토큰)
RAG_MAX_CONTEXT_LENGTH=4000

# 컨텍스트 오버랩
RAG_CONTEXT_OVERLAP=100

# ==============================================
# 캐시 시스템 설정 (Redis) - 향후 구현
# ==============================================
# Redis 서버 호스트
REDIS_HOST=localhost
# Docker Compose 사용시: redis

# Redis 서버 포트
REDIS_PORT=6379

# Redis 비밀번호 (선택사항)
# REDIS_PASSWORD=your_redis_password

# 캐시 TTL (초)
CACHE_TTL=3600

# ==============================================
# 로깅 및 모니터링
# ==============================================
# 로그 레벨 (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# 로그 포맷
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# LangSmith 추적 (선택사항)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
# LANGCHAIN_API_KEY=your_langsmith_api_key
# LANGCHAIN_PROJECT=ai-portfolio-chatbot

# ==============================================
# 서버 설정
# ==============================================
# FastAPI 서버 호스트
SERVER_HOST=0.0.0.0

# FastAPI 서버 포트
SERVER_PORT=8000

# 개발 모드 (auto-reload)
DEBUG_MODE=false

# CORS 허용 도메인 (쉼표로 구분)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8080

# ==============================================
# 데이터베이스 설정 (PostgreSQL) - 기존 백엔드와 공유
# ==============================================
# PostgreSQL 연결 정보 (데이터 동기화용)
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=ai_portfolio
# DB_USER=postgres
# DB_PASSWORD=your_db_password

# ==============================================
# 성능 최적화 설정
# ==============================================
# 동시 요청 처리 수
MAX_CONCURRENT_REQUESTS=10

# 요청 타임아웃 (초)
REQUEST_TIMEOUT=30

# 벡터 검색 타임아웃 (초)
VECTOR_SEARCH_TIMEOUT=5

# LLM 응답 타임아웃 (초)
LLM_RESPONSE_TIMEOUT=15