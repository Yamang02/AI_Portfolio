# AI Portfolio 설정 파일 (테스트용)
# 실제 운영시에는 .env 파일의 환경변수를 사용하세요

llm:
  openai:
    model_name: "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 1000
  
  google:
    model_name: "gemini-pro"
    temperature: 0.7
    max_output_tokens: 1000

database:
  host: "localhost"
  port: 5432
  database: "ai_portfolio"
  username: "postgres"
  password: "test_password"

cache:
  host: "localhost"
  port: 6379
  password: ""
  database: 0

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

langchain:
  korean:
    text_splitter:
      chunk_size: 500
      chunk_overlap: 75
      separators: ["\n\n", "\n", ". ", "! ", "? ", " ", ""]
  
  rag:
    chunk_size: 500
    chunk_overlap: 75
    top_k: 5
    similarity_threshold: 0.7

# 어댑터 설정
adapters:
  # 임베딩 어댑터 설정
  embedding:
    provider: "openai"
    model_name: "text-embedding-3-small"
    batch_size: 20
    api_key: null  # 환경변수 OPENAI_API_KEY 사용
  
  # 벡터 저장소 어댑터 설정
  vector:
    memory:
      model_name: "all-MiniLM-L6-v2"
    
  # 데이터베이스 어댑터 설정
  database:
    postgresql:
      pool_size: 10
      max_overflow: 20
      
  # 통합 LLM 어댑터 설정
  llm:
    unified:
      default_provider: "openai"
      default_model: "gpt-3.5-turbo"
      default_temperature: 0.7
      default_max_tokens: 1000

# 성능 및 모니터링 설정
performance:
  # Mock LLM 설정 (테스트용)
  mock_llm:
    response_delay: 0.5
    
  # 메트릭 수집 설정
  metrics:
    collection_interval: 60
    
  # 헬스체크 설정
  health_check:
    interval: 30
    timeout: 5