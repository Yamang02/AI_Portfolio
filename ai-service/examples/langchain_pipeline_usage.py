"""
LangChain íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì˜ˆì‹œ
LangChain íŒŒì´í”„ ì—°ì‚°ìì˜ ì§„ì •í•œ ì¥ì ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œ
"""

import asyncio
from src.adapters.inbound.web.langchain_dependencies import (
    get_langchain_integrated_rag_pipeline,
    get_langchain_document_processing_pipeline
)


async def demonstrate_rag_pipeline():
    """RAG íŒŒì´í”„ë¼ì¸ ë°ëª¨"""
    print("=== LangChain í†µí•© RAG íŒŒì´í”„ë¼ì¸ ë°ëª¨ ===")
    
    # íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
    rag_pipeline = get_langchain_integrated_rag_pipeline()
    
    # ì‚¬ìš©ì ì§ˆë¬¸ë“¤
    questions = [
        "ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ê°œë°œí–ˆë‚˜ìš”?",
        "Pythonê³¼ JavaScript ì¤‘ ì–´ëŠ ê²ƒì„ ë” ì˜ ì‚¬ìš©í•˜ë‚˜ìš”?",
        "ì—…ë¬´ ê²½í—˜ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
        "í¬íŠ¸í´ë¦¬ì˜¤ì— ëŒ€í•´ ê°„ë‹¨íˆ ì†Œê°œí•´ì£¼ì„¸ìš”"
    ]
    
    for question in questions:
        print(f"\nì§ˆë¬¸: {question}")
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (LangChain íŒŒì´í”„ ì—°ì‚°ìë¡œ ëª¨ë“  ë‹¨ê³„ê°€ ì—°ê²°ë¨)
        result = await rag_pipeline.process_message(question)
        
        print(f"ë‹µë³€: {result['response']}")
        print(f"ì‹ ë¢°ë„: {result['confidence']}")
        print(f"ì†ŒìŠ¤ ìˆ˜: {result['sources_count']}")
        print(f"ì¿¼ë¦¬ ë¶„ì„: {result['metadata']['query_analysis']}")


async def demonstrate_document_processing_pipeline():
    """ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë°ëª¨"""
    print("\n=== LangChain ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë°ëª¨ ===")
    
    # íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
    doc_pipeline = get_langchain_document_processing_pipeline()
    
    # ë¬¸ì„œ ì²˜ë¦¬
    result = await doc_pipeline.process_document(
        file_path="path/to/document.pdf",
        source="portfolio_docs",
        metadata={"category": "project", "language": "korean"}
    )
    
    print(f"ì²˜ë¦¬ ê²°ê³¼: {result['success']}")
    print(f"ë¬¸ì„œ ìˆ˜: {result['documents_loaded']}")
    print(f"ì²­í¬ ìˆ˜: {result['chunks_created']}")
    print(f"ì„ë² ë”© ìˆ˜: {result['embeddings_generated']}")


async def demonstrate_streaming():
    """ìŠ¤íŠ¸ë¦¬ë° ë°ëª¨"""
    print("\n=== ìŠ¤íŠ¸ë¦¬ë° RAG íŒŒì´í”„ë¼ì¸ ë°ëª¨ ===")
    
    rag_pipeline = get_langchain_integrated_rag_pipeline()
    
    print("ì§ˆë¬¸: AI í¬íŠ¸í´ë¦¬ì˜¤ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”")
    print("ë‹µë³€ (ìŠ¤íŠ¸ë¦¬ë°): ", end="", flush=True)
    
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
    async for chunk in rag_pipeline.process_message_streaming(
        "AI í¬íŠ¸í´ë¦¬ì˜¤ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”"
    ):
        print(chunk, end="", flush=True)
    
    print("\n")


def compare_approaches():
    """ê¸°ì¡´ ë°©ì‹ vs LangChain íŒŒì´í”„ë¼ì¸ ë°©ì‹ ë¹„êµ"""
    print("\n=== ì ‘ê·¼ ë°©ì‹ ë¹„êµ ===")
    
    print("""
    ğŸ”´ ê¸°ì¡´ ë°©ì‹ (ê°œë³„ ì–´ëŒ‘í„°):
    - ê° ê¸°ëŠ¥ì´ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„
    - ìˆ˜ë™ìœ¼ë¡œ ë‹¨ê³„ë³„ í˜¸ì¶œ í•„ìš”
    - ì—ëŸ¬ ì²˜ë¦¬ì™€ ë¡œê¹…ì´ ë¶„ì‚°ë¨
    - ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„ì´ ë³µì¡í•¨
    
    ğŸŸ¢ LangChain íŒŒì´í”„ë¼ì¸ ë°©ì‹:
    - íŒŒì´í”„ ì—°ì‚°ì(|)ë¡œ ëª¨ë“  ë‹¨ê³„ ì—°ê²°
    - ìë™ ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„
    - ë³‘ë ¬ ì²˜ë¦¬ (RunnableParallel) ë‚´ì¥
    - ìŠ¤íŠ¸ë¦¬ë° ì§€ì› ë‚´ì¥
    - ì²´ì¸ êµ¬ì„±ì´ ì„ ì–¸ì ì´ê³  ì½ê¸° ì‰¬ì›€
    """)


if __name__ == "__main__":
    # ë°ëª¨ ì‹¤í–‰
    asyncio.run(demonstrate_rag_pipeline())
    asyncio.run(demonstrate_document_processing_pipeline())
    asyncio.run(demonstrate_streaming())
    compare_approaches()
