# AI-Service ì•„í‚¤í…ì²˜ ì„¤ê³„ ëŒ€í™” (2025-08-26)

## ëŒ€í™” ìš”ì•½
ai-service ë””ë ‰í† ë¦¬ì— Document Loader, TextSplitter ëª¨ë“ˆí™”, ê²€ì¦ì, ì¤‘ì•™ì§‘ì¤‘ì‹ ì—ëŸ¬ì²˜ë¦¬ êµ¬ì¡° êµ¬í˜„ì„ ìœ„í•œ ì™„ì „ ì‹ ê·œ ì•„í‚¤í…ì²˜ ì„¤ê³„

## ì£¼ìš” ê²°ì •ì‚¬í•­

### 1. ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì„¤ê³„
- **ê¸°ì¡´**: Document Loaderì™€ TextSplitterë§Œ ê³ ë ¤
- **ìµœì¢…**: ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸ (Document â†’ Embedding â†’ Vector Store â†’ Retrieval â†’ Generation)

### 2. í™˜ê²½ ë¬´ê´€ ì½”ë“œ ì›ì¹™
- **ê²°ì •**: ëª¨ë“  í™˜ê²½ì—ì„œ ë™ì¼í•œ ì½”ë“œ ì‹¤í–‰
- **í™˜ê²½ë³€ìˆ˜**: ì™¸ë¶€ ì˜ì¡´ì„±ë§Œ (APIí‚¤, URL ë“±) - ìµœëŒ€ 8ê°œ
- **YAML ì„¤ì •**: ë‚´ë¶€ íŠœë‹ íŒŒë¼ë¯¸í„° (ë°°ì¹˜ì‚¬ì´ì¦ˆ, ì„ê³„ê°’ ë“±)
- **ê¸ˆì§€**: `if environment == "production"` ê°™ì€ í™˜ê²½ë³„ ë¶„ê¸°

### 3. ì„¤ì • ê´€ë¦¬ ì „ëµ
```bash
# í™˜ê²½ë³€ìˆ˜ (ì™¸ë¶€ ì˜ì¡´ì„±ë§Œ)
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=optional_key
REDIS_URL=redis://localhost:6379
GEMINI_API_KEY=your_gemini_key
LANGCHAIN_API_KEY=optional_langsmith_key
LOG_LEVEL=INFO
```

```yaml
# config.yaml (ë‚´ë¶€ ì„¤ì •)
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  batch_size: 32
  dimension: 384

document_processing:
  chunk_size: 1000
  chunk_overlap: 200

retrieval:
  top_k: 5
  score_threshold: 0.7
  strategy: "hybrid"

generation:
  model: "gemini-pro"
  temperature: 0.3
  max_tokens: 1000
```

### 4. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë‹¨ìˆœí™”
- **ì´ˆê¸° ê³„íš**: ë³µì¡í•œ ë²„ì „ ê´€ë¦¬, í•« ë¦¬ë¡œë“œ, ì›¹í›… ì‹œìŠ¤í…œ
- **ìµœì¢… ê²°ì •**: LangSmith + YAML í•˜ì´ë¸Œë¦¬ë“œ
  - 1ìˆœìœ„: LangSmith Hubì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
  - 2ìˆœìœ„: ë¡œì»¬ YAML íŒŒì¼ (ê¸°ì¡´ `C:\GIT\LangChain_Practice\prompt_loader.py` ì½”ë“œ í™œìš©)
  - ~~3ìˆœìœ„: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸~~ (ì œê±°)

### 5. ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
ai-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/                      # ì„¤ì •, ì—ëŸ¬ì²˜ë¦¬, DI
â”‚   â”œâ”€â”€ models/                    # Pydantic ëª¨ë¸ë“¤
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ document/              # ë¡œë”, ìŠ¤í”Œë¦¬í„°, ê²€ì¦
â”‚   â”‚   â”œâ”€â”€ embedding/             # ì„ë² ë”© + ìºì‹œ
â”‚   â”‚   â”œâ”€â”€ vectorstore/           # Qdrant ë“± ë²¡í„°DB
â”‚   â”‚   â”œâ”€â”€ retrieval/             # ê²€ìƒ‰ ì „ëµë“¤
â”‚   â”‚   â”œâ”€â”€ prompt/                # LangSmith + YAML ë¡œë”
â”‚   â”‚   â”œâ”€â”€ generation/            # LLM ì„œë¹„ìŠ¤
â”‚   â”‚   â””â”€â”€ rag/                   # RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”‚   â””â”€â”€ api/v1/                    # REST API
â”œâ”€â”€ prompts/                       # YAML í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤
â”œâ”€â”€ config.yaml                    # ë‚´ë¶€ ì„¤ì •
â””â”€â”€ .env                          # ì™¸ë¶€ ì„¤ì •
```

### 6. í•µì‹¬ ì„¤ê³„ ì›ì¹™
**âœ… ê¶Œì¥:**
- í™˜ê²½ë³€ìˆ˜ ìµœì†Œí™” (8ê°œ ì´í•˜)
- YAML ê¸°ë°˜ ë‚´ë¶€ ì„¤ì •
- í™˜ê²½ ë¬´ê´€ ì½”ë“œ
- LangSmith í™œìš©
- ë¹„ë™ê¸° ì²˜ë¦¬
- ë°°ì¹˜ ìµœì í™”

**âŒ ì§€ì–‘:**
- í™˜ê²½ë³„ ì½”ë“œ ë¶„ê¸°
- ê³¼ë„í•œ í™˜ê²½ë³€ìˆ˜
- ë³µì¡í•œ í…œí”Œë¦¿ ê´€ë¦¬
- í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸
- ë™ê¸° ì²˜ë¦¬

## êµ¬í˜„ ê³„íš
- Phase 1: ê¸°ë°˜ ì¸í”„ë¼ (ì„¤ì •, ì—ëŸ¬ì²˜ë¦¬, API)
- Phase 2: ë¬¸ì„œ ì²˜ë¦¬ (ë¡œë”, ìŠ¤í”Œë¦¬í„°, ê²€ì¦)
- Phase 3: ì„ë² ë”© + ë²¡í„°ìŠ¤í† ì–´
- Phase 4: ê²€ìƒ‰ + ìƒì„± (í”„ë¡¬í”„íŠ¸ í¬í•¨)
- Phase 5: RAG í†µí•©

## ë°°í¬ ì „ëµ
- ë™ì¼í•œ Docker ì´ë¯¸ì§€ë¥¼ ëª¨ë“  í™˜ê²½ì—ì„œ ì‚¬ìš©
- í™˜ê²½ë³„ë¡œ ë‹¤ë¥¸ .env íŒŒì¼ë§Œ ì‚¬ìš©
- config.yamlì€ ì½”ë“œì™€ í•¨ê»˜ ë°°í¬

---

## ì•„í‚¤í…ì²˜ ì„¤ê³„ ë³€ê²½ (ë°±ì—”ë“œ AI ê¸°ëŠ¥ ì™„ì „ ë¶„ë¦¬)

### ë°°ê²½
ì´ˆê¸°ì—ëŠ” Document Loaderì™€ TextSplitterë§Œ ëª¨ë“ˆí™”í•˜ë ¤ í–ˆìœ¼ë‚˜, í˜„ì¬ ë°±ì—”ë“œ ì½”ë“œ ë¶„ì„ ê²°ê³¼:
- Java ë°±ì—”ë“œì— AI ê´€ë ¨ ë¡œì§ì´ ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŒ (`ChatApplicationService`, `QuestionAnalysisService`, `ContextBuilderService` ë“±)
- ë°±ì—”ë“œì—ì„œ ì§ì ‘ Gemini API í˜¸ì¶œí•˜ëŠ” êµ¬ì¡°
- AI-ServiceëŠ” ë³„ë„ ì»¨í…Œì´ë„ˆë¡œ ì¡´ì¬í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ìƒíƒœ

### ë¬¸ì œì 
- **ê´€ì‹¬ì‚¬ í˜¼ì¬**: Java ë°±ì—”ë“œì— AI ë¡œì§ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì´ í˜¼ì¬
- **í™•ì¥ì„± ì œì•½**: RAG, ë²¡í„° ê²€ìƒ‰ ë“± AI ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€ê°€ ì–´ë ¤ì›€
- **ìœ ì§€ë³´ìˆ˜ì„±**: AI ê´€ë ¨ ë³€ê²½ ì‹œ ë°±ì—”ë“œ ì¬ë°°í¬ í•„ìš”
- **ê¸°ìˆ  ìŠ¤íƒ ë¶ˆì¼ì¹˜**: AI/MLì€ Pythonì´ ë” ì í•©í•œë° Javaë¡œ êµ¬í˜„

### ìµœì¢… ê²°ì •: ì™„ì „ ë¶„ë¦¬ ì•„í‚¤í…ì²˜

#### Before (í˜„ì¬)
```
Backend (Java)
â”œâ”€â”€ ChatApplicationService     # ì±„íŒ… ë¡œì§ 
â”œâ”€â”€ QuestionAnalysisService   # ì§ˆë¬¸ ë¶„ì„
â”œâ”€â”€ ContextBuilderService     # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± 
â”œâ”€â”€ AIService                 # AI í˜¸ì¶œ
â””â”€â”€ GeminiApiClient          # LLM ì§ì ‘ í˜¸ì¶œ
```

#### After (ëª©í‘œ)
```
Backend (Java)                     AI-Service (Python)
â”œâ”€â”€ ChatController             â”‚   â”œâ”€â”€ RAG Pipeline
â””â”€â”€ RestTemplate â†’ AI-Service  â”‚   â”œâ”€â”€ Question Analysis (ì´ê´€)
                               â”‚   â”œâ”€â”€ Context Builder (ì´ê´€)
                               â”‚   â”œâ”€â”€ Portfolio DB ì—°ë™ (ì‹ ê·œ)
                               â”‚   â”œâ”€â”€ Document Processing
                               â”‚   â”œâ”€â”€ Vector Search
                               â”‚   â””â”€â”€ LLM Generation
```

### ì´ê´€í•  ì£¼ìš” ê¸°ëŠ¥ë“¤

#### 1. ì§ˆë¬¸ ë¶„ì„ ë¡œì§
```python
# ë°±ì—”ë“œ QuestionAnalysisService â†’ AI-Service
class QuestionAnalyzer:
    async def analyze_question(self, question: str) -> AnalysisResult:
        # AI ì‚¬ìš© ì—¬ë¶€ íŒë‹¨
        # ì¦‰ì‹œ ì‘ë‹µ ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
        # ì§ˆë¬¸ íƒ€ì… ë¶„ë¥˜
```

#### 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ë¡œì§  
```python
# ë°±ì—”ë“œ ContextBuilderService â†’ AI-Service
class ContextBuilder:
    async def build_full_portfolio_context(self) -> str:
        # PostgreSQLì—ì„œ ì§ì ‘ Portfolio/Project/Experience ì¡°íšŒ
        # êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„±
    
    async def build_project_context(self, project_title: str) -> str:
        # íŠ¹ì • í”„ë¡œì íŠ¸ ì¤‘ì‹¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
```

#### 3. í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì ‘ê·¼
```python
# AI-Serviceì—ì„œ ì§ì ‘ PostgreSQL ì—°ê²°
class PortfolioRepository:
    async def get_all_projects(self) -> List[Project]:
        # ë°±ì—”ë“œì™€ ë™ì¼í•œ DB, ë™ì¼í•œ í…Œì´ë¸” ì¡°íšŒ
    
    async def get_full_portfolio(self) -> PortfolioData:
        # Projects + Experiences + Education + Certifications
```

### ìƒˆë¡œìš´ API ì„¤ê³„
```python
POST /api/v1/chat
{
    "question": "ì‚¬ìš©ì ì§ˆë¬¸",
    "user_context": "ì„ íƒëœ í”„ë¡œì íŠ¸ëª… (ì„ íƒì )",
    "user_id": "ì‚¬ìš©ì ì‹ë³„ì (ì„ íƒì )"
}

# AI-Serviceê°€ ëª¨ë“  AI ê´€ë ¨ ì²˜ë¦¬ ë‹´ë‹¹:
# 1. ì§ˆë¬¸ ë¶„ì„
# 2. DBì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì¡°íšŒ
# 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
# 4. RAG ë²¡í„° ê²€ìƒ‰ (í–¥í›„ í™•ì¥)
# 5. LLM ì‘ë‹µ ìƒì„±
```

### ë°±ì—”ë“œ ë‹¨ìˆœí™”
```java
// ë°±ì—”ë“œëŠ” ë‹¨ìˆœí•œ í”„ë¡ì‹œ ì—­í• 
@RestController
public class ChatController {
    @PostMapping("/api/chat")
    public ResponseEntity<ChatResponse> chat(@RequestBody ChatRequest request) {
        // AI-Serviceë¡œ ì „ë‹¬ë§Œ
        return restTemplate.postForEntity(aiServiceUrl + "/api/v1/chat", request, ChatResponse.class);
    }
}
```

### ì¥ì 
- **ê´€ì‹¬ì‚¬ ë¶„ë¦¬**: AI ë¡œì§ì´ AI-Serviceì— ì§‘ì¤‘
- **ê¸°ìˆ  ìŠ¤íƒ ìµœì í™”**: Pythonìœ¼ë¡œ AI/ML ê¸°ëŠ¥ êµ¬í˜„
- **í™•ì¥ì„±**: RAG, ë²¡í„° ê²€ìƒ‰ ë“± ê³ ê¸‰ AI ê¸°ëŠ¥ ììœ ë¡­ê²Œ í™•ì¥
- **ë…ë¦½ ë°°í¬**: AI ê¸°ëŠ¥ ë³€ê²½ ì‹œ AI-Serviceë§Œ ì¬ë°°í¬
- **ì„±ëŠ¥ ìµœì í™”**: AI ì „ìš© ìºì‹±, ìµœì í™” êµ¬í˜„ ê°€ëŠ¥

### êµ¬í˜„ ìš°ì„ ìˆœìœ„ (ìˆ˜ì •ëœ Phase 1)
1. **PostgreSQL ì—°ë™** - ë°±ì—”ë“œì™€ ë™ì¼í•œ DB ì—°ê²°
2. **ê¸°ì¡´ ë¡œì§ ì´ê´€** - QuestionAnalysis + ContextBuilder Python êµ¬í˜„
3. **API í˜¸í™˜ì„±** - ë°±ì—”ë“œì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ì¸í„°í˜ì´ìŠ¤
4. **ê¸°ë³¸ RAG êµ¬ì¡°** - í–¥í›„ ë²¡í„° ê²€ìƒ‰ í™•ì¥ì„ ìœ„í•œ ê¸°ë°˜ ë§ˆë ¨

---

## 2025-08-26: ë°±ì—”ë“œ AI ê¸°ëŠ¥ ì™„ì „ ë¶„ë¦¬ ë° AI-Service êµ¬ì¡° ì™„ì„±

### 1. ë°±ì—”ë“œ ì»´íŒŒì¼ ì˜¤ë¥˜ í•´ê²°

**ë¬¸ì œì :**
- ë°±ì—”ë“œì—ì„œ ai-serviceë¡œ ì´ê´€ëœ í´ë˜ìŠ¤ë“¤ì„ ì—¬ì „íˆ ì°¸ì¡°
- `QuestionAnalysisService`, `PromptService`, `PromptConverter` ë“± ì‚­ì œëœ í´ë˜ìŠ¤ ì°¸ì¡° ì˜¤ë¥˜

**í•´ê²°ì±…:**
- `PromptController` ì™„ì „ ì‚­ì œ (ë°±ì—”ë“œì—ì„œ AI ê¸°ëŠ¥ ì œê±°)
- `ChatRequest`ì— `sessionId` í•„ë“œ ì¶”ê°€ (user_id ëŒ€ì‹  session ê¸°ë°˜ ì‹ë³„)
- `ChatApplicationService`ì—ì„œ `getUserId()` â†’ `getSessionId()` ë³€ê²½

**ê²°ê³¼:**
- âœ… ë°±ì—”ë“œ ì»´íŒŒì¼ ì„±ê³µ
- âœ… ai-serviceë¡œ ëª¨ë“  AI ê¸°ëŠ¥ ì™„ì „ ì´ê´€
- âœ… ë°±ì—”ë“œëŠ” ìˆœìˆ˜ í”„ë¡ì‹œ ì—­í• ë§Œ ìˆ˜í–‰

### 2. AI-Service êµ¬ì¡° ì™„ì„±

**conversation_log.md ì„¤ê³„ì™€ í˜„ì¬ êµ¬ì¡° ì¡°í•©:**

#### ë””ë ‰í† ë¦¬ êµ¬ì¡° ì •ë¦¬
```
ai-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/                      # âœ… ì„¤ì •, DB ê´€ë¦¬
â”‚   â”œâ”€â”€ models/                    # âœ… Pydantic ëª¨ë¸ë“¤
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chat/                  # âœ… ì§ˆë¬¸ ë¶„ì„, ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
â”‚   â”‚   â”œâ”€â”€ portfolio/             # âœ… í¬íŠ¸í´ë¦¬ì˜¤ DB ì—°ë™
â”‚   â”‚   â””â”€â”€ generation/            # âœ… LLM ì„œë¹„ìŠ¤ (ìƒˆë¡œ ì¶”ê°€)
â”‚   â””â”€â”€ api/v1/                    # âœ… REST API
â”œâ”€â”€ config.yaml                    # âœ… ë‚´ë¶€ ì„¤ì •
â””â”€â”€ requirements-*.txt             # âœ… ì˜ì¡´ì„± ê´€ë¦¬
```

#### LLM ì„œë¹„ìŠ¤ êµ¬í˜„
- **íŒŒì¼**: `app/services/generation/llm_service.py`
- **ê¸°ëŠ¥**: Gemini API ì—°ë™, ì‘ë‹µ ìƒì„±
- **í†µí•©**: `chat.py`ì—ì„œ ì„ì‹œ ì‘ë‹µì„ ì‹¤ì œ LLM í˜¸ì¶œë¡œ êµì²´

**ì£¼ìš” ë³€ê²½ì‚¬í•­:**
```python
# Before: ì„ì‹œ ì‘ë‹µ
answer = await _generate_temporary_response(request.question, analysis, context)

# After: ì‹¤ì œ LLM í˜¸ì¶œ
answer = await llm_service.generate_response(
    question=request.question,
    context=context,
    system_prompt=None
)
```

### 3. í™˜ê²½ë³€ìˆ˜ ë° ì„¤ì • ê´€ë¦¬ ê°œì„ 

**ë¬¸ì œì :**
- `ExternalConfig`ì—ì„œ ì •ì˜ë˜ì§€ ì•Šì€ í™˜ê²½ë³€ìˆ˜ë¡œ ì¸í•œ Pydantic ê²€ì¦ ì˜¤ë¥˜
- `QDRANT__HOST`, `SERVER__DEBUG_MODE` ë“± GitHub Secretsì™€ ë¶ˆì¼ì¹˜

**í•´ê²°ì±…:**
- `ExternalConfig`ì— ëˆ„ë½ëœ í•„ë“œë“¤ ì¶”ê°€:
  - `QDRANT_HOST`, `QDRANT_PORT`, `QDRANT_API_KEY`
  - `SERVER_DEBUG_MODE`, `LOGGING_LEVEL`
- `extra = "ignore"` ì„¤ì •ìœ¼ë¡œ ì •ì˜ë˜ì§€ ì•Šì€ í™˜ê²½ë³€ìˆ˜ ë¬´ì‹œ

### 4. ì˜ì¡´ì„± ê´€ë¦¬ ë¬¸ì œ í•´ê²°

**ë¬¸ì œì :**
- Docker ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œì™€ ë¡œì»¬ ê°œë°œ í™˜ê²½ì˜ requirements íŒŒì¼ ë¶ˆì¼ì¹˜
- `asyncpg`ê°€ `requirements.txt`ì—ë§Œ ìˆê³  `requirements-base.txt`ì— ì—†ì–´ì„œ ë°°í¬ ì‹œ ëˆ„ë½

**í•´ê²°ì±…:**
- `asyncpg`, `sqlalchemy[asyncio]`, `alembic`ì„ `requirements-base.txt`ì— ì¶”ê°€
- Docker ë¹Œë“œ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ íŒ¨í‚¤ì§€ë“¤ì´ ëª¨ë‘ ì„¤ì¹˜ë˜ë„ë¡ ë³´ì¥

### 5. SQLAlchemy 2.0 í˜¸í™˜ì„±

**ë¬¸ì œì :**
- `"SELECT 1"` â†’ `text("SELECT 1")` ë¬¸ë²• ë³€ê²½ í•„ìš”

---

# RAG ë°ëª¨ ë° ë°°í¬ ìµœì í™” ì¶”ê°€ ì‘ì—… (2025-08-27)

## RAG ë°ëª¨ í˜ì´ì§€ êµ¬í˜„

### 1. RAG íŒŒì´í”„ë¼ì¸ ë°ëª¨ ê°œë°œ
- **ëª©ì **: ai-serviceì˜ RAG ì²˜ë¦¬ ê³¼ì •ì„ ì‹¤ì œ í´ë˜ìŠ¤ë“¤ë¡œ ì‹œì—°
- **UI**: Gradio 5.44.0 ê¸°ë°˜ 6ê°œ íƒ­ ì¸í„°í˜ì´ìŠ¤
- **ê¸°ëŠ¥**: ë¬¸ì„œ ì—…ë¡œë“œ â†’ ì„ë² ë”© â†’ ë²¡í„° ì €ì¥ â†’ ìœ ì‚¬ë„ ê²€ìƒ‰ â†’ RAG ì‘ë‹µ

#### êµ¬í˜„í•œ í•µì‹¬ ì»´í¬ë„ŒíŠ¸
```python
# ë²¡í„° ì €ì¥ì†Œ
app/demo/vector_store.py - InMemoryVectorStore (cosine similarity)

# ì„ë² ë”© ì„œë¹„ìŠ¤  
app/demo/embedding_service.py - SentenceTransformer ëª¨ë¸ ê´€ë¦¬

# RAG ë°ëª¨ ì„œë¹„ìŠ¤
app/demo/rag_demo_service.py - ê¸°ì¡´ RAG í´ë˜ìŠ¤ë“¤ê³¼ í†µí•©

# Gradio ì¸í„°í˜ì´ìŠ¤
main_demo.py - 6ê°œ íƒ­: ì—…ë¡œë“œ, ë²¡í„°ê²€ìƒ‰, ì„ë² ë”©, RAGìƒì„±, ê´€ë¦¬, ì„¤ì •
```

## ë°°í¬ ì „ëµ ìµœì í™”

### 1. í™˜ê²½ë³„ ë¶„ë¦¬ ì „ëµ
```
ë°°í¬ í™˜ê²½ êµ¬ë¶„:
â”œâ”€â”€ ğŸ—ï¸  CloudRun í”„ë¡œë•ì…˜ (API í˜¸ì¶œ ê¸°ë°˜)
â”‚   â””â”€â”€ requirements-cloudrun.txt (langchainë§Œ, ML ëª¨ë¸ ì œì™¸)
â”‚
â”œâ”€â”€ ğŸš€ HuggingFace Spaces ë°ëª¨ (ë¡œì»¬ ML ëª¨ë¸)  
â”‚   â””â”€â”€ requirements-demo.txt (sentence-transformers í¬í•¨)
â”‚
â””â”€â”€ ğŸ‘¨â€ğŸ’» ë¡œì»¬ ê°œë°œ
    â””â”€â”€ requirements-local.txt (ê°œë°œ í¸ì˜ì„±)
```

### 2. HuggingFace Spaces ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ
- **ë¬¸ì œ**: sentence-transformers â†’ torch ì˜ì¡´ì„±ìœ¼ë¡œ ~7GB ë¹Œë“œ
- **í•´ê²°**: Docker ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œë¡œ CPU-only PyTorch ì‚¬ìš©
- **ìµœì í™”**: ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ, ì‚¬ìš©ì ê¶Œí•œ ì„¤ì •

### 3. CI/CD ë° ì˜ì¡´ì„± ì •ë¦¬

#### ì›Œí¬í”Œë¡œìš° êµ¬ì¡°í™”
```
GitHub Actions:
â”œâ”€â”€ deploy-ai-service-demo.yml     # HF Spaces (main/staging â†’ ai-service/**)
â”œâ”€â”€ deploy-ai-service-production.yml # CloudRun í”„ë¡œë•ì…˜  
â”œâ”€â”€ deploy-ai-service-staging.yml    # CloudRun ìŠ¤í…Œì´ì§•
â”œâ”€â”€ deploy-production.yml            # ë©”ì¸ ì•± í”„ë¡œë•ì…˜
â””â”€â”€ deploy-staging.yml               # ë©”ì¸ ì•± ìŠ¤í…Œì´ì§•
```

#### ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬
**ì œê±°í•œ íŒŒì¼ë“¤:**
- âŒ `Dockerfile.demo` (Dockerfile.spacesì™€ ì¤‘ë³µ)
- âŒ `docker-compose.demo.yml` (ë¶ˆí•„ìš”)
- âŒ `requirements-base.txt`, `requirements-ml.txt` â†’ `requirements-cloudrun.txt` í†µí•©

**ì •ë¦¬í•œ ì˜ì¡´ì„±:**
- CloudRun: ë¡œì»¬ ML ëª¨ë¸ ì˜ì¡´ì„± ì œê±° (4-6GB ì ˆì•½)
- ë¡œì»¬ ê°œë°œ: ë¯¸ì‚¬ìš© íŒ¨í‚¤ì§€ ì œê±° (langsmith, unstructured ë“±)

## ë°°í¬ ì¤€ë¹„ ì™„ë£Œ

### HuggingFace Spaces ë°°í¬ íŒŒì¼ë“¤
- âœ… `app.py`: HF Spaces ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ 
- âœ… `main_demo.py`: Gradio ì¸í„°í˜ì´ìŠ¤
- âœ… `requirements-demo.txt`: ìµœì í™”ëœ ì˜ì¡´ì„±
- âœ… `Dockerfile.spaces`: ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ
- âœ… `README-HuggingFace.md`: HF Spaces ë©”íƒ€ë°ì´í„°
- âœ… `deploy-ai-service-demo.yml`: GitHub Actions ì›Œí¬í”Œë¡œìš°

### ì˜ˆìƒ íš¨ê³¼
- **HF Spaces**: 16GB RAMì—ì„œ ë¬´ë£Œ RAG ë°ëª¨ ì„œë¹„ìŠ¤
- **CloudRun**: 4-6GB ì ˆì•½ëœ ê²½ëŸ‰ í”„ë¡œë•ì…˜ ë°°í¬  
- **ê°œë°œ**: ëª…í™•íˆ ë¶„ë¦¬ëœ í™˜ê²½ë³„ êµ¬ì„±
- **ìœ ì§€ë³´ìˆ˜**: ì¤‘ë³µ ì œê±°ë¡œ ê°„ì†Œí™”ëœ ê´€ë¦¬

**í•´ê²°ì±…:**
- `from sqlalchemy import text` import ì¶”ê°€
- ëª¨ë“  raw SQL ì¿¼ë¦¬ë¥¼ `text()` í•¨ìˆ˜ë¡œ ê°ì‹¸ê¸°

### ìµœì¢… ì•„í‚¤í…ì²˜

```
Frontend â†’ Backend (í”„ë¡ì‹œ) â†’ AI-Service
         â†“
    sessionId ê¸°ë°˜
    ìŠ¤íŒ¸ ë°©ì§€ & ê²€ì¦
```

**ë°±ì—”ë“œ ì—­í• :**
- ì…ë ¥ ê²€ì¦ ë° ìŠ¤íŒ¸ ë°©ì§€
- AI-Serviceë¡œ ìš”ì²­ ì „ë‹¬
- ì‘ë‹µ ë°˜í™˜

**AI-Service ì—­í• :**
- ì§ˆë¬¸ ë¶„ì„ (QuestionAnalyzer)
- í¬íŠ¸í´ë¦¬ì˜¤ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ContextBuilder)
- LLM ì‘ë‹µ ìƒì„± (LLMService)
- í–¥í›„ RAG íŒŒì´í”„ë¼ì¸ í™•ì¥ ì¤€ë¹„

### 6. Requirements íŒŒì¼ êµ¬ì¡° ê°œì„ 

**ë¬¸ì œì :**
- Docker ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œì™€ ë¡œì»¬ ê°œë°œ í™˜ê²½ì˜ requirements íŒŒì¼ ë¶ˆì¼ì¹˜
- ë¡œì»¬ì—ì„œëŠ” `requirements.txt` ì‚¬ìš©, ë°°í¬ì—ì„œëŠ” `requirements-base.txt` + `requirements-ml.txt` ì‚¬ìš©
- ìƒˆë¡œìš´ ì˜ì¡´ì„± ì¶”ê°€ ì‹œ ì–´ëŠ íŒŒì¼ì— ì¶”ê°€í•´ì•¼ í• ì§€ ë¶ˆëª…í™•

**í•´ê²°ì±…:**
- **`requirements-local.txt`**: ë¡œì»¬ ê°œë°œìš© ë‹¨ì¼ íŒŒì¼ ìƒì„±
- **`requirements-base.txt`**: Docker ê¸°ë³¸ ì˜ì¡´ì„± (FastAPI, DB, ìœ í‹¸ë¦¬í‹°)
- **`requirements-ml.txt`**: Docker ML/AI ì˜ì¡´ì„± (LangChain, Transformers)
- **`requirements.txt`**: Docker ë¹Œë“œ ì•ˆë‚´ìš©ìœ¼ë¡œ ë³€ê²½
- **`README-requirements.md`**: ì‚¬ìš©ë²• ë° ê°€ì´ë“œë¼ì¸ ë¬¸ì„œí™”

**ìƒˆë¡œìš´ ì˜ì¡´ì„± ì¶”ê°€ ê°€ì´ë“œë¼ì¸:**
```bash
# ë¡œì»¬ ê°œë°œìš©
echo "new-package==1.0.0" >> requirements-local.txt

# Docker ë°°í¬ìš© (ê¸°ë³¸ ì˜ì¡´ì„±)
echo "new-package==1.0.0" >> requirements-base.txt

# Docker ë°°í¬ìš© (ML/AI ê´€ë ¨)
echo "new-package==1.0.0" >> requirements-ml.txt
```

**ê²°ê³¼:**
- âœ… ë¡œì»¬ê³¼ ë°°í¬ í™˜ê²½ì˜ ëª…í™•í•œ ë¶„ë¦¬
- âœ… CI/CD ì˜¤ë¥˜ ë°©ì§€
- âœ… ì˜ì¡´ì„± ê´€ë¦¬ ê°€ì´ë“œë¼ì¸ í™•ë¦½

### 7. ìŠ¤í…Œì´ì§• í™˜ê²½ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜ í•´ê²°

**ë¬¸ì œì :**
- AI ì„œë¹„ìŠ¤ì—ì„œ `DATABASE_URL` í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
- GitHub Secretsì—ëŠ” `POSTGRE_URL`ë¡œ ì„¤ì •ë¨
- ìŠ¤í…Œì´ì§• ë°°í¬ ì‹œ `[Errno 111] Connection refused` ì˜¤ë¥˜ ë°œìƒ

**í•´ê²°ì±…:**
- **AI ì„œë¹„ìŠ¤ ì„¤ì • ë³€ê²½**: `DATABASE_URL` â†’ `POSTGRE_URL`ë¡œ í†µì¼
- **ë°°í¬ ì›Œí¬í”Œë¡œìš° ìˆ˜ì •**: ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ ëª¨ë‘ì— `POSTGRE_URL` í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

**ë³€ê²½ëœ íŒŒì¼ë“¤:**
```python
# ai-service/app/core/config.py
POSTGRE_URL: str = "postgresql+asyncpg://dev_user:dev_password@localhost:5432/ai_portfolio"

def get_database_config(self) -> dict:
    return {
        "url": self.external.POSTGRE_URL,  # DATABASE_URL â†’ POSTGRE_URL
        **self.internal['database']
    }
```

```yaml
# .github/workflows/deploy-ai-service-staging.yml
# .github/workflows/deploy-ai-service-production.yml
--set-env-vars="POSTGRE_URL=${{ secrets.POSTGRE_URL }}" \
```

**ê²°ê³¼:**
- âœ… ìŠ¤í…Œì´ì§• í™˜ê²½ì—ì„œ PostgreSQL ì—°ê²° ì„±ê³µ
- âœ… í™˜ê²½ë³€ìˆ˜ ëª…ëª… ê·œì¹™ í†µì¼
- âœ… ë°±ì—”ë“œì™€ AI ì„œë¹„ìŠ¤ ê°„ ì¼ê´€ì„± í™•ë³´

### ë‹¤ìŒ ë‹¨ê³„
1. **RAG íŒŒì´í”„ë¼ì¸ í™•ì¥**: Document processing, Vector store, Retrieval
2. **ìºì‹± ì‹œìŠ¤í…œ**: Redis ì—°ë™ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
3. **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**: LangSmith + YAML í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ

---

## 2025-08-26: Document Loaderì™€ TextSplitter ëª¨ë“ˆ ì„¤ê³„ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ ì •

### ë°°ê²½
conversation_logì˜ ìµœì¢…ê²°ì • ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ, Document Loaderì™€ TextSplitter ëª¨ë“ˆ êµ¬í˜„ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ ì • ë° ê²€ì¦ ë°©ì‹ ê²°ì •

### Knowledge-Base ë¶„ì„ ê²°ê³¼
- **ëŒ€ìƒ íŒŒì¼**: `docs/projects/` ë””ë ‰í† ë¦¬ì˜ Markdown íŒŒì¼ë“¤
  - `3_OnTheTrain.md` (181ì¤„) - ì—¬í–‰ ê³„íš ìŠ¤ì¼€ì¤„ëŸ¬ í”„ë¡œì íŠ¸
  - `2_CloseToU.md` (135ì¤„) - ì¤‘ê³ ê±°ë˜ ê²Œì‹œíŒ í”„ë¡œì íŠ¸  
  - `1_README.md` (141ì¤„) - SKKU ë¯¸ìˆ ë™ì•„ë¦¬ ê°¤ëŸ¬ë¦¬ í”„ë¡œì íŠ¸

- **ë¬¸ì„œ íŠ¹ì„±**:
  - êµ¬ì¡°í™”ëœ Markdown (í—¤ë” 1-5 ë ˆë²¨)
  - í”„ë¡œì íŠ¸ë³„ 100-180ì¤„ì˜ ìƒì„¸ ë¬¸ì„œ
  - ê¸°ìˆ  ìŠ¤íƒ, ê¸°ëŠ¥, êµ¬í˜„ ê³¼ì • ë“± ì²´ê³„ì  êµ¬ì„±

### ë¼ì´ë¸ŒëŸ¬ë¦¬ í›„ë³´êµ° ë¶„ì„

#### DocumentLoader í›„ë³´êµ°
1. **LangChain DocumentLoader** â­
   - ì¥ì : RAG ì‹œìŠ¤í…œ ì™„ë²½ í˜¸í™˜, ë©”íƒ€ë°ì´í„° ìë™ ì¶”ì¶œ, í‘œì¤€í™”ëœ ì¶œë ¥
   - ë‹¨ì : ì˜ì¡´ì„±ì´ ë¬´ê±°ì›€, ì„¸ë°€í•œ ì œì–´ ì–´ë ¤ì›€

2. **python-markdown + pathlib** â­â­  
   - ì¥ì : ê°€ë³ê³  ë¹ ë¦„, Markdown í™•ì¥ ì§€ì›, ì™„ì „í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§•
   - ë‹¨ì : ì§ì ‘ êµ¬í˜„ í•„ìš”, Document ê°ì²´ ë³€í™˜ í•„ìš”

3. **Unstructured**
   - ì¥ì : ê³ ê¸‰ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
   - ë‹¨ì : ê³¼ë„í•œ ê¸°ëŠ¥, ë‹¨ìˆœ MDì—ëŠ” ë¶ˆí•„ìš”

#### TextSplitter í›„ë³´êµ°
1. **LangChain TextSplitter** â­â­
   - ì¥ì : Markdown í—¤ë” ê¸°ë°˜ ë¶„í• , ì •ë°€í•œ ì œì–´, ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜
   - ë‹¨ì : LangChain ì˜ì¡´ì„± í•„ìš”

2. **spaCy + ì§ì ‘ êµ¬í˜„** â­
   - ì¥ì : ë¬¸ì¥/ë‹¨ë½ ê²½ê³„ ìš°ìˆ˜, ì™„ì „ ì»¤ìŠ¤í„°ë§ˆì´ì§•, ê°€ë²¼ìš´ ì˜ì¡´ì„±
   - ë‹¨ì : êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ, ì„±ëŠ¥ íŠœë‹ í•„ìš”

3. **tiktoken (OpenAI)**
   - ì¥ì : í† í° ê¸°ë°˜ ì •í™•í•œ ë¶„í• 
   - ë‹¨ì : ì˜ë¯¸ì  ê²½ê³„ ë¬´ì‹œ, Markdown êµ¬ì¡° ë¯¸ê³ ë ¤

4. **NLTK + ì§ì ‘ êµ¬í˜„**
   - ì¥ì : ë¬¸ì¥ ê²½ê³„ ê°ì§€ ìš°ìˆ˜
   - ë‹¨ì : Markdown í—¤ë” ì§ì ‘ ì²˜ë¦¬ í•„ìš”, í•œêµ­ì–´ ì§€ì› ì œí•œ

### ìµœì¢… ê²°ì •: LangChain í†µí•© ì¶”ì²œ â­â­â­

#### ì„ ì • ì´ìœ 
- RAG íŒŒì´í”„ë¼ì¸ê³¼ ì™„ë²½ í˜¸í™˜
- ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜ê³¼ ì•ˆì •ì„±  
- ë©”íƒ€ë°ì´í„° ìë™ ì²˜ë¦¬
- Markdown í—¤ë” êµ¬ì¡° ì¸ì‹
- í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ íŠ¹ì„±ì— ìµœì 

#### êµ¬í˜„ í´ë˜ìŠ¤ ì„¤ê³„
```python
# DocumentLoader
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.document_loaders import UnstructuredMarkdownLoader

# TextSplitter  
from langchain.text_splitter import MarkdownHeaderTextSplitter
from langchain.text_splitter import RecursiveCharacterTextSplitter
```

### ê²€ì¦ ì‹œìŠ¤í…œ ì„¤ê³„

#### 1. Document Load ê²€ì¦
```python
class DocumentLoadValidator:
    def validate_file_integrity(self, file_path: str) -> ValidationResult:
        # íŒŒì¼ ì¡´ì¬, ì½ê¸° ê¶Œí•œ, í¬ê¸° ê²€ì¦
    
    def validate_markdown_structure(self, content: str) -> ValidationResult:
        # í—¤ë” êµ¬ì¡°, ë§í¬, ì´ë¯¸ì§€ ê²½ë¡œ ê²€ì¦
    
    def validate_encoding(self, file_path: str) -> ValidationResult:
        # UTF-8 ì¸ì½”ë”© ê²€ì¦
```

#### 2. TextSplit ê²€ì¦
```python
class TextSplitValidator:
    def validate_chunk_sizes(self, chunks: List[TextChunk]) -> ValidationResult:
        # chunk_size ë²”ìœ„ ê²€ì¦ (500-2000ì)
    
    def validate_overlap_consistency(self, chunks: List[TextChunk]) -> ValidationResult:
        # ì²­í¬ ê°„ overlap ê²€ì¦
    
    def validate_content_completeness(self, original: str, chunks: List[TextChunk]) -> ValidationResult:
        # ì›ë³¸ ë‚´ìš© ì†ì‹¤ ì—†ëŠ”ì§€ ê²€ì¦
    
    def validate_semantic_boundaries(self, chunks: List[TextChunk]) -> ValidationResult:
        # í—¤ë”/ë¬¸ë‹¨ ê²½ê³„ì—ì„œ ë¶„í• ë˜ì—ˆëŠ”ì§€ ê²€ì¦
```

#### 3. í†µí•© ê²€ì¦  
```python
class DocumentProcessingValidator:
    def validate_pipeline(self, file_path: str) -> PipelineValidationResult:
        # load -> split -> embed ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦
```

### êµ¬í˜„ ê³„íš (Phase 2 ì„¸ë¶€)
1. **LangChain ì˜ì¡´ì„± ì¶”ê°€**: requirementsì— langchain-community ì¶”ê°€
2. **Document Loader êµ¬í˜„**: DirectoryLoader + UnstructuredMarkdownLoader
3. **Text Splitter êµ¬í˜„**: MarkdownHeaderTextSplitter + RecursiveCharacterTextSplitter  
4. **ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„**: ê° ë‹¨ê³„ë³„ ê²€ì¦ í´ë˜ìŠ¤
5. **í†µí•© í…ŒìŠ¤íŠ¸**: docs/projects/ íŒŒì¼ë“¤ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦

### ì„¤ì • íŒŒë¼ë¯¸í„°
```yaml
# config.yaml ì¶”ê°€ ì„¤ì •
document_processing:
  source_directory: "docs/projects/"
  file_pattern: "*.md"
  chunk_size: 1000
  chunk_overlap: 200
  header_levels: [1, 2, 3]  # ë¶„í• í•  í—¤ë” ë ˆë²¨
```

---

## 2025-08-26: Document Processing ëª¨ë“ˆ ì™„ì „ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ

### êµ¬í˜„ ì™„ë£Œëœ ì•„í‚¤í…ì²˜

#### ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
```
ai-service/app/services/document/
â”œâ”€â”€ __init__.py                    # ëª¨ë“ˆ exports
â”œâ”€â”€ pipeline.py                    # ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”œâ”€â”€ loaders/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                    # DocumentLoader ì¸í„°í˜ì´ìŠ¤
â”‚   â””â”€â”€ markdown_loader.py         # LangChain TextLoader ê¸°ë°˜ êµ¬í˜„
â”œâ”€â”€ splitters/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                    # TextSplitter ì¸í„°í˜ì´ìŠ¤ + TextChunk ëª¨ë¸
â”‚   â””â”€â”€ markdown_splitter.py       # MarkdownHeaderTextSplitter ê¸°ë°˜ êµ¬í˜„
â””â”€â”€ validators/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ base.py                    # ê²€ì¦ ê¸°ë°˜ í´ë˜ìŠ¤ë“¤ (ValidationResult, ValidationStatus)
    â”œâ”€â”€ load_validator.py          # ë¬¸ì„œ ë¡œë”© ê²€ì¦
    â”œâ”€â”€ split_validator.py         # í…ìŠ¤íŠ¸ ë¶„í•  ê²€ì¦  
    â””â”€â”€ pipeline_validator.py      # í†µí•© íŒŒì´í”„ë¼ì¸ ê²€ì¦
```

### í•µì‹¬ êµ¬í˜„ í´ë˜ìŠ¤ë“¤

#### 1. Base Interfaces
```python
# DocumentLoader ì¸í„°í˜ì´ìŠ¤
class DocumentLoader(ABC):
    async def load_document(self, file_path: Path) -> Document
    async def load_documents(self, directory_path: Path, pattern: Optional[str] = None) -> List[Document]

# TextSplitter ì¸í„°í˜ì´ìŠ¤ + TextChunk ëª¨ë¸
@dataclass
class TextChunk:
    content: str
    metadata: dict
    start_index: int = 0
    end_index: int = 0

class TextSplitter(ABC):
    async def split_document(self, document: Document) -> List[TextChunk]
    async def split_documents(self, documents: List[Document]) -> List[TextChunk]
```

#### 2. LangChain í†µí•© êµ¬í˜„ì²´
```python
# MarkdownDocumentLoader: TextLoader ê¸°ë°˜ (unstructured ëŒ€ì‹  ê²½ëŸ‰í™”)
class MarkdownDocumentLoader(DocumentLoader):
    - DirectoryLoader + TextLoader ì¡°í•©
    - ë¹„ë™ê¸° ì²˜ë¦¬ (run_in_executor)
    - í’ë¶€í•œ ë©”íƒ€ë°ì´í„° (íŒŒì¼ ì •ë³´, í¬ê¸°, ê²½ë¡œ ë“±)

# MarkdownTextSplitter: 2ë‹¨ê³„ ë¶„í• 
class MarkdownTextSplitter(TextSplitter):
    - 1ë‹¨ê³„: MarkdownHeaderTextSplitter (H1, H2, H3 ê¸°ì¤€)
    - 2ë‹¨ê³„: RecursiveCharacterTextSplitter (chunk_size ê¸°ì¤€)
    - ë©”íƒ€ë°ì´í„° ì „íŒŒ ë° ì²­í¬ ì¸ë±ì‹±
```

#### 3. 3ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ
```python
# DocumentLoadValidator: íŒŒì¼ ë¬´ê²°ì„±, ë©”íƒ€ë°ì´í„°, ë§ˆí¬ë‹¤ìš´ êµ¬ì¡° ê²€ì¦
class DocumentLoadValidator:
    - íŒŒì¼ ì¡´ì¬/ê¶Œí•œ/í¬ê¸° ê²€ì¦
    - UTF-8 ì¸ì½”ë”© ê²€ì¦
    - ë§ˆí¬ë‹¤ìš´ í—¤ë” êµ¬ì¡° ë¶„ì„
    - ë¸Œë¡œí° ë§í¬ ê°ì§€

# TextSplitValidator: ë¶„í•  í’ˆì§ˆ, ì˜¤ë²„ë©, ì˜ë¯¸ ê²½ê³„ ê²€ì¦  
class TextSplitValidator:
    - ì²­í¬ í¬ê¸° ë¶„í¬ ë¶„ì„ (100-2000ì)
    - ì˜¤ë²„ë© ì¼ê´€ì„± ê²€ì¦ (10%-30%)
    - ì˜ë¯¸ì  ê²½ê³„ ê²€ì¦ (ë¬¸ì¥/ë¬¸ë‹¨ ë‹¨ìœ„)
    - ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦ (ì›ë³¸ê³¼ ë¹„êµ)

# PipelineValidator: ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© ê²€ì¦
class PipelineValidator:
    - ë¬¸ì„œ-ì²­í¬ ë¹„ìœ¨ ë¶„ì„
    - ë©”íƒ€ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
    - ì½˜í…ì¸  ë¶„í¬ í†µê³„
```

#### 4. DocumentProcessingPipeline ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
```python
class DocumentProcessingPipeline:
    async def process_directory(self, directory_path: Path, file_pattern: str = "*.md") -> Dict[str, Any]
    async def process_file(self, file_path: Path) -> Dict[str, Any]  
    async def process_batch(self, paths: List[Path], max_concurrent: int = 5) -> List[Dict[str, Any]]
    def get_processing_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]
```

### ì˜ì¡´ì„± ê´€ë¦¬ ê°œì„ 

#### requirements íŒŒì¼ ì—…ë°ì´íŠ¸
```bash
# requirements-ml.txt (CI/CD ë°°í¬ìš©)
langchain-community==0.0.10

# requirements-local.txt (ë¡œì»¬ ê°œë°œìš©)  
langchain-community==0.0.10
```

**ì„ íƒí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬:**
- **langchain-community**: DirectoryLoader, TextLoader
- **langchain.text_splitter**: MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter
- **unstructured ì œì™¸**: ì˜ì¡´ì„± ë³µì¡ì„±ìœ¼ë¡œ ì¸í•´ TextLoaderë¡œ ëŒ€ì²´

### ì„¤ì • ì‹œìŠ¤í…œ í†µí•©

#### config.yaml í™•ì¥
```yaml
document_processing:
  source_directory: "docs/projects/"
  file_pattern: "*.md"
  encoding: "utf-8"
  enable_validation: true
  max_concurrent_processing: 5
  
  # Splitter Configuration
  splitter:
    chunk_size: 1000
    chunk_overlap: 200
    header_levels: [1, 2, 3]
  
  # Validator Configuration  
  validator:
    max_file_size_mb: 10
    min_chunk_size: 100
    max_chunk_size: 2000
    min_overlap_ratio: 0.1
    max_overlap_ratio: 0.3
```

### ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼

#### í…ŒìŠ¤íŠ¸ í™˜ê²½
- **ëŒ€ìƒ íŒŒì¼**: docs/projects/ ë””ë ‰í† ë¦¬ì˜ 3ê°œ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ
  - `1_README.md` (SKKU FAC Gallery) - 3,687ì
  - `2_CloseToU.md` (ì¤‘ê³ ê±°ë˜ ê²Œì‹œíŒ) - 2,424ì  
  - `3_OnTheTrain.md` (ì—¬í–‰ ìŠ¤ì¼€ì¤„ëŸ¬) - 3,095ì

#### ì„±ê³µ ê²°ê³¼
- âœ… **ë¬¸ì„œ ë¡œë”©**: 3ê°œ ë¬¸ì„œ, 9,206ì ì„±ê³µ ì²˜ë¦¬
- âœ… **ì²­í¬ ìƒì„±**: 67ê°œ ì²­í¬ (í‰ê·  22.3ê°œ/ë¬¸ì„œ)
- âœ… **ì²˜ë¦¬ ì„±ëŠ¥**: 0.01ì´ˆ ì²˜ë¦¬ ì‹œê°„ (561.1 ë¬¸ì„œ/ì´ˆ)
- âœ… **ë¹„ë™ê¸° ì²˜ë¦¬**: ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ
- âœ… **ê²€ì¦ ì‹œìŠ¤í…œ**: 3ë‹¨ê³„ ê²€ì¦ ëª¨ë‘ ë™ì‘ í™•ì¸

#### ê²€ì¦ìœ¼ë¡œ ë°œê²¬ëœ ê°œì„ ì 
- âš ï¸ **ì²­í¬ í¬ê¸°**: 40ê°œ ì²­í¬ê°€ 100ì ë¯¸ë§Œ (min_chunk_size ì¡°ì • í•„ìš”)
- âš ï¸ **ì½˜í…ì¸  ì†ì‹¤**: 9.4% ê¸¸ì´ ì°¨ì´ (ë¶„í•  ì•Œê³ ë¦¬ì¦˜ ê°œì„  í•„ìš”)
- âš ï¸ **ì˜¤ë²„ë© ì¼ê´€ì„±**: 66ê°œ ì²­í¬ì—ì„œ ì˜¤ë²„ë© ë¹„ì¼ê´€ì„±
- âš ï¸ **ì˜ë¯¸ ê²½ê³„**: 64ê°œ ì²­í¬ê°€ ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ë¶„í• 

#### í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„
- **test_document_processing.py**: ì™„ì „í•œ í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸
- **UTF-8 ì¸ì½”ë”© ì²˜ë¦¬**: Windows í™˜ê²½ í˜¸í™˜ì„±
- **ìƒì„¸í•œ ê²°ê³¼ ë³´ê³ **: ë¬¸ì„œ, ì²­í¬, ê²€ì¦ ê²°ê³¼ ë¶„ì„
- **ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸**: ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í™•ì¸

### ë‹¤ìŒ ë‹¨ê³„ ê³„íš

#### Phase 3: ë²¡í„° ì„ë² ë”© ë° ì €ì¥ì†Œ ì—°ë™
```python
# ì˜ˆì •ëœ í™•ì¥
embedding/
â”œâ”€â”€ embedder.py          # SentenceTransformer ê¸°ë°˜ ì„ë² ë”©
â”œâ”€â”€ vector_store.py      # Qdrant ì—°ë™
â””â”€â”€ retriever.py         # ìœ ì‚¬ë„ ê²€ìƒ‰
```

#### ì„¤ì • íŠœë‹ ìš°ì„ ìˆœìœ„
1. **chunk_size**: 1000 â†’ 800 (ë” ê· ë“±í•œ ë¶„í• )
2. **min_chunk_size**: 100 â†’ 200 (í’ˆì§ˆ í–¥ìƒ)
3. **header_levels**: [1, 2, 3, 4] (ë” ì„¸ë°€í•œ ë¶„í• )
4. **overlap_ratio**: í˜„ì¬ 20% â†’ 15% (ì¤‘ë³µ ìµœì í™”)

### ê¸°ìˆ ì  ì„±ê³¼

#### ì•„í‚¤í…ì²˜ ì„¤ê³„
- âœ… **ê´€ì‹¬ì‚¬ ë¶„ë¦¬**: Loader, Splitter, Validator ë…ë¦½ ëª¨ë“ˆ
- âœ… **ì¸í„°í˜ì´ìŠ¤ ì¶”ìƒí™”**: ë‹¤ì–‘í•œ êµ¬í˜„ì²´ êµì²´ ê°€ëŠ¥
- âœ… **Pipeline íŒ¨í„´**: ë‹¨ê³„ë³„ ì²˜ë¦¬ ë° ê²€ì¦
- âœ… **ë¹„ë™ê¸° ì²˜ë¦¬**: ì„±ëŠ¥ ìµœì í™”

#### LangChain ìƒíƒœê³„ í†µí•©
- âœ… **í‘œì¤€ í˜¸í™˜ì„±**: Document, TextChunk ëª¨ë¸ ì¤€ìˆ˜
- âœ… **ë©”íƒ€ë°ì´í„° í™œìš©**: í’ë¶€í•œ ë¬¸ì„œ ì •ë³´ ë³´ì¡´
- âœ… **í™•ì¥ì„±**: í–¥í›„ RAG íŒŒì´í”„ë¼ì¸ ì—°ê²° ì¤€ë¹„

#### ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬
- âœ… **ë‹¤ì¸µ ê²€ì¦**: ë¡œë”© â†’ ë¶„í•  â†’ íŒŒì´í”„ë¼ì¸ ê²€ì¦
- âœ… **ë¬¸ì œ ì§„ë‹¨**: êµ¬ì²´ì ì¸ ì´ìŠˆì™€ í•´ê²° ì œì•ˆ
- âœ… **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì²˜ë¦¬ ì‹œê°„, ì²˜ë¦¬ëŸ‰ ì¸¡ì •

ì´ì œ Document Processing ëª¨ë“ˆì´ ì™„ì „íˆ êµ¬í˜„ë˜ì–´ í–¥í›„ RAG íŒŒì´í”„ë¼ì¸ì˜ ê¸°ì´ˆê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## 2025-08-27: Gradio ê¸°ë°˜ RAG ë°ëª¨ í˜ì´ì§€ êµ¬ì¶• 

### ë°°ê²½ ë° ëª©í‘œ
ê¸°ì¡´ RAG ì‹œìŠ¤í…œì˜ ë‹¨ê³„ë³„ ë™ì‘ ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ” ì¸í„°ë™í‹°ë¸Œ ë°ëª¨ í˜ì´ì§€ êµ¬ì¶•. í•™ì›ì—ì„œ ë°°ìš´ Gradio ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ai-serviceì˜ ë©”ì¸ í˜ì´ì§€ë¡œ ì œê³µ.

### 1. RAG ë°ëª¨ í˜ì´ì§€ êµ¬ì¡° ì„¤ê³„

#### ì „ì²´ íŒŒì´í”„ë¼ì¸ íƒ­ êµ¬ì„±
```
ğŸ“± RAG Pipeline Demonstration  
â”œâ”€â”€ ğŸ“„ Document Loading     âœ… êµ¬í˜„ ê°€ëŠ¥ (DocumentProcessingPipeline)
â”œâ”€â”€ âœ‚ï¸ Text Splitting      âœ… êµ¬í˜„ ê°€ëŠ¥ (MarkdownTextSplitter)  
â”œâ”€â”€ ğŸ”¤ Embedding           ğŸš§ í–¥í›„ í™•ì¥ (OpenAI/HuggingFace ì—°ë™ ì˜ˆì •)
â”œâ”€â”€ ğŸ“¦ Vector Store        ğŸš§ í–¥í›„ í™•ì¥ (Qdrant ì €ì¥ ë¡œì§ ì˜ˆì •)
â”œâ”€â”€ ğŸ” Retriever          ğŸš§ í–¥í›„ í™•ì¥ (ìœ ì‚¬ë„ ê²€ìƒ‰ ì˜ˆì •)
â”œâ”€â”€ ğŸ¤– Generation         âœ… êµ¬í˜„ ê°€ëŠ¥ (ContextBuilder + LLMService)
â””â”€â”€ ğŸ”„ Full Pipeline      âœ… êµ¬í˜„ ê°€ëŠ¥ (ì „ì²´ í†µí•© í”Œë¡œìš°)
```

#### ê° íƒ­ë³„ ê¸°ëŠ¥ ì„¤ê³„
**A. Document Loading íƒ­**
- ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ `docs/projects/` íŒŒì¼ ì„ íƒ 
- `DocumentProcessingPipeline.process_file()` ì‹¤í–‰
- ë¡œë”© ê²°ê³¼: ë©”íƒ€ë°ì´í„°, ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ

**B. Text Splitting íƒ­**  
- ìŠ¬ë¼ì´ë”: chunk_size, chunk_overlap ì‹¤ì‹œê°„ ì¡°ì •
- `MarkdownTextSplitter` ë™ì‘ ì‹œê°í™”
- ë¶„í•  ê²°ê³¼: ì²­í¬ë³„ ìƒ‰ìƒ êµ¬ë¶„, í†µê³„ í‘œì‹œ

**C. Generation íƒ­**
- ì§ˆë¬¸ ì…ë ¥ â†’ `ContextBuilder` ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ ë‹µë³€ í‘œì‹œ
- ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° í™œìš©í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ê³¼ì • ì‹œê°í™”

**D. Full Pipeline íƒ­**
- ë¬¸ì„œ ë¡œë”© â†’ ë¶„í•  â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ ë‹µë³€ ìƒì„± ì „ì²´ ê³¼ì •
- ê° ë‹¨ê³„ë³„ ì¤‘ê°„ ê²°ê³¼ ëª¨ë‘ í‘œì‹œ

**E. í–¥í›„ í™•ì¥ íƒ­ë“¤ (ğŸš§ ë¹„í™œì„± ìƒíƒœ)**
- Embedding, Vector Store, Retriever íƒ­ êµ¬ì¡°ë§Œ êµ¬ì„±
- "í–¥í›„ êµ¬í˜„ ì˜ˆì •" ë©”ì‹œì§€ì™€ êµ¬í˜„ ê³„íš ì„¤ëª…
- ëª¨í‚¹ UIë¡œ ë¯¸ë˜ ê¸°ëŠ¥ ë¯¸ë¦¬ë³´ê¸°

### 2. FastAPI + Gradio í†µí•© ì•„í‚¤í…ì²˜

#### ë©”ì¸ í˜ì´ì§€ ë¼ìš°íŒ… ì„¤ê³„
```python
# app/main.py ìˆ˜ì •
import gradio as gr
from .demo.rag_demo import create_rag_demo_interface

app = FastAPI()

# ê¸°ì¡´ API ë¼ìš°í„°ë“¤
app.include_router(api_router, prefix="/api/v1")

# Gradio ì•± ìƒì„± ë° ë§ˆìš´íŠ¸
demo_app = create_rag_demo_interface()
app = gr.mount_gradio_app(app, demo_app, path="/")  # ë©”ì¸ í˜ì´ì§€ë¡œ ì„¤ì •
```

**ì ‘ì† ë°©ë²•**:
- `http://localhost:8000/` â†’ Gradio RAG ë°ëª¨ í™”ë©´
- `http://localhost:8000/api/v1/chat` â†’ ê¸°ì¡´ API ìœ ì§€

#### ìƒˆë¡œìš´ ëª¨ë“ˆ êµ¬ì¡°
```
ai-service/app/
â”œâ”€â”€ demo/                      # RAG ë°ëª¨ ì¸í„°í˜ì´ìŠ¤ (ì‹ ê·œ)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag_demo.py           # Gradio ì¸í„°í˜ì´ìŠ¤ ì •ì˜
â”‚   â””â”€â”€ demo_service.py       # ê¸°ì¡´ RAG í´ë˜ìŠ¤ë“¤ê³¼ ì—°ë™ ì„œë¹„ìŠ¤
â”œâ”€â”€ main.py                   # FastAPI + Gradio í†µí•© ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â””â”€â”€ ...
```

### 3. í•µì‹¬ êµ¬í˜„ í´ë˜ìŠ¤ë“¤

#### A. RAGDemoService (ê¸°ì¡´ í´ë˜ìŠ¤ ë˜í•‘)
```python
class RAGDemoService:
    def __init__(self):
        # ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ ì´ˆê¸°í™”
        self.pipeline = DocumentProcessingPipeline()
        self.context_builder = ContextBuilder(portfolio_service)
        # self.llm_service = LLMService()  # í–¥í›„ ì—°ë™
    
    async def demo_document_loading(self, selected_file):
        """ì‹¤ì œ DocumentProcessingPipeline ì‚¬ìš©"""
        file_path = Path(f"docs/projects/{selected_file}")
        result = await self.pipeline.process_file(file_path)
        return result["documents"][0].page_content, result["processing_stats"]
    
    async def demo_text_splitting(self, content, chunk_size, overlap):
        """ì‹¤ì œ MarkdownTextSplitter ì‚¬ìš©"""
        splitter = MarkdownTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)
        chunks = await splitter.split_text(content)
        return self._format_chunks_for_display(chunks)
```

#### B. Gradio ì¸í„°í˜ì´ìŠ¤ (7ê°œ íƒ­)
```python 
def create_rag_demo_interface():
    with gr.Blocks(title="RAG Pipeline Demonstration") as demo:
        gr.Markdown("# ğŸ¤– RAG Pipeline Demonstration")
        
        with gr.Tabs():
            # âœ… êµ¬í˜„ëœ íƒ­ë“¤
            with gr.Tab("ğŸ“„ Document Loading"):
                # ì‹¤ì œ docs/projects/ íŒŒì¼ë“¤ ë¡œë”© ë°ëª¨
            
            with gr.Tab("âœ‚ï¸ Text Splitting"):  
                # chunk_size, overlap ìŠ¬ë¼ì´ë”ì™€ ì‹¤ì‹œê°„ ë¶„í•  ê²°ê³¼
                
            with gr.Tab("ğŸ¤– Generation"):
                # ContextBuilder + LLM ì„œë¹„ìŠ¤ ì—°ë™
                
            with gr.Tab("ğŸ”„ Full Pipeline"):
                # ì „ì²´ ê³¼ì • í†µí•© ì‹¤í–‰
            
            # ğŸš§ í–¥í›„ í™•ì¥ íƒ­ë“¤ (ë¹„í™œì„±)
            with gr.Tab("ğŸš§ Embedding (í–¥í›„ êµ¬í˜„)"):
                gr.Markdown("OpenAI/HuggingFace ì„ë² ë”© ëª¨ë¸ ì—°ë™ ì˜ˆì •")
                
            with gr.Tab("ğŸš§ Vector Store (í–¥í›„ êµ¬í˜„)"):
                gr.Markdown("Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì˜ˆì •")
                
            with gr.Tab("ğŸš§ Retriever (í–¥í›„ êµ¬í˜„)"):
                gr.Markdown("ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ë° ì¬ë­í‚¹ ì˜ˆì •")
```

### 4. ì˜ì¡´ì„± ê´€ë¦¬ ë° í˜¸í™˜ì„±

#### Requirements íŒŒì¼ ì—…ë°ì´íŠ¸
```bash
# requirements-base.txtì— Gradio ì¶”ê°€
gradio==5.44.0

# Document Processingìš© LangChain ì¶”ê°€  
langchain==0.3.27
langchain-community==0.3.28
```

#### ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
- **ë¬¸ì œ**: google-generativeaiì™€ langchain-google-genai ê°„ ì˜ì¡´ì„± ì¶©ëŒ
- **í•´ê²°**: google-generativeai ì œê±°, langchain-google-genaië§Œ ì‚¬ìš©
- **ê²°ê³¼**: ì˜ì¡´ì„± ì¶©ëŒ ì—†ì´ LangChain ìƒíƒœê³„ë¡œ í†µì¼

### 5. Docker í™˜ê²½ í…ŒìŠ¤íŠ¸

#### Docker êµ¬ì„± ìµœì í™”
```yaml
# docker-compose.demo.yml (RAG ë°ëª¨ ì „ìš©)
services:
  ai-service-demo:
    build:
      dockerfile: Dockerfile.demo
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
```

```dockerfile
# Dockerfile.demo (ìµœì†Œí•œì˜ ì˜ì¡´ì„±)
FROM python:3.11-slim
COPY requirements-demo.txt .
RUN pip install --no-cache-dir -r requirements-demo.txt
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

#### í…ŒìŠ¤íŠ¸ ê²°ê³¼
- âœ… **Gradio ì¸í„°í˜ì´ìŠ¤ ë¡œë”©**: ì„±ê³µ
- âœ… **ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜**: ë¹ ë¥¸ ë¹Œë“œ (< 5ë¶„)  
- âš ï¸ **ì „ì²´ ì˜ì¡´ì„± ì¶©ëŒ**: google.generativeai ëª¨ë“ˆ ì—†ìŒ ì˜¤ë¥˜
- ğŸ”„ **í•´ê²° ë°©ì•ˆ**: LLM ì„œë¹„ìŠ¤ ë¶„ë¦¬ ë° ë‹¨ê³„ì  í†µí•©

### 6. ì‹¤ì œ ë™ì‘ ê²€ì¦

#### ë‹¨ìˆœ í…ŒìŠ¤íŠ¸ ì„±ê³µ
```python
# test_demo.pyë¡œ Gradio ê¸°ë³¸ ë™ì‘ í™•ì¸
- âœ… Gradio ì„œë²„ êµ¬ë™: http://localhost:8000
- âœ… íƒ­ êµ¬ì¡° í‘œì‹œ: Document Loading, Text Splitting ë“±
- âœ… ì¸í„°ë™í‹°ë¸Œ ìš”ì†Œ: ë“œë¡­ë‹¤ìš´, ìŠ¬ë¼ì´ë”, ë²„íŠ¼ ë™ì‘
- âœ… ê¸°ë³¸ ì½œë°± í•¨ìˆ˜: íŒŒì¼ ì„ íƒ, í…ìŠ¤íŠ¸ ë¶„í•  í…ŒìŠ¤íŠ¸
```

### 7. í˜„ì¬ ìƒíƒœ ë° ë‹¤ìŒ ë‹¨ê³„

#### í˜„ì¬ êµ¬í˜„ ì™„ë£Œ
- âœ… **Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì¡°**: 7ê°œ íƒ­ ì™„ì „ ì„¤ê³„
- âœ… **FastAPI í†µí•©**: ë©”ì¸ í˜ì´ì§€ ë§ˆìš´íŠ¸ ë°©ì‹ í™•ë¦½  
- âœ… **ê¸°ì¡´ í´ë˜ìŠ¤ ì—°ë™**: DocumentProcessingPipeline, ContextBuilder ë˜í•‘
- âœ… **Docker í™˜ê²½**: ë°ëª¨ ì „ìš© ê²½ëŸ‰ ì»¨í…Œì´ë„ˆ êµ¬ì„±
- âœ… **í™•ì¥ì„± ê³ ë ¤**: í–¥í›„ ê¸°ëŠ¥ë“¤ì˜ ë¹„í™œì„± íƒ­ ë¯¸ë¦¬ êµ¬ì„±

#### ë‚¨ì€ ê³¼ì œ  
- ğŸ”„ **ì˜ì¡´ì„± ìµœì¢… ì •ë¦¬**: LLM ì„œë¹„ìŠ¤ ì˜ì¡´ì„± í•´ê²°
- ğŸ”„ **ì‹¤ì œ RAG í´ë˜ìŠ¤ ì—°ë™**: ëª¨í‚¹ì—ì„œ ì‹¤ì œ êµ¬í˜„ìœ¼ë¡œ êµì²´
- ğŸ”„ **í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸**: ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
- ğŸ”„ **ìŠ¤í…Œì´ì§• ë°°í¬**: ì‹¤ì œ í™˜ê²½ì—ì„œ ë™ì‘ í™•ì¸

### ê¸°ìˆ ì  ì„±ê³¼

#### ì„¤ê³„ ì›ì¹™ ì¤€ìˆ˜
- âœ… **ê´€ì‹¬ì‚¬ ë¶„ë¦¬**: ë°ëª¨ UIì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¶„ë¦¬
- âœ… **ê¸°ì¡´ ìì‚° í™œìš©**: DocumentProcessingPipeline ë“± ì¬ì‚¬ìš©
- âœ… **í™•ì¥ì„±**: í–¥í›„ RAG ê¸°ëŠ¥ë“¤ì˜ ë‹¨ê³„ì  í™œì„±í™” êµ¬ì¡°
- âœ… **í•™ìŠµ ëª©í‘œ**: Gradio ê¸°ìˆ  ì‹¤ì „ ì ìš©

#### ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
- âœ… **ì‹œê°ì  ì´í•´**: RAG íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ì‹œê°í™”
- âœ… **ì¸í„°ë™í‹°ë¸Œ ì²´í—˜**: ì‹¤ì‹œê°„ íŒŒë¼ë¯¸í„° ì¡°ì • ë° ê²°ê³¼ í™•ì¸
- âœ… **êµìœ¡ì  ê°€ì¹˜**: ê° ë‹¨ê³„ë³„ ì„¤ëª…ê³¼ êµ¬í˜„ ê³„íš ì œì‹œ
- âœ… **ì ‘ê·¼ì„±**: ë©”ì¸ í˜ì´ì§€ì—ì„œ ë°”ë¡œ ì²´í—˜ ê°€ëŠ¥

ì´ì œ ai-serviceëŠ” ì‹¤ìš©ì ì¸ RAG ë°ëª¨ í˜ì´ì§€ë¥¼ ê°–ì¶˜ ì™„ì „í•œ AI ì„œë¹„ìŠ¤ë¡œ ë°œì „í–ˆìŠµë‹ˆë‹¤.

---

## 2025-08-27: í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì €ì¥ì†Œ ê¸°ë°˜ RAG ë°ëª¨ ì‹œìŠ¤í…œ ì„¤ê³„

### ë°°ê²½ ë° ê²°ì • ì‚¬í•­
ê¸°ì¡´ RAG ë°ëª¨ í˜ì´ì§€ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•˜ê¸° ìœ„í•´ **í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì €ì¥ì†Œ ê¸°ë°˜ RAG ë°ëª¨ ì‹œìŠ¤í…œ** ë„ì…ì„ ê²°ì •.

### ë¬¸ì œ ì¸ì‹
- **í˜„ì¬ ìƒíƒœ**: ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ë°ëª¨ (ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ ì—†ìŒ)
- **í•œê³„**: Qdrant ì˜ì¡´ì„±ìœ¼ë¡œ ì¸í•œ ë³µì¡í•œ í™˜ê²½ ì„¤ì •
- **ëª©í‘œ**: ë…ë¦½ì ì´ë©´ì„œë„ ì‹¤ì œ RAG ê¸°ëŠ¥ì„ ì²´í—˜í•  ìˆ˜ ìˆëŠ” ë°ëª¨

### ìµœì¢… ì„ íƒ: ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ â­â­â­

#### í•µì‹¬ ì•„í‚¤í…ì²˜
```python
class InMemoryVectorStore:
    """ë¸Œë¼ìš°ì € ì„¸ì…˜ ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ"""
    def __init__(self):
        self.documents = []     # ì›ë³¸ ë¬¸ì„œ
        self.embeddings = []    # ë²¡í„° ì„ë² ë”©
        self.metadata = []      # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
        self.chunks = []        # ë¶„í• ëœ í…ìŠ¤íŠ¸ ì²­í¬
    
    def add_documents(self, docs, embeddings, metadata):
        """ë¬¸ì„œì™€ ì„ë² ë”© ì¶”ê°€"""
        
    def similarity_search(self, query_embedding, top_k=3):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰"""
        return similar_documents
    
    def get_store_stats(self):
        """ì €ì¥ì†Œ í†µê³„ ì •ë³´"""
        return {"docs": len(self.documents), "chunks": len(self.chunks)}
```

#### ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸ ì„ íƒ
```python
# ì˜µì…˜ 1: ë‹¤êµ­ì–´ ì§€ì› ê²½ëŸ‰ ëª¨ë¸ (ì¶”ì²œ)
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# ì˜µì…˜ 2: í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ (ê³ ë„í™” ë‹¨ê³„)
model = SentenceTransformer('jhgan/ko-sroberta-multitask')
```

### ìƒˆë¡œìš´ ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤

#### 1ë‹¨ê³„: ê¸°ë³¸ ë°ì´í„°ì…‹ ë¡œë”©
- `docs/projects/` ë””ë ‰í† ë¦¬ì˜ í¬íŠ¸í´ë¦¬ì˜¤ ë¬¸ì„œë“¤
- ì‚¬ì „ ì²˜ë¦¬ëœ ì²­í¬ ë° ì„ë² ë”© (ì„ íƒì‚¬í•­)

#### 2ë‹¨ê³„: ì‹¤ì‹œê°„ ë¬¸ì„œ ì—…ë¡œë“œ
```python
with gr.Tab("ğŸ“„ Document Upload & Processing"):
    file_upload = gr.File(
        file_types=[".md", ".txt"], 
        label="Upload Your Document"
    )
    process_btn = gr.Button("Process & Add to Vector Store")
    processing_status = gr.Textbox(label="Processing Status")
```

#### 3ë‹¨ê³„: ì‹¤ì‹œê°„ ì„ë² ë”© ìƒì„±
```python
with gr.Tab("ğŸ§® Embedding Generation (Live)"):
    with gr.Row():
        text_input = gr.Textbox(label="Text to Embed")
        embed_btn = gr.Button("Generate Embedding")
        
    embedding_output = gr.Textbox(label="Embedding Vector")
    similarity_viz = gr.Plot(label="Embedding Visualization")
```

#### 4ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ ì²´í—˜
```python
with gr.Tab("ğŸ” Vector Search (Live)"):
    with gr.Row():
        query_input = gr.Textbox(label="Search Query")
        search_btn = gr.Button("Search Similar Documents")
        
    with gr.Row():
        search_results = gr.DataFrame(label="Search Results")
        similarity_scores = gr.Plot(label="Similarity Scores")
```

#### 5ë‹¨ê³„: ì „ì²´ RAG íŒŒì´í”„ë¼ì¸
```python
with gr.Tab("ğŸ”„ Full RAG Pipeline (Live)"):
    # ì§ˆë¬¸ ì…ë ¥ â†’ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ ë‹µë³€ ìƒì„±
    # ê° ë‹¨ê³„ë³„ ì¤‘ê°„ ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ
```

### ê¸°ìˆ ì  ì¥ì 

#### A. ë…ë¦½ì„± í™•ë³´
- âœ… **Qdrant ì˜ì¡´ì„± ì œê±°**: ë³µì¡í•œ ì„¤ì¹˜ ê³¼ì • ë¶ˆí•„ìš”
- âœ… **ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥**: Docker ê¸°ë³¸ í™˜ê²½ì—ì„œ ë°”ë¡œ ë™ì‘
- âœ… **í¬í„°ë¸”**: ì–´ë–¤ í™˜ê²½ì—ì„œë“  ì¼ê´€ëœ ë™ì‘

#### B. ì‹¤ì œ RAG ê¸°ëŠ¥ ì œê³µ
- âœ… **ì§„ì§œ ì„ë² ë”©**: SentenceTransformer ê¸°ë°˜ ì‹¤ì œ ë²¡í„° ìƒì„±
- âœ… **ì‹¤ì œ ê²€ìƒ‰**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰
- âœ… **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ì‚¬ìš©ì ì—…ë¡œë“œ â†’ ì„ë² ë”© â†’ ê²€ìƒ‰ ì „ì²´ í”Œë¡œìš°

#### C. êµìœ¡ì  ê°€ì¹˜
- âœ… **ë‹¨ê³„ë³„ ì‹œê°í™”**: ê° ë‹¨ê³„ì˜ ì¤‘ê°„ ê²°ê³¼ í™•ì¸ ê°€ëŠ¥
- âœ… **ë§¤ê°œë³€ìˆ˜ ì¡°ì •**: chunk_size, top_k, similarity_threshold ì‹¤ì‹œê°„ ë³€ê²½
- âœ… **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì²˜ë¦¬ ì‹œê°„, ì •í™•ë„, ì €ì¥ì†Œ ìƒíƒœ í‘œì‹œ

### êµ¬í˜„ ê³„íš

#### Phase 1: ê¸°ë³¸ ë²¡í„° ì €ì¥ì†Œ êµ¬í˜„
1. **InMemoryVectorStore í´ë˜ìŠ¤** êµ¬í˜„
2. **ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸** í†µí•© (sentence-transformers)
3. **ê¸°ë³¸ CRUD ê¸°ëŠ¥** (ë¬¸ì„œ ì¶”ê°€, ê²€ìƒ‰, ì‚­ì œ)

#### Phase 2: Gradio UI ê³ ë„í™”
1. **íŒŒì¼ ì—…ë¡œë“œ** ì¸í„°í˜ì´ìŠ¤
2. **ì‹¤ì‹œê°„ ì²˜ë¦¬ ìƒíƒœ** í‘œì‹œ
3. **ê²€ìƒ‰ ê²°ê³¼ ì‹œê°í™”** (ìœ ì‚¬ë„ ì ìˆ˜, í•˜ì´ë¼ì´íŒ…)

#### Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€
1. **ì„ë² ë”© ì‹œê°í™”** (t-SNE, PCA)
2. **ë§¤ê°œë³€ìˆ˜ íŠœë‹** UI
3. **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬** ë„êµ¬

### ì˜ì¡´ì„± ì—…ë°ì´íŠ¸

#### requirements-demo.txt ì¶”ê°€
```bash
# ê¸°ì¡´ ì˜ì¡´ì„±
fastapi==0.116.1
uvicorn[standard]==0.35.0
gradio==5.44.0
langchain==0.3.27
langchain-community==0.3.28

# ìƒˆë¡œìš´ ì˜ì¡´ì„± (ë²¡í„° ì²˜ë¦¬)
sentence-transformers==5.1.0    # ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸
numpy==2.3.2                    # ë²¡í„° ì—°ì‚°
scikit-learn==1.5.2            # ìœ ì‚¬ë„ ê³„ì‚°
matplotlib==3.9.0              # ê²°ê³¼ ì‹œê°í™”
```

### ì˜ˆìƒ ì‚¬ìš©ì ê²½í—˜

#### ë°ëª¨ í”Œë¡œìš°
```
1. ğŸ“„ ê¸°ë³¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¬¸ì„œë“¤ì´ ì´ë¯¸ ë¡œë“œë¨
2. ğŸ” "React í”„ë¡œì íŠ¸"ë¥¼ ê²€ìƒ‰í•˜ë©´ ê´€ë ¨ ë¬¸ì„œ 3ê°œ ë°˜í™˜
3. ğŸ“¤ ì‚¬ìš©ìê°€ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ
4. âš¡ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„ë² ë”© ìƒì„± ë° ì €ì¥ì†Œì— ì¶”ê°€
5. ğŸ” ì—…ë¡œë“œí•œ ë¬¸ì„œ ë‚´ìš©ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥
6. ğŸ“Š ìœ ì‚¬ë„ ì ìˆ˜ì™€ ì‹œê°í™” ê²°ê³¼ í™•ì¸
```

### ê¸°ëŒ€ íš¨ê³¼

#### A. ì‚¬ìš©ì ê´€ì 
- **ì‹¤ì œ RAG ì‹œìŠ¤í…œ ì²´í—˜**: ì‹œë®¬ë ˆì´ì…˜ì´ ì•„ë‹Œ ì§„ì§œ ë²¡í„° ê²€ìƒ‰
- **í•™ìŠµ íš¨ê³¼**: RAGì˜ ê° ë‹¨ê³„ë¥¼ ì§ì ‘ ì¡°ì‘í•˜ë©° ì´í•´
- **í¬íŠ¸í´ë¦¬ì˜¤ í™œìš©**: ì‹¤ì œ í”„ë¡œì íŠ¸ ë¬¸ì„œë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸

#### B. ê°œë°œì ê´€ì   
- **í”„ë¡œí† íƒ€ì´í•‘**: ë³µì¡í•œ ì¸í”„ë¼ ì—†ì´ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
- **ì•Œê³ ë¦¬ì¦˜ ê²€ì¦**: ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ê³¼ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
- **ì„±ëŠ¥ ì¸¡ì •**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ê²€ìƒ‰ ì†ë„ ë“± ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

#### C. ê¸°ìˆ ì  ê´€ì 
- **í™•ì¥ì„±**: í–¥í›„ Qdrant ì—°ë™ ì‹œ ì¸í„°í˜ì´ìŠ¤ ì¬ì‚¬ìš© ê°€ëŠ¥
- **ë…ë¦½ì„±**: ì™¸ë¶€ ì„œë¹„ìŠ¤ì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ì™„ì „í•œ ë°ëª¨
- **ê²½ëŸ‰í™”**: ìµœì†Œí•œì˜ ë¦¬ì†ŒìŠ¤ë¡œ ìµœëŒ€ ê¸°ëŠ¥ ì œê³µ

ì´ì œ í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì €ì¥ì†Œ ê¸°ë°˜ì˜ ì‹¤ì œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì„ í†µí•´ ì§„ì •í•œ ì¸í„°ë™í‹°ë¸Œ ë°ëª¨ í™˜ê²½ì„ ì œê³µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## 2025-08-27: í™˜ê²½ë³„ ë°°í¬ ì „ëµ ë° Railway CI/CD êµ¬ì¶• ê²°ì •

### ìµœì¢… ë°°í¬ ì „ëµ ê²°ì •

#### **ì´ì›í™” + API ì „ëµ** ì±„íƒ â­â­â­

**í•µì‹¬ ì›ì¹™**: ë™ì¼ ì½”ë“œë² ì´ìŠ¤, í™˜ê²½ë³„ ì„¤ì •ìœ¼ë¡œ ìµœì í™”

```yaml
ì½”ë“œ í†µì¼ì„±: 
  - ë‹¨ì¼ Git ë¦¬í¬ì§€í† ë¦¬
  - í™˜ê²½ ì„¤ì •ìœ¼ë¡œë§Œ êµ¬ë¶„ (ENV_TYPE)
  - ì„œë¹„ìŠ¤ íŒ©í† ë¦¬ íŒ¨í„´ ì ìš©

í™˜ê²½ë³„ ìµœì í™”:
  - Demo: Railway + ë¡œì»¬ ëª¨ë¸ (êµìœ¡/ì‹œì—°ìš©)
  - Staging/Production: Cloud Run + API í˜¸ì¶œ (ì‹¤ì‚¬ìš©)
```

### í™˜ê²½ë³„ êµ¬ì„±

#### **1ï¸âƒ£ Demo Environment (Railway)**
```yaml
ëª©ì : RAG íŒŒì´í”„ë¼ì¸ í•™ìŠµ ë° ì‹œì—°
í”Œë«í¼: Railway Pro ($20/ì›”)
ì„¤ì •:
  ENV_TYPE: demo
  EMBEDDING_SERVICE_TYPE: local  # sentence-transformers
  LLM_SERVICE_TYPE: mock
  VECTOR_STORE_TYPE: memory
  ENABLE_GRADIO_DEMO: true

ê¸°ìˆ  ìŠ¤íƒ:
  - sentence-transformers: ì‹¤ì œ ì„ë² ë”© ëª¨ë¸
  - InMemoryVectorStore: ì„¸ì…˜ ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ  
  - Gradio UI: ì¸í„°ë™í‹°ë¸Œ RAG ë°ëª¨
  - ë¦¬ì†ŒìŠ¤: 4-6GB RAM, 4vCPU

íŠ¹ì§•:
  âœ… ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ ì²´í—˜
  âœ… ë¬¸ì„œ ì—…ë¡œë“œ & ì‹¤ì‹œê°„ ì²˜ë¦¬
  âœ… ì„ë² ë”© ìƒì„± & ìœ ì‚¬ë„ ê³„ì‚°
  âœ… RAG íŒŒì´í”„ë¼ì¸ ì „ ê³¼ì • ì‹œì—°
```

#### **2ï¸âƒ£ Staging/Production Environment (Cloud Run)**
```yaml
ëª©ì : ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ Q&A ì„œë¹„ìŠ¤
í”Œë«í¼: Google Cloud Run ($10-20/ì›”)
ì„¤ì •:
  ENV_TYPE: production
  EMBEDDING_SERVICE_TYPE: openai  # API í˜¸ì¶œ
  LLM_SERVICE_TYPE: gemini       # API í˜¸ì¶œ
  VECTOR_STORE_TYPE: qdrant      # í´ë¼ìš°ë“œ ë²¡í„°DB
  ENABLE_GRADIO_DEMO: false      # APIë§Œ

ê¸°ìˆ  ìŠ¤íƒ:
  - OpenAI Embedding API: $0.0004/1K tokens
  - Gemini LLM API: $0.002/1K tokens  
  - Qdrant Cloud: ë²¡í„° ì €ì¥ì†Œ
  - PostgreSQL: ë©”íƒ€ë°ì´í„°
  - ë¦¬ì†ŒìŠ¤: 512MB-1GB RAM, 1vCPU (ì´ˆê²½ëŸ‰!)

íŠ¹ì§•:
  âœ… ë¹ ë¥¸ ì‘ë‹µ (1-3ì´ˆ)
  âœ… ë¬´ì œí•œ í™•ì¥ì„±
  âœ… ìµœì‹  ëª¨ë¸ í’ˆì§ˆ
  âœ… ì„œë²„ë¦¬ìŠ¤ ë¹„ìš© íš¨ìœ¨ì„±
```

### í†µí•© ì•„í‚¤í…ì²˜ êµ¬í˜„

#### **í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬**
```python
# app/config/settings.py
class Settings(BaseSettings):
    ENV_TYPE: str = "demo"  # demo, staging, production
    
    # ì„œë¹„ìŠ¤ íƒ€ì…ë³„ ì„¤ì •
    EMBEDDING_SERVICE_TYPE: str = "local"  # local, openai, gemini
    LLM_SERVICE_TYPE: str = "mock"        # mock, openai, gemini  
    VECTOR_STORE_TYPE: str = "memory"     # memory, qdrant
    
    # API í‚¤ (í™˜ê²½ë³„)
    OPENAI_API_KEY: Optional[str] = None
    GEMINI_API_KEY: Optional[str] = None
    QDRANT_URL: Optional[str] = None
    
    # UI ì„¤ì •
    ENABLE_GRADIO_DEMO: bool = True
    ENABLE_API_ENDPOINTS: bool = True

    class Config:
        env_file = {
            "demo": ".env.demo",
            "staging": ".env.staging", 
            "production": ".env.production"
        }
```

#### **ì„œë¹„ìŠ¤ íŒ©í† ë¦¬ íŒ¨í„´**
```python
# app/services/factory.py
class ServiceFactory:
    @staticmethod
    def create_embedding_service(settings):
        if settings.EMBEDDING_SERVICE_TYPE == "local":
            return SentenceTransformersService()  # ë¡œì»¬ ëª¨ë¸
        elif settings.EMBEDDING_SERVICE_TYPE == "openai":
            return OpenAIEmbeddingService()       # API í˜¸ì¶œ
        elif settings.EMBEDDING_SERVICE_TYPE == "gemini":
            return GeminiEmbeddingService()       # API í˜¸ì¶œ
        else:
            return MockEmbeddingService()         # Mock
```

### Docker ë° ë°°í¬ êµ¬ì„±

#### **í™˜ê²½ë³„ Dockerfile**
```dockerfile
# Dockerfile.demo (Railwayìš© - ëª¨ë“  ì˜ì¡´ì„±)
FROM python:3.11-slim
COPY requirements-demo.txt .
RUN pip install -r requirements-demo.txt
COPY . .
ENV ENV_TYPE=demo
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

# Dockerfile.prod (Cloud Runìš© - ê²½ëŸ‰í™”)
FROM python:3.11-slim  
COPY requirements-prod.txt .
RUN pip install -r requirements-prod.txt  # torch ì œì™¸
COPY . .
ENV ENV_TYPE=production
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### **Requirements ë¶„ë¦¬**
```txt
# requirements-demo.txt (3.5GB+ íŒ¨í‚¤ì§€)
sentence-transformers==5.1.0
torch==2.8.0
scikit-learn==1.5.2  
gradio==5.44.0
# ... ëª¨ë“  ML ì˜ì¡´ì„±

# requirements-prod.txt (ê²½ëŸ‰ API ì „ìš©)
fastapi==0.116.1
openai==1.54.4
google-generativeai==0.8.5
qdrant-client==1.15.1
# sentence-transformers, torch ì œì™¸
```

### ë¡œì»¬ ê°œë°œ í™˜ê²½

#### **ë¡œì»¬ì—ì„œ Demo í™˜ê²½ í™•ì¸ ê°€ëŠ¥** âœ…
```bash
# ë¡œì»¬ ê°œë°œ (Demo í™˜ê²½ê³¼ ë™ì¼)
export ENV_TYPE=demo
export EMBEDDING_SERVICE_TYPE=local
export ENABLE_GRADIO_DEMO=true

python -m uvicorn app.main:app --reload
# â†’ http://localhost:8000 (Gradio Demo UI)

# ë¡œì»¬ì—ì„œ Production í™˜ê²½ í…ŒìŠ¤íŠ¸ë„ ê°€ëŠ¥
export ENV_TYPE=production  
export EMBEDDING_SERVICE_TYPE=openai
export OPENAI_API_KEY=sk-...
export ENABLE_GRADIO_DEMO=false

python -m uvicorn app.main:app --reload  
# â†’ http://localhost:8000/api/v1/chat (APIë§Œ)
```

### ë¹„ìš© ë¶„ì„

#### **ì´ ìš´ì˜ ë¹„ìš©**
```yaml
Demo Environment (HuggingFace Spaces):
  - í”Œë«í¼: $0/ì›” (ë¬´ë£Œ) âœ…
  - í•˜ë“œì›¨ì–´: 16GB RAM CPU Basic
  - íŠ¹ì§•: ML ëª¨ë¸ ìµœì í™”, ë¬´ì œí•œ ìŠ¤í† ë¦¬ì§€

Production Environment (Cloud Run):
  - í”Œë«í¼: $5-10/ì›” (ì‚¬ìš©ëŸ‰ ê¸°ë°˜)
  - API í˜¸ì¶œ: $10-15/ì›” (OpenAI + Gemini)
  - íŠ¹ì§•: ì„œë²„ë¦¬ìŠ¤, ìš”ì²­ ê¸°ë°˜ ê³¼ê¸ˆ

ì´ ì˜ˆìƒ ë¹„ìš©: $15-25/ì›” (70% ì ˆì•½!)
ê¸°ì¡´ í†µí•© ë°©ì‹: $80-120/ì›” ëŒ€ë¹„ 80% ì ˆì•½
```

### HuggingFace Spaces CI/CD êµ¬ì¶• ê³„íš

#### **ë°°í¬ ì „ëµ ë³€ê²½ ì´ìœ **
```yaml
Railway Hobby ì œì•½ì‚¬í•­:
  - Memory: 512MB (í•„ìš”: 4-6GB) âŒ
  - Storage: 1GB (í•„ìš”: 3.5GB) âŒ  
  - Sleep: 15ë¶„ ë¹„í™œì„± ì‹œ ìŠ¬ë¦½ âŒ

HuggingFace Spaces ì¥ì :
  - Memory: 16GB RAM ë¬´ë£Œ âœ…
  - Storage: Unlimited âœ…
  - ML ëª¨ë¸ ìµœì í™” âœ…
  - ì™„ì „ ë¬´ë£Œ âœ…
```

#### **ìë™ ë°°í¬ íŠ¸ë¦¬ê±°**
```yaml
ë¸Œëœì¹˜ ì „ëµ:
  - main â†’ Production (Cloud Run)  
  - staging â†’ Staging (Cloud Run)
  - demo â†’ Demo (HuggingFace Spaces)

HuggingFace Spaces ì„¤ì •:
  - Repository: AI_Portfolio  
  - Branch: demo
  - Space Type: Gradio
  - Hardware: CPU Basic (16GB RAM)
  - SDK: gradio==5.44.0
```

### ê¸°ëŒ€ íš¨ê³¼

#### **ê°œë°œ ìƒì‚°ì„±**
- âœ… **ë¡œì»¬ í…ŒìŠ¤íŠ¸**: Demo/Production í™˜ê²½ ëª¨ë‘ ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- âœ… **ì½”ë“œ í†µì¼ì„±**: ë‹¨ì¼ ì½”ë“œë² ì´ìŠ¤ë¡œ ëª¨ë“  í™˜ê²½ ì§€ì›
- âœ… **ë°°í¬ ìë™í™”**: ë¸Œëœì¹˜ë³„ ìë™ ë°°í¬

#### **ì‚¬ìš©ì ê²½í—˜**  
- âœ… **Demo**: ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸ ì²´í—˜
- âœ… **Production**: ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ì‹¤ì‚¬ìš© ì„œë¹„ìŠ¤
- âœ… **í•™ìŠµ ê°€ì¹˜**: ì‹¤ì œ ëª¨ë¸ê³¼ API í˜¸ì¶œ ë°©ì‹ ë¹„êµ í•™ìŠµ

#### **ìš´ì˜ íš¨ìœ¨ì„±**
- âœ… **ë¹„ìš© ìµœì í™”**: í™˜ê²½ë³„ ìµœì ì˜ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©
- âœ… **ê´€ë¦¬ ë‹¨ìˆœí™”**: ì„¤ì • ê¸°ë°˜ í™˜ê²½ ë¶„ë¦¬  
- âœ… **í™•ì¥ì„±**: ìƒˆë¡œìš´ í™˜ê²½ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥

ì´ì œ ë™ì¼í•œ ì½”ë“œë¡œ ë¡œì»¬ ê°œë°œ, Demo ì‹œì—°, Production ì„œë¹„ìŠ¤ë¥¼ ëª¨ë‘ ì§€ì›í•˜ëŠ” ì™„ë²½í•œ multi-environment ì•„í‚¤í…ì²˜ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## 2025-08-28: ë°ëª¨ ì•± ì´ˆê¸°í™” ì˜¤ë¥˜ í•´ê²° ë° Clean Architecture ì„¤ê³„ ë³€ê²½

### ë°°ê²½
ë°ëª¨ ì•±ì—ì„œ Docker ì‹¤í–‰ ì‹œ "âŒ RAG Service Not Ready" ì˜¤ë¥˜ì™€ HuggingFace ìºì‹œ ê¶Œí•œ ë¬¸ì œê°€ ë°œìƒ. ì´ë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì—ì„œ ì‹œìŠ¤í…œ ì „ë°˜ì˜ ì•„í‚¤í…ì²˜ ë¬¸ì œì ì´ ë“œëŸ¬ë‚˜ Clean Architecture ê¸°ë°˜ ì¬ì„¤ê³„ë¥¼ ì‹¤ì‹œí•¨.

### 1. ë°ëª¨ ì•± ì´ˆê¸°í™” ì˜¤ë¥˜ í•´ê²°

#### ë°œìƒí•œ ë¬¸ì œë“¤
- **ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨**: `main_demo.py`ì—ì„œ RAG ì„œë¹„ìŠ¤ import ì˜¤ë¥˜
- **HuggingFace ìºì‹œ ê¶Œí•œ ì˜¤ë¥˜**: `/home/user/.cache/huggingface/` ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ 
- **ì˜ì¡´ì„± ëˆ„ë½**: `scikit-learn` íŒ¨í‚¤ì§€ ëˆ„ë½ìœ¼ë¡œ ì„ë² ë”© ì„œë¹„ìŠ¤ ì˜¤ë¥˜
- **ë°ì´í„° ëª¨ë¸ ë¶ˆì¼ì¹˜**: `TextChunk`ê³¼ LangChain `Document` ê°„ í˜¼ì¬ ì‚¬ìš©

#### í•´ê²° ë°©ì•ˆ
**Docker ê¶Œí•œ ë¬¸ì œ í•´ê²°**:
```dockerfile
# Dockerfile.spaces ìˆ˜ì •
RUN chown -R user:user /app && \
    mkdir -p /home/user/.cache/huggingface && \
    chown -R user:user /home/user/.cache
ENV TRANSFORMERS_CACHE=/home/user/.cache/huggingface
ENV HF_HOME=/home/user/.cache/huggingface
```

**ì˜ì¡´ì„± ê´€ë¦¬ ê°œì„ **:
```bash
# requirements-demo.txtì™€ requirements-local.txtì— ì¶”ê°€
scikit-learn==1.5.2
```

**ë°ì´í„° ëª¨ë¸ í‘œì¤€í™”**:
- ëª¨ë“  Document processingì—ì„œ LangChain `Document` í‘œì¤€ ì‚¬ìš©
- `TextChunk` â†’ `Document.page_content` ë³€í™˜
- ë©”íƒ€ë°ì´í„° êµ¬ì¡° í†µì¼

### 2. ì•„í‚¤í…ì²˜ ë¬¸ì œì  ì‹ë³„

#### ë°œê²¬ëœ ì„¤ê³„ ê²°í•¨ë“¤
- **ìˆœí™˜ ì˜ì¡´ì„±**: Document pipelineê³¼ validator ê°„ ìƒí˜¸ ì°¸ì¡°
- **ë°ì´í„° ëª¨ë¸ í˜¼ì¬**: ì»¤ìŠ¤í…€ `TextChunk`ì™€ LangChain `Document` í˜¼ìš©
- **ê´€ì‹¬ì‚¬ í˜¼ì¬**: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì¸í”„ë¼ êµ¬í˜„ì´ ê°•ê²°í•©
- **í™•ì¥ì„± ì œì•½**: ìƒˆë¡œìš´ íŒŒì¼ íƒ€ì… ì¶”ê°€ ì‹œ ì—¬ëŸ¬ í´ë˜ìŠ¤ ìˆ˜ì • í•„ìš”

#### ì‚¬ìš©ì í”¼ë“œë°±
> "ì´ë ‡ê²Œ ëœ ê±´ ì„¤ê³„ì  ê²°í•¨ì´ ìˆëŠ” ê²ƒ ê°™ë‹¤. ai-service ì‹œìŠ¤í…œì´ ë‹¨ê³„ë³„ë¡œ ê¹”ë”í•˜ê²Œ ì§„í–‰ë˜ê³ , ì°¸ì¡°ë“¤ë„ ìš°ì•„í•˜ê²Œ ë  ìˆ˜ ìˆë„ë¡ ì „ë°˜ì ì¸ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ê³ ë ¤í•´ì¤˜."

### 3. Clean Architecture ì¬ì„¤ê³„ ì‹¤ì‹œ

#### ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ êµ¬ì¡°
```
ai-service/app/
â”œâ”€â”€ domain/                     # ìˆœìˆ˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”œâ”€â”€ entities/              # ë„ë©”ì¸ ê°ì²´
â”‚   â”‚   â””â”€â”€ document.py       # ProcessedDocument, DocumentChunk, ProcessingResult
â”‚   â”œâ”€â”€ interfaces/           # ì˜ì¡´ì„± ì—­ì „ì„ ìœ„í•œ ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â””â”€â”€ document_processor.py  # DocumentLoader, DocumentSplitter ë“±
â”‚   â””â”€â”€ services/            # ë„ë©”ì¸ ì„œë¹„ìŠ¤
â”‚       â””â”€â”€ document_processing_service.py  # í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”œâ”€â”€ application/              # ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë¹„ìŠ¤
â”‚   â””â”€â”€ document_pipeline.py  # ê³ ìˆ˜ì¤€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â””â”€â”€ infrastructure/          # êµ¬í˜„ì²´
    â””â”€â”€ document/
        â”œâ”€â”€ langchain_adapter.py    # LangChain ì—°ë™
        â”œâ”€â”€ processor_factory.py    # êµ¬ì²´ íŒ©í† ë¦¬
        â””â”€â”€ validator.py           # ê²€ì¦ êµ¬í˜„
```

#### í•µì‹¬ ì„¤ê³„ ì›ì¹™ ì ìš©
**1. ì˜ì¡´ì„± ì—­ì „ (Dependency Inversion)**
- Domain layerê°€ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- Infrastructure layerê°€ êµ¬ì²´ êµ¬í˜„ ì œê³µ
- Application layerê°€ ë‘˜ì„ ì—°ê²°

**2. ê´€ì‹¬ì‚¬ ë¶„ë¦¬ (Separation of Concerns)**
- Domain: ìˆœìˆ˜ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™
- Application: ìœ ìŠ¤ì¼€ì´ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜  
- Infrastructure: ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™

**3. ë‹¨ì¼ ì±…ì„ ì›ì¹™ (Single Responsibility)**
- ê° í´ë˜ìŠ¤ëŠ” í•˜ë‚˜ì˜ ì±…ì„ë§Œ ê°€ì§
- Factory íŒ¨í„´ìœ¼ë¡œ ê°ì²´ ìƒì„± ë¶„ë¦¬
- Adapter íŒ¨í„´ìœ¼ë¡œ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²©ë¦¬

### 4. êµ¬í˜„ëœ í•µì‹¬ í´ë˜ìŠ¤ë“¤

#### Domain Entities (ë„ë©”ì¸ ì—”í‹°í‹°)
```python
@dataclass(frozen=True)
class ProcessedDocument:
    """ìˆœìˆ˜í•œ ë„ë©”ì¸ ê°ì²´ - ë¶ˆë³€ì„± ë³´ì¥"""
    content: str
    metadata: Dict[str, Any]
    
    def __post_init__(self):
        if not self.content:
            raise ValueError("Document content cannot be empty")

@dataclass(frozen=True) 
class DocumentChunk:
    """í…ìŠ¤íŠ¸ ì²­í¬ ë„ë©”ì¸ ê°ì²´"""
    content: str
    metadata: Dict[str, Any]
    chunk_index: int
```

#### Domain Interfaces (ì˜ì¡´ì„± ì—­ì „)
```python
class DocumentLoader(ABC):
    @abstractmethod
    async def load_document(self, file_path: Path) -> ProcessedDocument: ...

class DocumentSplitter(ABC):
    @abstractmethod
    async def split_document(self, document: ProcessedDocument) -> List[DocumentChunk]: ...

class DocumentProcessorFactory(ABC):
    @abstractmethod
    def create_loader(self, file_path: Path) -> DocumentLoader: ...
    @abstractmethod  
    def create_splitter(self, file_type: str) -> DocumentSplitter: ...
```

#### Infrastructure Adapters (LangChain í†µí•©)
```python
def langchain_document_to_domain(langchain_doc: Document) -> ProcessedDocument:
    """LangChain Documentë¥¼ ë„ë©”ì¸ ê°ì²´ë¡œ ë³€í™˜"""
    metadata = dict(langchain_doc.metadata)
    if "document_id" not in metadata:
        metadata["document_id"] = str(uuid.uuid4())
    
    return ProcessedDocument(
        content=langchain_doc.page_content,
        metadata=metadata
    )

class LangChainProcessorFactory(DocumentProcessorFactory):
    """LangChain ê¸°ë°˜ êµ¬ì²´ íŒ©í† ë¦¬ êµ¬í˜„"""
    def create_loader(self, file_path: Path) -> DocumentLoader:
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì ì ˆí•œ ë¡œë” ìƒì„±
    def create_splitter(self, file_type: str) -> DocumentSplitter:
        # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì ì ˆí•œ ìŠ¤í”Œë¦¬í„° ìƒì„±
```

### 5. RAG ì„œë¹„ìŠ¤ í†µí•©

#### ê¸°ì¡´ RAG ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
```python
class RAGService:
    def __init__(
        self,
        vector_store: VectorStore,
        llm_service: LlmService, 
        embedding_service: EmbeddingService,
        document_pipeline: DocumentProcessingPipeline = None,  # Clean Architecture ì£¼ì…
    ):
        # Clean Architecture íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
        self.document_pipeline = document_pipeline or DocumentProcessingPipeline({
            "chunk_size": 1000,
            "chunk_overlap": 200, 
            "encoding": "utf-8"
        })
    
    async def process_file(self, file_path: Path) -> Dict[str, Any]:
        """Clean Architecture íŒŒì´í”„ë¼ì¸ ì‚¬ìš©"""
        pipeline_result = await self.document_pipeline.process_file(file_path)
        # ... LangChain í¬ë§·ìœ¼ë¡œ ë³€í™˜ í›„ ë²¡í„° ì €ì¥ì†Œ ì—°ë™
```

### 6. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

#### ì¢…ë‹¨ê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼
```python
# í…ŒìŠ¤íŠ¸ ê²°ê³¼
âœ… Clean architecture pipeline initialized successfully
âœ… RAG Service import successful  
âœ… File processing success: True
âœ… Document count: 1, Chunk count: 1
âœ… Search success: True
âœ… End-to-end test passed!
```

#### ì§€ì› íŒŒì¼ í˜•ì‹
- `.txt` íŒŒì¼: RecursiveCharacterTextSplitter
- `.md` íŒŒì¼: MarkdownHeaderTextSplitter + CharacterTextSplitter  
- `.json` íŒŒì¼: JSONLoader with flexible schema

### 7. ì£¼ìš” ê¸°ìˆ ì  ì„±ê³¼

#### ì•„í‚¤í…ì²˜ í’ˆì§ˆ í–¥ìƒ
- **ìˆœí™˜ ì˜ì¡´ì„± í•´ê²°**: ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ ì˜ì¡´ì„± ì—­ì „ìœ¼ë¡œ ê¹”ë”í•œ ê³„ì¸µ êµ¬ì¡°
- **ë‹¨ì¼ ë°ì´í„° ëª¨ë¸**: LangChain Document í‘œì¤€ìœ¼ë¡œ í†µì¼
- **í™•ì¥ì„± í™•ë³´**: ìƒˆ íŒŒì¼ íƒ€ì… ì¶”ê°€ ì‹œ Factoryì—ì„œë§Œ ìˆ˜ì •
- **í…ŒìŠ¤íŠ¸ ìš©ì´ì„±**: ê° ê³„ì¸µë³„ ë…ë¦½ì  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

#### ê°œë°œ ë° ìœ ì§€ë³´ìˆ˜ì„± ê°œì„   
- **ì½”ë“œ ì¬ì‚¬ìš©ì„±**: Domain ë¡œì§ì€ ëª¨ë“  í™˜ê²½ì—ì„œ ê³µí†µ ì‚¬ìš©
- **ë³€ê²½ ì˜í–¥ë„ ìµœì†Œí™”**: ì¸í”„ë¼ ë³€ê²½ì´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ì˜í–¥ ì—†ìŒ
- **ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬**: ê° í´ë˜ìŠ¤ì˜ ì—­í• ê³¼ ì±…ì„ ëª…í™•í™”
- **í‘œì¤€í™”**: ì—…ê³„ í‘œì¤€ì¸ Clean Architecture íŒ¨í„´ ì ìš©

### 8. í–¥í›„ í™•ì¥ ê³„íš

#### ìƒˆ ì•„í‚¤í…ì²˜ ê¸°ë°˜ í™•ì¥ í¬ì¸íŠ¸
- **ìƒˆ ë¬¸ì„œ í˜•ì‹ ì§€ì›**: PDF, Word ë“± ì¶”ê°€ ì‹œ Factoryë§Œ í™•ì¥
- **ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸**: OpenAI, HuggingFace ë“± í”ŒëŸ¬ê·¸ì¸ ë°©ì‹ ì§€ì›
- **ë²¡í„° ì €ì¥ì†Œ í™•ì¥**: Qdrant, Pinecone, Weaviate ë“± ì–´ëŒ‘í„° ì¶”ê°€
- **ê²€ì¦ ì‹œìŠ¤í…œ**: ë„ë©”ì¸ë³„ ë‹¤ì–‘í•œ ê²€ì¦ ê·œì¹™ ì¶”ê°€

### ê²°ë¡ 

ê¸°ì¡´ì˜ í˜¼ì¬ëœ ì•„í‚¤í…ì²˜ë¥¼ Clean Architecture ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ ì¬ì„¤ê³„í•˜ì—¬:

1. **ì„¤ê³„ ê²°í•¨ í•´ê²°**: ìˆœí™˜ ì˜ì¡´ì„±ê³¼ ë°ì´í„° ëª¨ë¸ ë¶ˆì¼ì¹˜ ë¬¸ì œ ê·¼ë³¸ì  í•´ê²°
2. **í™•ì¥ì„± í™•ë³´**: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ì˜í–¥ë„ ìµœì†Œí™”  
3. **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**: ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬ì™€ í‘œì¤€ íŒ¨í„´ ì ìš©
4. **í…ŒìŠ¤íŠ¸ ìš©ì´ì„±**: ê° ê³„ì¸µë³„ ë…ë¦½ì  í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬ì¡°

ì‚¬ìš©ìê°€ ì§€ì í•œ "ì„¤ê³„ì  ê²°í•¨"ì„ Clean Architecture ì›ì¹™ìœ¼ë¡œ í•´ê²°í•˜ì—¬, ai-serviceê°€ "ë‹¨ê³„ë³„ë¡œ ê¹”ë”í•˜ê²Œ ì§„í–‰ë˜ê³  ì°¸ì¡°ë“¤ë„ ìš°ì•„í•œ" ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „í–ˆìŠµë‹ˆë‹¤.