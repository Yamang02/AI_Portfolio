#!/usr/bin/env python3
"""
ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ìºì‹œ ìŠ¤í¬ë¦½íŠ¸
ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•˜ì—¬ ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ê³µìœ í•˜ëŠ” ëª¨ë¸ ìºì‹œ ìƒì„±
"""

import os
import sys
from pathlib import Path
import subprocess
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def download_models():
    """í•„ìš”í•œ ëª¨ë¸ë“¤ì„ ë‹¤ìš´ë¡œë“œ"""
    
    # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì˜ ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
    cache_dir = Path("model_cache")
    cache_dir.mkdir(exist_ok=True)
    
    # HuggingFace ìºì‹œ ë””ë ‰í† ë¦¬
    hf_cache = cache_dir / "huggingface"
    hf_cache.mkdir(exist_ok=True)
    
    # KoNLPy ìºì‹œ ë””ë ‰í† ë¦¬
    konlpy_cache = cache_dir / "konlpy"
    konlpy_cache.mkdir(exist_ok=True)
    
    # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    os.environ["HF_HOME"] = str(hf_cache)
    os.environ["TRANSFORMERS_CACHE"] = str(hf_cache)
    os.environ["KONLPY_DATA_PATH"] = str(konlpy_cache)
    
    logger.info("ğŸš€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    try:
        # 1. Sentence Transformers ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        logger.info("ğŸ“¥ Sentence Transformers ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        subprocess.run([
            sys.executable, "-c",
            "from sentence_transformers import SentenceTransformer; "
            "model = SentenceTransformer('jhgan/ko-sroberta-multitask'); "
            "print('âœ… Sentence Transformers ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ')"
        ], check=True, env=os.environ)
        
        # 2. KoNLPy ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        logger.info("ğŸ“¥ KoNLPy ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        subprocess.run([
            sys.executable, "-c",
            "import konlpy; konlpy.download('all'); "
            "print('âœ… KoNLPy ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ')"
        ], check=True, env=os.environ)
        
        # 3. ì¶”ê°€ ëª¨ë¸ë“¤ (í•„ìš”ì‹œ)
        logger.info("ğŸ“¥ ì¶”ê°€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        subprocess.run([
            sys.executable, "-c",
            "from transformers import AutoTokenizer, AutoModel; "
            "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base'); "
            "model = AutoModel.from_pretrained('klue/bert-base'); "
            "print('âœ… BERT ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ')"
        ], check=True, env=os.environ)
        
        logger.info("ğŸ‰ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        logger.info(f"ğŸ“ ìºì‹œ ìœ„ì¹˜: {cache_dir.absolute()}")
        
        # ìºì‹œ í¬ê¸° í™•ì¸
        total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
        logger.info(f"ğŸ“Š ìºì‹œ í¬ê¸°: {total_size / (1024*1024):.1f} MB")
        
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return False
    
    return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸ”§ ëª¨ë¸ ìºì‹œ ì„¤ì • ì‹œì‘")
    
    if download_models():
        logger.info("âœ… ëª¨ë¸ ìºì‹œ ì„¤ì • ì™„ë£Œ")
        logger.info("ğŸ’¡ ì´ì œ Docker Compose ì‹¤í–‰ ì‹œ ëª¨ë¸ì´ ë¹ ë¥´ê²Œ ë¡œë“œë©ë‹ˆë‹¤!")
        logger.info("ğŸš€ ì‹¤í–‰ ëª…ë ¹: docker-compose up")
    else:
        logger.error("âŒ ëª¨ë¸ ìºì‹œ ì„¤ì • ì‹¤íŒ¨")
        sys.exit(1)

if __name__ == "__main__":
    main()
